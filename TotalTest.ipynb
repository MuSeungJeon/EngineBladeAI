{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 1: 환경 설정 및 Import =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 프로젝트 경로 추가\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# 모델 import\n",
    "from models.unified.unified_model import UnifiedModel\n",
    "from models.heads.mask2former_damage_head import Mask2FormerLoss\n",
    "from utils.dataset import UnifiedDamageDataset, create_dataloaders\n",
    "from utils.evaluate import ModelEvaluator\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 2: Mask2Former 설정 =====\n",
    "class Config:\n",
    "    # 데이터 경로 - 분리된 경로\n",
    "    blade_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data')  # Head-A용\n",
    "    damage_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\multilabeled_data_augmented')  # Head-B용\n",
    "    \n",
    "    blade_checkpoint = 'best_unified_blade_model.pth'\n",
    "    \n",
    "    # 모델 타입\n",
    "    model_type = 'mask2former'\n",
    "    \n",
    "    # 모델 기본 설정\n",
    "    backbone_type = 'tiny'\n",
    "    use_fpn = True\n",
    "    num_blade_classes = 2\n",
    "    num_damage_classes = 3\n",
    "    \n",
    "    # Mask2Former 특화 설정\n",
    "    batch_size = 2  # 메모리 절약\n",
    "    accumulate_grad_batches = 2  # Gradient accumulation\n",
    "    num_workers = 0\n",
    "    \n",
    "    # Mask2Former Head 설정\n",
    "    mask2former_config = {\n",
    "        'num_queries': 100,  # 처음엔 적게\n",
    "        'hidden_dim': 256,\n",
    "        'num_heads': 8,\n",
    "        'dec_layers': 3,  # 처음엔 적은 레이어\n",
    "        'dropout': 0.1\n",
    "    }\n",
    "    \n",
    "    # 학습 설정\n",
    "    epochs = 30\n",
    "    learning_rate = 1e-5  # Mask2Former는 작은 lr\n",
    "    weight_decay = 0.05\n",
    "    gradient_clip = 0.01  # 작은 gradient clipping\n",
    "    \n",
    "    # Mixed Precision Training\n",
    "    use_amp = True\n",
    "    \n",
    "    # 학습 전략\n",
    "    freeze_blade_initially = True\n",
    "    unfreeze_epoch = 15\n",
    "    \n",
    "    # Loss weights\n",
    "    blade_loss_weight = 1.0\n",
    "    aux_loss_weight = 0.4\n",
    "    \n",
    "    # 기타\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    save_dir = Path('outputs_mask2former')\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    experiment_name = f\"mask2former_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "config = Config()\n",
    "print(f\"Experiment: {config.experiment_name}\")\n",
    "print(f\"Model Type: {config.model_type}\")\n",
    "print(f\"Batch Size: {config.batch_size} x {config.accumulate_grad_batches} = {config.batch_size * config.accumulate_grad_batches}\")\n",
    "print(f\"Blade Data: {config.blade_data_root}\")\n",
    "print(f\"Damage Data: {config.damage_data_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 3: 데이터로더 생성 =====\n",
    "print(\"데이터로더 생성 중...\")\n",
    "\n",
    "train_loader, valid_loader, test_loader = create_dataloaders(\n",
    "    blade_data_root=config.blade_data_root,\n",
    "    damage_data_root=config.damage_data_root,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    model_type='mask2former'\n",
    ")\n",
    "\n",
    "print(f\"✅ Train: {len(train_loader)} batches\")\n",
    "print(f\"✅ Valid: {len(valid_loader)} batches\")\n",
    "print(f\"✅ Test: {len(test_loader)} batches\")\n",
    "\n",
    "# 데이터 샘플 확인\n",
    "for batch in train_loader:\n",
    "    print(f\"\\n데이터 샘플:\")\n",
    "    for key, value in batch.items():\n",
    "        if torch.is_tensor(value):\n",
    "            print(f\"  {key}: {value.shape}\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"  {key}: {len(value)} items\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 4: Mask2Former 모델 생성 =====\n",
    "print(\"Mask2Former 모델 생성 중...\")\n",
    "\n",
    "model = UnifiedModel(\n",
    "    backbone_type=config.backbone_type,\n",
    "    num_blade_classes=config.num_blade_classes,\n",
    "    num_damage_classes=config.num_damage_classes,\n",
    "    pretrained_backbone=True,\n",
    "    blade_checkpoint=config.blade_checkpoint if Path(config.blade_checkpoint).exists() else None,\n",
    "    freeze_blade=config.freeze_blade_initially,\n",
    "    use_fpn=config.use_fpn,\n",
    "    damage_head_type='mask2former',\n",
    "    damage_head_config=config.mask2former_config\n",
    ")\n",
    "\n",
    "model = model.to(config.device)\n",
    "\n",
    "# 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"✅ Total parameters: {total_params/1e6:.2f}M\")\n",
    "print(f\"✅ Trainable parameters: {trainable_params/1e6:.2f}M\")\n",
    "print(f\"✅ Blade head frozen: {config.freeze_blade_initially}\")\n",
    "print(f\"✅ Damage head type: Mask2Former\")\n",
    "print(f\"  - Queries: {config.mask2former_config['num_queries']}\")\n",
    "print(f\"  - Decoder layers: {config.mask2former_config['dec_layers']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 5 재정의: autocast 안전한 Loss =====\n",
    "class SimpleLoss(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.blade_ce = nn.CrossEntropyLoss()\n",
    "        self.ml_loss = nn.BCEWithLogitsLoss()  # 항상 이것만 사용\n",
    "    \n",
    "    def forward(self, outputs, batch):\n",
    "        losses = {}\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Blade loss\n",
    "        if 'blade' in outputs and 'blade_mask' in batch:\n",
    "            losses['blade'] = self.blade_ce(outputs['blade'], batch['blade_mask'])\n",
    "            total_loss += losses['blade'] * self.config.blade_loss_weight\n",
    "        \n",
    "        # Multilabel loss - 항상 BCEWithLogitsLoss 사용\n",
    "        if 'multilabel' in outputs and 'multilabel' in batch:\n",
    "            # multilabel 출력이 이미 sigmoid를 거쳤다면 logit으로 역변환\n",
    "            ml_output = outputs['multilabel']\n",
    "            if ml_output.min() >= 0 and ml_output.max() <= 1:\n",
    "                # sigmoid 역변환: logit = log(p / (1-p))\n",
    "                eps = 1e-7\n",
    "                ml_output = torch.log((ml_output + eps) / (1 - ml_output + eps))\n",
    "            \n",
    "            losses['ml'] = self.ml_loss(ml_output, batch['multilabel'])\n",
    "            total_loss += losses['ml'] * 2.0\n",
    "        \n",
    "        losses['total'] = total_loss\n",
    "        return total_loss, losses\n",
    "\n",
    "criterion = SimpleLoss(config)\n",
    "print(\"✅ SimpleLoss ready - autocast safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab67d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 6: Optimizer =====\n",
    "param_groups = [\n",
    "    {'params': model.backbone.parameters(), 'lr': config.learning_rate * 0.1, 'name': 'backbone'}\n",
    "]\n",
    "\n",
    "# Damage head parameters\n",
    "for name, param in model.damage_head.named_parameters():\n",
    "    param_groups.append({'params': [param], 'lr': config.learning_rate, 'name': 'damage_head'})\n",
    "\n",
    "if not config.freeze_blade_initially:\n",
    "    param_groups.append({'params': model.blade_head.parameters(), 'lr': config.learning_rate * 0.5, 'name': 'blade_head'})\n",
    "\n",
    "optimizer = torch.optim.AdamW(param_groups[:2], weight_decay=config.weight_decay)  # 처음 2개 그룹만\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs, eta_min=1e-7)\n",
    "scaler = GradScaler() if config.use_amp else None\n",
    "\n",
    "print(f\"✅ Optimizer ready with {len(param_groups[:2])} groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfacb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 7: Improved Training Functions =====\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scheduler, scaler, config, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': 0,\n",
    "        'blade_iou': 0,\n",
    "        'damage_f1': 0,\n",
    "        'num_batches': 0\n",
    "    }\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.epochs}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        # Move to device\n",
    "        for key in batch:\n",
    "            if torch.is_tensor(batch[key]):\n",
    "                batch[key] = batch[key].to(config.device)\n",
    "            elif isinstance(batch[key], list):\n",
    "                batch[key] = [item.to(config.device) if torch.is_tensor(item) else item \n",
    "                             for item in batch[key]]\n",
    "        \n",
    "        with autocast(enabled=config.use_amp):\n",
    "            outputs = model(batch['image'])\n",
    "            loss, loss_dict = criterion(outputs, batch)\n",
    "            loss = loss / config.accumulate_grad_batches\n",
    "        \n",
    "        # Backward\n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        \n",
    "        # Optimizer step\n",
    "        if (batch_idx + 1) % config.accumulate_grad_batches == 0:\n",
    "            if scaler:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            # Blade IoU\n",
    "            if 'blade' in outputs and 'blade_mask' in batch:\n",
    "                blade_pred = outputs['blade'].argmax(1)\n",
    "                intersection = (blade_pred & batch['blade_mask']).float().sum()\n",
    "                union = (blade_pred | batch['blade_mask']).float().sum()\n",
    "                blade_iou = (intersection / (union + 1e-6)).item()\n",
    "                metrics['blade_iou'] += blade_iou\n",
    "            \n",
    "            # Damage F1\n",
    "            if 'multilabel' in outputs and 'multilabel' in batch:\n",
    "                ml_output = outputs['multilabel']\n",
    "                if ml_output.min() >= 0 and ml_output.max() <= 1:\n",
    "                    pred = (ml_output > 0.5).float()\n",
    "                else:\n",
    "                    pred = (torch.sigmoid(ml_output) > 0.5).float()\n",
    "                \n",
    "                tp = (pred * batch['multilabel']).sum()\n",
    "                fp = (pred * (1 - batch['multilabel'])).sum()\n",
    "                fn = ((1 - pred) * batch['multilabel']).sum()\n",
    "                \n",
    "                f1 = (2 * tp / (2 * tp + fp + fn + 1e-6)).item()\n",
    "                metrics['damage_f1'] += f1\n",
    "        \n",
    "        metrics['loss'] += loss.item() * config.accumulate_grad_batches\n",
    "        metrics['num_batches'] += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        avg_blade_iou = metrics['blade_iou'] / max(1, metrics['num_batches'])\n",
    "        avg_damage_f1 = metrics['damage_f1'] / max(1, metrics['num_batches'])\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{loss.item() * config.accumulate_grad_batches:.4f}\",\n",
    "            'blade_iou': f\"{avg_blade_iou:.3f}\",\n",
    "            'damage_f1': f\"{avg_damage_f1:.3f}\",\n",
    "            'lr': f\"{optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        })\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    return {\n",
    "        'total': metrics['loss'] / metrics['num_batches'],\n",
    "        'blade_iou': metrics['blade_iou'] / metrics['num_batches'],\n",
    "        'damage_f1': metrics['damage_f1'] / metrics['num_batches']\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_epoch(model, valid_loader, criterion, config):\n",
    "    model.eval()\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': 0,\n",
    "        'blade_iou': 0,\n",
    "        'damage_tp': torch.zeros(3).to(config.device),\n",
    "        'damage_fp': torch.zeros(3).to(config.device),\n",
    "        'damage_fn': torch.zeros(3).to(config.device),\n",
    "        'num_batches': 0\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc='Validation'):\n",
    "            for key in batch:\n",
    "                if torch.is_tensor(batch[key]):\n",
    "                    batch[key] = batch[key].to(config.device)\n",
    "                elif isinstance(batch[key], list):\n",
    "                    batch[key] = [item.to(config.device) if torch.is_tensor(item) else item \n",
    "                                 for item in batch[key]]\n",
    "            \n",
    "            outputs = model(batch['image'])\n",
    "            loss, _ = criterion(outputs, batch)\n",
    "            metrics['loss'] += loss.item()\n",
    "            \n",
    "            # Blade IoU\n",
    "            if 'blade' in outputs and 'blade_mask' in batch:\n",
    "                blade_pred = outputs['blade'].argmax(1)\n",
    "                intersection = (blade_pred & batch['blade_mask']).float().sum()\n",
    "                union = (blade_pred | batch['blade_mask']).float().sum()\n",
    "                metrics['blade_iou'] += (intersection / (union + 1e-6)).item()\n",
    "            \n",
    "            # Damage metrics\n",
    "            if 'multilabel' in outputs and 'multilabel' in batch:\n",
    "                ml_output = outputs['multilabel']\n",
    "                if ml_output.min() >= 0 and ml_output.max() <= 1:\n",
    "                    pred = (ml_output > 0.5).float()\n",
    "                else:\n",
    "                    pred = (torch.sigmoid(ml_output) > 0.5).float()\n",
    "                \n",
    "                metrics['damage_tp'] += (pred * batch['multilabel']).sum(dim=0)\n",
    "                metrics['damage_fp'] += (pred * (1 - batch['multilabel'])).sum(dim=0)\n",
    "                metrics['damage_fn'] += ((1 - pred) * batch['multilabel']).sum(dim=0)\n",
    "            \n",
    "            metrics['num_batches'] += 1\n",
    "    \n",
    "    # Calculate F1 scores\n",
    "    precision = metrics['damage_tp'] / (metrics['damage_tp'] + metrics['damage_fp'] + 1e-6)\n",
    "    recall = metrics['damage_tp'] / (metrics['damage_tp'] + metrics['damage_fn'] + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    \n",
    "    return {\n",
    "        'loss': metrics['loss'] / metrics['num_batches'],\n",
    "        'blade_iou': metrics['blade_iou'] / metrics['num_batches'],\n",
    "        'damage_f1': f1.mean().item(),\n",
    "        'per_class_f1': f1.cpu().numpy(),\n",
    "        'precision': precision.cpu().numpy(),\n",
    "        'recall': recall.cpu().numpy()\n",
    "    }\n",
    "\n",
    "print(\"✅ Training functions with full metrics ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 8: Improved Training Loop =====\n",
    "print(\"=\"*60)\n",
    "print(\"Mask2Former 통합 학습 시작\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_blade_iou': [], 'val_blade_iou': [],\n",
    "    'train_damage_f1': [], 'val_damage_f1': []\n",
    "}\n",
    "best_score = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if epoch == config.unfreeze_epoch and config.freeze_blade_initially:\n",
    "        print(\"🔓 Unfreezing Blade Head for fine-tuning\")\n",
    "        for param in model.blade_head.parameters():\n",
    "            param.requires_grad = True\n",
    "        optimizer.add_param_group({\n",
    "            'params': model.blade_head.parameters(), \n",
    "            'lr': config.learning_rate * 0.1\n",
    "        })\n",
    "    \n",
    "    # Training\n",
    "    train_metrics = train_epoch(model, train_loader, criterion, optimizer, \n",
    "                               scheduler, scaler, config, epoch)\n",
    "    \n",
    "    # Validation\n",
    "    val_metrics = validate_epoch(model, valid_loader, criterion, config)\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_metrics['total'])\n",
    "    history['train_blade_iou'].append(train_metrics['blade_iou'])\n",
    "    history['train_damage_f1'].append(train_metrics['damage_f1'])\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_blade_iou'].append(val_metrics['blade_iou'])\n",
    "    history['val_damage_f1'].append(val_metrics['damage_f1'])\n",
    "    \n",
    "    # Combined score\n",
    "    combined_score = 0.4 * val_metrics['blade_iou'] + 0.6 * val_metrics['damage_f1']\n",
    "    \n",
    "    # Print detailed summary\n",
    "    print(f\"\\n📊 Epoch {epoch+1} Summary:\")\n",
    "    print(f\"  Train:\")\n",
    "    print(f\"    Loss: {train_metrics['total']:.4f}\")\n",
    "    print(f\"    Blade IoU: {train_metrics['blade_iou']:.4f}\")\n",
    "    print(f\"    Damage F1: {train_metrics['damage_f1']:.4f}\")\n",
    "    print(f\"  Valid:\")\n",
    "    print(f\"    Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"    Blade IoU: {val_metrics['blade_iou']:.4f}\")\n",
    "    print(f\"    Damage F1: {val_metrics['damage_f1']:.4f}\")\n",
    "    \n",
    "    # Per-class F1\n",
    "    damage_types = ['Crack', 'Nick', 'Tear']\n",
    "    for i, (f1, p, r) in enumerate(zip(val_metrics['per_class_f1'], \n",
    "                                       val_metrics['precision'], \n",
    "                                       val_metrics['recall'])):\n",
    "        print(f\"    {damage_types[i]}: F1={f1:.3f}, P={p:.3f}, R={r:.3f}\")\n",
    "    \n",
    "    print(f\"  Combined Score: {combined_score:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if combined_score > best_score:\n",
    "        best_score = combined_score\n",
    "        best_epoch = epoch\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_score': best_score,\n",
    "            'val_blade_iou': val_metrics['blade_iou'],\n",
    "            'val_damage_f1': val_metrics['damage_f1']\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, config.save_dir / f'{config.experiment_name}_best.pth')\n",
    "        print(f\"  ✅ Best model saved! (Score: {best_score:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"학습 완료! Best epoch: {best_epoch+1}, Best score: {best_score:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a65861",
   "metadata": {},
   "source": [
    "20250928 다시 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 1: 환경 설정 및 Import =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 프로젝트 경로 추가\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# 모델 import\n",
    "from models.unified.unified_model import UnifiedModel\n",
    "from models.heads.mask2former_damage_head import Mask2FormerLoss\n",
    "from utils.dataset import UnifiedDamageDataset, create_dataloaders\n",
    "from utils.evaluate import ModelEvaluator\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맨 위에 추가 (이미 import 했더라도)\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# 모듈 리로드\n",
    "if 'models.heads.mask2former_damage_head' in sys.modules:\n",
    "    del sys.modules['models.heads.mask2former_damage_head']\n",
    "\n",
    "from models.heads.mask2former_damage_head import Mask2FormerDamageHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a7f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 셀에서 직접 확인\n",
    "import torch\n",
    "\n",
    "# 테스트 데이터\n",
    "batch_size = 2\n",
    "dummy_features = [\n",
    "    torch.randn(batch_size, 256, 160, 160),\n",
    "    torch.randn(batch_size, 256, 80, 80),\n",
    "    torch.randn(batch_size, 256, 40, 40),\n",
    "    torch.randn(batch_size, 256, 20, 20)\n",
    "]\n",
    "\n",
    "# Shape만 확인\n",
    "print(\"Input feature shapes:\")\n",
    "for i, f in enumerate(dummy_features):\n",
    "    print(f\"  Level {i}: {f.shape}\")\n",
    "    elements = f.shape[2] * f.shape[3]\n",
    "    print(f\"    -> {f.shape[2]}x{f.shape[3]} = {elements} spatial elements\")\n",
    "\n",
    "# 예상되는 mask shape\n",
    "# 보통 첫 번째 레벨 크기를 따라감\n",
    "expected_mask_h, expected_mask_w = dummy_features[0].shape[2:]\n",
    "print(f\"\\nExpected mask shape: [batch, queries, {expected_mask_h}, {expected_mask_w}]\")\n",
    "print(f\"Total elements per mask: {expected_mask_h * expected_mask_w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3248d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNeXtFPN 문제를 우회하고 직접 테스트\n",
    "\n",
    "# 1. 더미 features 생성 (640x640 입력 기준)\n",
    "batch_size = 2\n",
    "dummy_features = [\n",
    "    torch.randn(batch_size, 256, 160, 160),  # 640/4 = 160\n",
    "    torch.randn(batch_size, 256, 80, 80),    # 640/8 = 80\n",
    "    torch.randn(batch_size, 256, 40, 40),    # 640/16 = 40\n",
    "    torch.randn(batch_size, 256, 20, 20)     # 640/32 = 20\n",
    "]\n",
    "\n",
    "print(\"=== 640x640 입력 → Backbone 예상 출력 ===\")\n",
    "for i, f in enumerate(dummy_features):\n",
    "    h, w = f.shape[-2:]\n",
    "    print(f\"Level {i}: {f.shape} -> {h}x{w} = {h*w} elements\")\n",
    "\n",
    "# 2. Mask2Former Head 직접 테스트\n",
    "from models.heads.mask2former_damage_head import Mask2FormerDamageHead\n",
    "\n",
    "mask2former_head = Mask2FormerDamageHead(\n",
    "    in_channels=256,\n",
    "    num_classes=3,\n",
    "    num_queries=100,\n",
    "    hidden_dim=256,\n",
    "    num_heads=8,\n",
    "    dec_layers=3,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(\"\\n=== Mask2Former Head 테스트 ===\")\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        # Head 통과\n",
    "        outputs = mask2former_head(dummy_features, blade_mask=batch.get('blade_mask'))\n",
    "        \n",
    "        print(\"출력:\")\n",
    "        for key, value in outputs.items():\n",
    "            if torch.is_tensor(value):\n",
    "                print(f\"  {key}: {value.shape}\")\n",
    "                \n",
    "                if key == 'pred_masks':\n",
    "                    h, w = value.shape[-2:]\n",
    "                    total = h * w\n",
    "                    print(f\"    -> {h}x{w} = {total} elements\")\n",
    "                    \n",
    "                    if total == 640000:\n",
    "                        print(\"    ⚠️ 800x800 발견! (문제의 원인)\")\n",
    "                    elif total == 409600:\n",
    "                        print(\"    ✓ 640x640 (정상)\")\n",
    "                    elif total == 102400:\n",
    "                        print(\"    ⚠️ 320x320\")\n",
    "                    elif total == 40000:\n",
    "                        print(\"    ⚠️ 200x200\")\n",
    "                    elif total == 25600:\n",
    "                        print(\"    ⚠️ 160x160\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"에러: {e}\")\n",
    "        \n",
    "# 3. Target과 비교\n",
    "print(\"\\n=== Target 크기 확인 ===\")\n",
    "if 'instance_masks' in batch:\n",
    "    print(f\"instance_masks: {batch['instance_masks'][0].shape}\")\n",
    "    h, w = batch['instance_masks'][0].shape[-2:]\n",
    "    print(f\"  -> {h}x{w} = {h*w} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf7db11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 Shape: {'image': torch.Size([2, 3, 640, 640]), 'blade_mask': torch.Size([2, 640, 640]), 'multilabel': torch.Size([2, 3]), 'instance_masks': 2, 'instance_labels': 2}\n",
      "mask_embed shape: torch.Size([2, 100, 256])\n",
      "mask_pred shape: torch.Size([2, 100, 160, 160])\n",
      "mask_pred spatial: H=160, W=160\n",
      "Total elements per mask: 25600\n",
      "⚠️ Unexpected resolution: 25600 elements\n",
      "\n",
      "=== Mask2Former 출력 ===\n",
      "pred_logits: torch.Size([2, 100, 4])\n",
      "pred_masks: torch.Size([2, 100, 160, 160])\n",
      "  -> 160x160 = 25600 elements\n",
      "multilabel: torch.Size([2, 3])\n",
      "\n",
      "=== Hungarian Loss 테스트 ===\n",
      "✅ 성공!\n",
      "Total loss: 8.9148\n",
      "Loss components: {'ce': 1.6377153396606445, 'mask': 0.734769880771637, 'dice': 0.9827669858932495}\n",
      "\n",
      "=== 크기 매칭 확인 ===\n",
      "Prediction: 160x160\n",
      "Target: 640x640\n",
      "⚠️ 크기 불일치 - 4.0배 업샘플링 필요\n"
     ]
    }
   ],
   "source": [
    "# ===== 셀 1: Import 및 설정 =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from utils.hungarian_loss import HungarianLoss\n",
    "from utils.hungarian_matcher import HungarianMatcherFixed\n",
    "from utils.dataset import create_dataloaders\n",
    "\n",
    "# ===== 셀 2: 데이터 로드 =====\n",
    "blade_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data')\n",
    "damage_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\multilabeled_data_augmented')\n",
    "\n",
    "train_loader, valid_loader, test_loader = create_dataloaders(\n",
    "    blade_data_root=blade_data_root,\n",
    "    damage_data_root=damage_data_root,\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    model_type='mask2former'\n",
    ")\n",
    "\n",
    "# batch 변수 정의 (중요!)\n",
    "batch = next(iter(train_loader))\n",
    "print(\"데이터 Shape:\", {k: v.shape if torch.is_tensor(v) else len(v) for k, v in batch.items()})\n",
    "\n",
    "# ===== 셀 3: SimplePixelDecoder 정의 =====\n",
    "class SimplePixelDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(256, 256, 1)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        # 일단 160x160 그대로 (나중에 업샘플링 추가)\n",
    "        mask_features = self.conv(features[0])\n",
    "        return mask_features, features[:3]\n",
    "\n",
    "# ===== 셀 4: Mask2Former 테스트 =====\n",
    "from models.heads.mask2former_damage_head import Mask2FormerDamageHead\n",
    "\n",
    "# Mask2Former 생성\n",
    "mask2former = Mask2FormerDamageHead(\n",
    "    in_channels=256,\n",
    "    num_classes=3,\n",
    "    num_queries=100\n",
    ")\n",
    "\n",
    "# MSDeformAttnPixelDecoder 대체\n",
    "mask2former.pixel_decoder = SimplePixelDecoder()\n",
    "\n",
    "# 더미 features\n",
    "dummy_features = [\n",
    "    torch.randn(2, 256, 160, 160),\n",
    "    torch.randn(2, 256, 80, 80),\n",
    "    torch.randn(2, 256, 40, 40),\n",
    "    torch.randn(2, 256, 20, 20)\n",
    "]\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = mask2former(dummy_features)\n",
    "    \n",
    "print(\"\\n=== Mask2Former 출력 ===\")\n",
    "for k, v in outputs.items():\n",
    "    if torch.is_tensor(v):\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "        if k == 'pred_masks':\n",
    "            h, w = v.shape[-2:]\n",
    "            print(f\"  -> {h}x{w} = {h*w} elements\")\n",
    "\n",
    "# ===== 셀 5: Hungarian Loss 테스트 =====\n",
    "print(\"\\n=== Hungarian Loss 테스트 ===\")\n",
    "\n",
    "criterion = HungarianLoss(num_classes=3)\n",
    "\n",
    "try:\n",
    "    loss, loss_dict = criterion(outputs, batch)\n",
    "    print(f\"✅ 성공!\")\n",
    "    print(f\"Total loss: {loss.item():.4f}\")\n",
    "    print(\"Loss components:\", {k: v.item() if torch.is_tensor(v) else v for k, v in loss_dict.items()})\n",
    "except Exception as e:\n",
    "    print(f\"❌ 에러: {e}\")\n",
    "    \n",
    "    # 디버깅 정보\n",
    "    print(\"\\n디버깅 정보:\")\n",
    "    print(f\"outputs keys: {outputs.keys()}\")\n",
    "    print(f\"batch keys: {batch.keys()}\")\n",
    "    \n",
    "    if 'instance_masks' in batch:\n",
    "        print(f\"instance_masks[0]: {batch['instance_masks'][0].shape}\")\n",
    "        print(f\"pred_masks: {outputs['pred_masks'].shape}\")\n",
    "\n",
    "# ===== 셀 6: 크기 문제 해결 확인 =====\n",
    "print(\"\\n=== 크기 매칭 확인 ===\")\n",
    "pred_h, pred_w = outputs['pred_masks'].shape[-2:]\n",
    "tgt_h, tgt_w = batch['instance_masks'][0].shape[-2:]\n",
    "\n",
    "print(f\"Prediction: {pred_h}x{pred_w}\")\n",
    "print(f\"Target: {tgt_h}x{tgt_w}\")\n",
    "\n",
    "if pred_h != tgt_h:\n",
    "    print(f\"⚠️ 크기 불일치 - {tgt_h/pred_h}배 업샘플링 필요\")\n",
    "else:\n",
    "    print(\"✅ 크기 일치!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b7caf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 파라미터 수: 24.690439 M\n",
      "\n",
      "=== 개선된 Mask2Former 출력 ===\n",
      "pred_logits: torch.Size([2, 100, 4])\n",
      "pred_masks: torch.Size([2, 100, 640, 640])\n",
      "  -> Resolution: 640x640 = 409600 pixels\n",
      "  ✅ 640x640 달성!\n",
      "multilabel: torch.Size([2, 3])\n",
      "\n",
      "=== Hungarian Loss 결과 ===\n",
      "Total loss: 4.8094\n",
      "  ce: 0.7768\n",
      "  mask: 0.2529\n",
      "  dice: 0.9958\n",
      "✅ Hungarian matching 성공!\n",
      "\n",
      "메모리 사용량: 2.39 GB\n"
     ]
    }
   ],
   "source": [
    "# ===== Jupyter Notebook 테스트: 개선된 Mask2Former =====\n",
    "\n",
    "# 셀 1: 파일 재로드\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# 기존 모듈 제거\n",
    "if 'models.heads.mask2former_damage_head' in sys.modules:\n",
    "    del sys.modules['models.heads.mask2former_damage_head']\n",
    "\n",
    "# 다시 import\n",
    "from models.heads.mask2former_damage_head import Mask2FormerDamageHead\n",
    "\n",
    "# 셀 2: 모델 생성 및 테스트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Mask2Former 생성 (개선된 버전)\n",
    "mask2former = Mask2FormerDamageHead(\n",
    "    in_channels=256,\n",
    "    num_classes=3,\n",
    "    num_queries=100,  # 줄임\n",
    "    hidden_dim=256,\n",
    "    num_heads=8,\n",
    "    dec_layers=3,  # 줄임\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(\"모델 파라미터 수:\", sum(p.numel() for p in mask2former.parameters()) / 1e6, \"M\")\n",
    "\n",
    "# 셀 3: 더미 데이터로 Forward Pass 테스트\n",
    "dummy_features = [\n",
    "    torch.randn(2, 256, 160, 160),\n",
    "    torch.randn(2, 256, 80, 80),\n",
    "    torch.randn(2, 256, 40, 40),\n",
    "    torch.randn(2, 256, 20, 20)\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = mask2former(dummy_features)\n",
    "\n",
    "print(\"\\n=== 개선된 Mask2Former 출력 ===\")\n",
    "for k, v in outputs.items():\n",
    "    if torch.is_tensor(v):\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "        if k == 'pred_masks':\n",
    "            h, w = v.shape[-2:]\n",
    "            print(f\"  -> Resolution: {h}x{w} = {h*w} pixels\")\n",
    "            if h*w == 409600:\n",
    "                print(\"  ✅ 640x640 달성!\")\n",
    "\n",
    "# 셀 4: 실제 데이터로 테스트\n",
    "from utils.dataset import create_dataloaders\n",
    "from pathlib import Path\n",
    "\n",
    "blade_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data')\n",
    "damage_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\multilabeled_data_augmented')\n",
    "\n",
    "train_loader, _, _ = create_dataloaders(\n",
    "    blade_data_root=blade_data_root,\n",
    "    damage_data_root=damage_data_root,\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    model_type='mask2former'\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# 셀 5: Hungarian Loss 테스트\n",
    "from utils.hungarian_loss import HungarianLoss\n",
    "\n",
    "criterion = HungarianLoss(num_classes=3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = mask2former(dummy_features)\n",
    "    \n",
    "try:\n",
    "    loss, loss_dict = criterion(outputs, batch)\n",
    "    print(\"\\n=== Hungarian Loss 결과 ===\")\n",
    "    print(f\"Total loss: {loss.item():.4f}\")\n",
    "    for k, v in loss_dict.items():\n",
    "        print(f\"  {k}: {v.item():.4f}\")\n",
    "    print(\"✅ Hungarian matching 성공!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 에러: {e}\")\n",
    "\n",
    "# 셀 6: 메모리 사용량 확인\n",
    "if torch.cuda.is_available():\n",
    "    mask2former = mask2former.cuda()\n",
    "    dummy_features_cuda = [f.cuda() for f in dummy_features]\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    with torch.no_grad():\n",
    "        outputs = mask2former(dummy_features_cuda)\n",
    "    \n",
    "    memory_used = torch.cuda.max_memory_allocated() / 1e9\n",
    "    print(f\"\\n메모리 사용량: {memory_used:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecab4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
