{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì…€ 1: í™˜ê²½ ì„¤ì • ë° Import =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# ëª¨ë¸ import\n",
    "from models.unified.unified_model import UnifiedModel\n",
    "from models.heads.mask2former_damage_head import Mask2FormerLoss\n",
    "from utils.dataset import UnifiedDamageDataset, create_dataloaders\n",
    "from utils.evaluate import ModelEvaluator\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì…€ 2: Mask2Former ì„¤ì • =====\n",
    "class Config:\n",
    "    # ë°ì´í„° ê²½ë¡œ - ë¶„ë¦¬ëœ ê²½ë¡œ\n",
    "    blade_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data')  # Head-Aìš©\n",
    "    damage_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\multilabeled_data_augmented')  # Head-Bìš©\n",
    "    \n",
    "    blade_checkpoint = 'best_unified_blade_model.pth'\n",
    "    \n",
    "    # ëª¨ë¸ íƒ€ì…\n",
    "    model_type = 'mask2former'\n",
    "    \n",
    "    # ëª¨ë¸ ê¸°ë³¸ ì„¤ì •\n",
    "    backbone_type = 'tiny'\n",
    "    use_fpn = True\n",
    "    num_blade_classes = 2\n",
    "    num_damage_classes = 3\n",
    "    \n",
    "    # Mask2Former íŠ¹í™” ì„¤ì •\n",
    "    batch_size = 2  # ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "    accumulate_grad_batches = 2  # Gradient accumulation\n",
    "    num_workers = 0\n",
    "    \n",
    "    # Mask2Former Head ì„¤ì •\n",
    "    mask2former_config = {\n",
    "        'num_queries': 100,  # ì²˜ìŒì—” ì ê²Œ\n",
    "        'hidden_dim': 256,\n",
    "        'num_heads': 8,\n",
    "        'dec_layers': 3,  # ì²˜ìŒì—” ì ì€ ë ˆì´ì–´\n",
    "        'dropout': 0.1\n",
    "    }\n",
    "    \n",
    "    # í•™ìŠµ ì„¤ì •\n",
    "    epochs = 30\n",
    "    learning_rate = 1e-5  # Mask2FormerëŠ” ì‘ì€ lr\n",
    "    weight_decay = 0.05\n",
    "    gradient_clip = 0.01  # ì‘ì€ gradient clipping\n",
    "    \n",
    "    # Mixed Precision Training\n",
    "    use_amp = True\n",
    "    \n",
    "    # í•™ìŠµ ì „ëµ\n",
    "    freeze_blade_initially = True\n",
    "    unfreeze_epoch = 15\n",
    "    \n",
    "    # Loss weights\n",
    "    blade_loss_weight = 1.0\n",
    "    aux_loss_weight = 0.4\n",
    "    \n",
    "    # ê¸°íƒ€\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    save_dir = Path('outputs_mask2former')\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    experiment_name = f\"mask2former_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "config = Config()\n",
    "print(f\"Experiment: {config.experiment_name}\")\n",
    "print(f\"Model Type: {config.model_type}\")\n",
    "print(f\"Batch Size: {config.batch_size} x {config.accumulate_grad_batches} = {config.batch_size * config.accumulate_grad_batches}\")\n",
    "print(f\"Blade Data: {config.blade_data_root}\")\n",
    "print(f\"Damage Data: {config.damage_data_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì…€ 3: ë°ì´í„°ë¡œë” ìƒì„± =====\n",
    "print(\"ë°ì´í„°ë¡œë” ìƒì„± ì¤‘...\")\n",
    "\n",
    "train_loader, valid_loader, test_loader = create_dataloaders(\n",
    "    blade_data_root=config.blade_data_root,\n",
    "    damage_data_root=config.damage_data_root,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    model_type='mask2former'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Train: {len(train_loader)} batches\")\n",
    "print(f\"âœ… Valid: {len(valid_loader)} batches\")\n",
    "print(f\"âœ… Test: {len(test_loader)} batches\")\n",
    "\n",
    "# ë°ì´í„° ìƒ˜í”Œ í™•ì¸\n",
    "for batch in train_loader:\n",
    "    print(f\"\\në°ì´í„° ìƒ˜í”Œ:\")\n",
    "    for key, value in batch.items():\n",
    "        if torch.is_tensor(value):\n",
    "            print(f\"  {key}: {value.shape}\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"  {key}: {len(value)} items\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì…€ 4: Mask2Former ëª¨ë¸ ìƒì„± =====\n",
    "print(\"Mask2Former ëª¨ë¸ ìƒì„± ì¤‘...\")\n",
    "\n",
    "model = UnifiedModel(\n",
    "    backbone_type=config.backbone_type,\n",
    "    num_blade_classes=config.num_blade_classes,\n",
    "    num_damage_classes=config.num_damage_classes,\n",
    "    pretrained_backbone=True,\n",
    "    blade_checkpoint=config.blade_checkpoint if Path(config.blade_checkpoint).exists() else None,\n",
    "    freeze_blade=config.freeze_blade_initially,\n",
    "    use_fpn=config.use_fpn,\n",
    "    damage_head_type='mask2former',\n",
    "    damage_head_config=config.mask2former_config\n",
    ")\n",
    "\n",
    "model = model.to(config.device)\n",
    "\n",
    "# íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"âœ… Total parameters: {total_params/1e6:.2f}M\")\n",
    "print(f\"âœ… Trainable parameters: {trainable_params/1e6:.2f}M\")\n",
    "print(f\"âœ… Blade head frozen: {config.freeze_blade_initially}\")\n",
    "print(f\"âœ… Damage head type: Mask2Former\")\n",
    "print(f\"  - Queries: {config.mask2former_config['num_queries']}\")\n",
    "print(f\"  - Decoder layers: {config.mask2former_config['dec_layers']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì…€ 5 ì¬ì •ì˜: autocast ì•ˆì „í•œ Loss =====\n",
    "class SimpleLoss(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.blade_ce = nn.CrossEntropyLoss()\n",
    "        self.ml_loss = nn.BCEWithLogitsLoss()  # í•­ìƒ ì´ê²ƒë§Œ ì‚¬ìš©\n",
    "    \n",
    "    def forward(self, outputs, batch):\n",
    "        losses = {}\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Blade loss\n",
    "        if 'blade' in outputs and 'blade_mask' in batch:\n",
    "            losses['blade'] = self.blade_ce(outputs['blade'], batch['blade_mask'])\n",
    "            total_loss += losses['blade'] * self.config.blade_loss_weight\n",
    "        \n",
    "        # Multilabel loss - í•­ìƒ BCEWithLogitsLoss ì‚¬ìš©\n",
    "        if 'multilabel' in outputs and 'multilabel' in batch:\n",
    "            # multilabel ì¶œë ¥ì´ ì´ë¯¸ sigmoidë¥¼ ê±°ì³¤ë‹¤ë©´ logitìœ¼ë¡œ ì—­ë³€í™˜\n",
    "            ml_output = outputs['multilabel']\n",
    "            if ml_output.min() >= 0 and ml_output.max() <= 1:\n",
    "                # sigmoid ì—­ë³€í™˜: logit = log(p / (1-p))\n",
    "                eps = 1e-7\n",
    "                ml_output = torch.log((ml_output + eps) / (1 - ml_output + eps))\n",
    "            \n",
    "            losses['ml'] = self.ml_loss(ml_output, batch['multilabel'])\n",
    "            total_loss += losses['ml'] * 2.0\n",
    "        \n",
    "        losses['total'] = total_loss\n",
    "        return total_loss, losses\n",
    "\n",
    "criterion = SimpleLoss(config)\n",
    "print(\"âœ… SimpleLoss ready - autocast safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab67d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì…€ 6: Optimizer =====\n",
    "param_groups = [\n",
    "    {'params': model.backbone.parameters(), 'lr': config.learning_rate * 0.1, 'name': 'backbone'}\n",
    "]\n",
    "\n",
    "# Damage head parameters\n",
    "for name, param in model.damage_head.named_parameters():\n",
    "    param_groups.append({'params': [param], 'lr': config.learning_rate, 'name': 'damage_head'})\n",
    "\n",
    "if not config.freeze_blade_initially:\n",
    "    param_groups.append({'params': model.blade_head.parameters(), 'lr': config.learning_rate * 0.5, 'name': 'blade_head'})\n",
    "\n",
    "optimizer = torch.optim.AdamW(param_groups[:2], weight_decay=config.weight_decay)  # ì²˜ìŒ 2ê°œ ê·¸ë£¹ë§Œ\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs, eta_min=1e-7)\n",
    "scaler = GradScaler() if config.use_amp else None\n",
    "\n",
    "print(f\"âœ… Optimizer ready with {len(param_groups[:2])} groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfacb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì…€ 7: Improved Training Functions =====\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scheduler, scaler, config, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': 0,\n",
    "        'blade_iou': 0,\n",
    "        'damage_f1': 0,\n",
    "        'num_batches': 0\n",
    "    }\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.epochs}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        # Move to device\n",
    "        for key in batch:\n",
    "            if torch.is_tensor(batch[key]):\n",
    "                batch[key] = batch[key].to(config.device)\n",
    "            elif isinstance(batch[key], list):\n",
    "                batch[key] = [item.to(config.device) if torch.is_tensor(item) else item \n",
    "                             for item in batch[key]]\n",
    "        \n",
    "        with autocast(enabled=config.use_amp):\n",
    "            outputs = model(batch['image'])\n",
    "            loss, loss_dict = criterion(outputs, batch)\n",
    "            loss = loss / config.accumulate_grad_batches\n",
    "        \n",
    "        # Backward\n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        \n",
    "        # Optimizer step\n",
    "        if (batch_idx + 1) % config.accumulate_grad_batches == 0:\n",
    "            if scaler:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            # Blade IoU\n",
    "            if 'blade' in outputs and 'blade_mask' in batch:\n",
    "                blade_pred = outputs['blade'].argmax(1)\n",
    "                intersection = (blade_pred & batch['blade_mask']).float().sum()\n",
    "                union = (blade_pred | batch['blade_mask']).float().sum()\n",
    "                blade_iou = (intersection / (union + 1e-6)).item()\n",
    "                metrics['blade_iou'] += blade_iou\n",
    "            \n",
    "            # Damage F1\n",
    "            if 'multilabel' in outputs and 'multilabel' in batch:\n",
    "                ml_output = outputs['multilabel']\n",
    "                if ml_output.min() >= 0 and ml_output.max() <= 1:\n",
    "                    pred = (ml_output > 0.5).float()\n",
    "                else:\n",
    "                    pred = (torch.sigmoid(ml_output) > 0.5).float()\n",
    "                \n",
    "                tp = (pred * batch['multilabel']).sum()\n",
    "                fp = (pred * (1 - batch['multilabel'])).sum()\n",
    "                fn = ((1 - pred) * batch['multilabel']).sum()\n",
    "                \n",
    "                f1 = (2 * tp / (2 * tp + fp + fn + 1e-6)).item()\n",
    "                metrics['damage_f1'] += f1\n",
    "        \n",
    "        metrics['loss'] += loss.item() * config.accumulate_grad_batches\n",
    "        metrics['num_batches'] += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        avg_blade_iou = metrics['blade_iou'] / max(1, metrics['num_batches'])\n",
    "        avg_damage_f1 = metrics['damage_f1'] / max(1, metrics['num_batches'])\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{loss.item() * config.accumulate_grad_batches:.4f}\",\n",
    "            'blade_iou': f\"{avg_blade_iou:.3f}\",\n",
    "            'damage_f1': f\"{avg_damage_f1:.3f}\",\n",
    "            'lr': f\"{optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        })\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    return {\n",
    "        'total': metrics['loss'] / metrics['num_batches'],\n",
    "        'blade_iou': metrics['blade_iou'] / metrics['num_batches'],\n",
    "        'damage_f1': metrics['damage_f1'] / metrics['num_batches']\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_epoch(model, valid_loader, criterion, config):\n",
    "    model.eval()\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': 0,\n",
    "        'blade_iou': 0,\n",
    "        'damage_tp': torch.zeros(3).to(config.device),\n",
    "        'damage_fp': torch.zeros(3).to(config.device),\n",
    "        'damage_fn': torch.zeros(3).to(config.device),\n",
    "        'num_batches': 0\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc='Validation'):\n",
    "            for key in batch:\n",
    "                if torch.is_tensor(batch[key]):\n",
    "                    batch[key] = batch[key].to(config.device)\n",
    "                elif isinstance(batch[key], list):\n",
    "                    batch[key] = [item.to(config.device) if torch.is_tensor(item) else item \n",
    "                                 for item in batch[key]]\n",
    "            \n",
    "            outputs = model(batch['image'])\n",
    "            loss, _ = criterion(outputs, batch)\n",
    "            metrics['loss'] += loss.item()\n",
    "            \n",
    "            # Blade IoU\n",
    "            if 'blade' in outputs and 'blade_mask' in batch:\n",
    "                blade_pred = outputs['blade'].argmax(1)\n",
    "                intersection = (blade_pred & batch['blade_mask']).float().sum()\n",
    "                union = (blade_pred | batch['blade_mask']).float().sum()\n",
    "                metrics['blade_iou'] += (intersection / (union + 1e-6)).item()\n",
    "            \n",
    "            # Damage metrics\n",
    "            if 'multilabel' in outputs and 'multilabel' in batch:\n",
    "                ml_output = outputs['multilabel']\n",
    "                if ml_output.min() >= 0 and ml_output.max() <= 1:\n",
    "                    pred = (ml_output > 0.5).float()\n",
    "                else:\n",
    "                    pred = (torch.sigmoid(ml_output) > 0.5).float()\n",
    "                \n",
    "                metrics['damage_tp'] += (pred * batch['multilabel']).sum(dim=0)\n",
    "                metrics['damage_fp'] += (pred * (1 - batch['multilabel'])).sum(dim=0)\n",
    "                metrics['damage_fn'] += ((1 - pred) * batch['multilabel']).sum(dim=0)\n",
    "            \n",
    "            metrics['num_batches'] += 1\n",
    "    \n",
    "    # Calculate F1 scores\n",
    "    precision = metrics['damage_tp'] / (metrics['damage_tp'] + metrics['damage_fp'] + 1e-6)\n",
    "    recall = metrics['damage_tp'] / (metrics['damage_tp'] + metrics['damage_fn'] + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    \n",
    "    return {\n",
    "        'loss': metrics['loss'] / metrics['num_batches'],\n",
    "        'blade_iou': metrics['blade_iou'] / metrics['num_batches'],\n",
    "        'damage_f1': f1.mean().item(),\n",
    "        'per_class_f1': f1.cpu().numpy(),\n",
    "        'precision': precision.cpu().numpy(),\n",
    "        'recall': recall.cpu().numpy()\n",
    "    }\n",
    "\n",
    "print(\"âœ… Training functions with full metrics ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì…€ 8: Improved Training Loop =====\n",
    "print(\"=\"*60)\n",
    "print(\"Mask2Former í†µí•© í•™ìŠµ ì‹œì‘\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_blade_iou': [], 'val_blade_iou': [],\n",
    "    'train_damage_f1': [], 'val_damage_f1': []\n",
    "}\n",
    "best_score = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if epoch == config.unfreeze_epoch and config.freeze_blade_initially:\n",
    "        print(\"ğŸ”“ Unfreezing Blade Head for fine-tuning\")\n",
    "        for param in model.blade_head.parameters():\n",
    "            param.requires_grad = True\n",
    "        optimizer.add_param_group({\n",
    "            'params': model.blade_head.parameters(), \n",
    "            'lr': config.learning_rate * 0.1\n",
    "        })\n",
    "    \n",
    "    # Training\n",
    "    train_metrics = train_epoch(model, train_loader, criterion, optimizer, \n",
    "                               scheduler, scaler, config, epoch)\n",
    "    \n",
    "    # Validation\n",
    "    val_metrics = validate_epoch(model, valid_loader, criterion, config)\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_metrics['total'])\n",
    "    history['train_blade_iou'].append(train_metrics['blade_iou'])\n",
    "    history['train_damage_f1'].append(train_metrics['damage_f1'])\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_blade_iou'].append(val_metrics['blade_iou'])\n",
    "    history['val_damage_f1'].append(val_metrics['damage_f1'])\n",
    "    \n",
    "    # Combined score\n",
    "    combined_score = 0.4 * val_metrics['blade_iou'] + 0.6 * val_metrics['damage_f1']\n",
    "    \n",
    "    # Print detailed summary\n",
    "    print(f\"\\nğŸ“Š Epoch {epoch+1} Summary:\")\n",
    "    print(f\"  Train:\")\n",
    "    print(f\"    Loss: {train_metrics['total']:.4f}\")\n",
    "    print(f\"    Blade IoU: {train_metrics['blade_iou']:.4f}\")\n",
    "    print(f\"    Damage F1: {train_metrics['damage_f1']:.4f}\")\n",
    "    print(f\"  Valid:\")\n",
    "    print(f\"    Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"    Blade IoU: {val_metrics['blade_iou']:.4f}\")\n",
    "    print(f\"    Damage F1: {val_metrics['damage_f1']:.4f}\")\n",
    "    \n",
    "    # Per-class F1\n",
    "    damage_types = ['Crack', 'Nick', 'Tear']\n",
    "    for i, (f1, p, r) in enumerate(zip(val_metrics['per_class_f1'], \n",
    "                                       val_metrics['precision'], \n",
    "                                       val_metrics['recall'])):\n",
    "        print(f\"    {damage_types[i]}: F1={f1:.3f}, P={p:.3f}, R={r:.3f}\")\n",
    "    \n",
    "    print(f\"  Combined Score: {combined_score:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if combined_score > best_score:\n",
    "        best_score = combined_score\n",
    "        best_epoch = epoch\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_score': best_score,\n",
    "            'val_blade_iou': val_metrics['blade_iou'],\n",
    "            'val_damage_f1': val_metrics['damage_f1']\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, config.save_dir / f'{config.experiment_name}_best.pth')\n",
    "        print(f\"  âœ… Best model saved! (Score: {best_score:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"í•™ìŠµ ì™„ë£Œ! Best epoch: {best_epoch+1}, Best score: {best_score:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a65861",
   "metadata": {},
   "source": [
    "20250928 ë‹¤ì‹œ ì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ì…€ 1: í™˜ê²½ ì„¤ì • ë° Import =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# ëª¨ë¸ import\n",
    "from models.unified.unified_model import UnifiedModel\n",
    "from models.heads.mask2former_damage_head import Mask2FormerLoss\n",
    "from utils.dataset import UnifiedDamageDataset, create_dataloaders\n",
    "from utils.evaluate import ModelEvaluator\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§¨ ìœ„ì— ì¶”ê°€ (ì´ë¯¸ import í–ˆë”ë¼ë„)\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# ëª¨ë“ˆ ë¦¬ë¡œë“œ\n",
    "if 'models.heads.mask2former_damage_head' in sys.modules:\n",
    "    del sys.modules['models.heads.mask2former_damage_head']\n",
    "\n",
    "from models.heads.mask2former_damage_head import Mask2FormerDamageHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a7f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook ì…€ì—ì„œ ì§ì ‘ í™•ì¸\n",
    "import torch\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "batch_size = 2\n",
    "dummy_features = [\n",
    "    torch.randn(batch_size, 256, 160, 160),\n",
    "    torch.randn(batch_size, 256, 80, 80),\n",
    "    torch.randn(batch_size, 256, 40, 40),\n",
    "    torch.randn(batch_size, 256, 20, 20)\n",
    "]\n",
    "\n",
    "# Shapeë§Œ í™•ì¸\n",
    "print(\"Input feature shapes:\")\n",
    "for i, f in enumerate(dummy_features):\n",
    "    print(f\"  Level {i}: {f.shape}\")\n",
    "    elements = f.shape[2] * f.shape[3]\n",
    "    print(f\"    -> {f.shape[2]}x{f.shape[3]} = {elements} spatial elements\")\n",
    "\n",
    "# ì˜ˆìƒë˜ëŠ” mask shape\n",
    "# ë³´í†µ ì²« ë²ˆì§¸ ë ˆë²¨ í¬ê¸°ë¥¼ ë”°ë¼ê°\n",
    "expected_mask_h, expected_mask_w = dummy_features[0].shape[2:]\n",
    "print(f\"\\nExpected mask shape: [batch, queries, {expected_mask_h}, {expected_mask_w}]\")\n",
    "print(f\"Total elements per mask: {expected_mask_h * expected_mask_w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3248d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNeXtFPN ë¬¸ì œë¥¼ ìš°íšŒí•˜ê³  ì§ì ‘ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "# 1. ë”ë¯¸ features ìƒì„± (640x640 ì…ë ¥ ê¸°ì¤€)\n",
    "batch_size = 2\n",
    "dummy_features = [\n",
    "    torch.randn(batch_size, 256, 160, 160),  # 640/4 = 160\n",
    "    torch.randn(batch_size, 256, 80, 80),    # 640/8 = 80\n",
    "    torch.randn(batch_size, 256, 40, 40),    # 640/16 = 40\n",
    "    torch.randn(batch_size, 256, 20, 20)     # 640/32 = 20\n",
    "]\n",
    "\n",
    "print(\"=== 640x640 ì…ë ¥ â†’ Backbone ì˜ˆìƒ ì¶œë ¥ ===\")\n",
    "for i, f in enumerate(dummy_features):\n",
    "    h, w = f.shape[-2:]\n",
    "    print(f\"Level {i}: {f.shape} -> {h}x{w} = {h*w} elements\")\n",
    "\n",
    "# 2. Mask2Former Head ì§ì ‘ í…ŒìŠ¤íŠ¸\n",
    "from models.heads.mask2former_damage_head import Mask2FormerDamageHead\n",
    "\n",
    "mask2former_head = Mask2FormerDamageHead(\n",
    "    in_channels=256,\n",
    "    num_classes=3,\n",
    "    num_queries=100,\n",
    "    hidden_dim=256,\n",
    "    num_heads=8,\n",
    "    dec_layers=3,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(\"\\n=== Mask2Former Head í…ŒìŠ¤íŠ¸ ===\")\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        # Head í†µê³¼\n",
    "        outputs = mask2former_head(dummy_features, blade_mask=batch.get('blade_mask'))\n",
    "        \n",
    "        print(\"ì¶œë ¥:\")\n",
    "        for key, value in outputs.items():\n",
    "            if torch.is_tensor(value):\n",
    "                print(f\"  {key}: {value.shape}\")\n",
    "                \n",
    "                if key == 'pred_masks':\n",
    "                    h, w = value.shape[-2:]\n",
    "                    total = h * w\n",
    "                    print(f\"    -> {h}x{w} = {total} elements\")\n",
    "                    \n",
    "                    if total == 640000:\n",
    "                        print(\"    âš ï¸ 800x800 ë°œê²¬! (ë¬¸ì œì˜ ì›ì¸)\")\n",
    "                    elif total == 409600:\n",
    "                        print(\"    âœ“ 640x640 (ì •ìƒ)\")\n",
    "                    elif total == 102400:\n",
    "                        print(\"    âš ï¸ 320x320\")\n",
    "                    elif total == 40000:\n",
    "                        print(\"    âš ï¸ 200x200\")\n",
    "                    elif total == 25600:\n",
    "                        print(\"    âš ï¸ 160x160\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"ì—ëŸ¬: {e}\")\n",
    "        \n",
    "# 3. Targetê³¼ ë¹„êµ\n",
    "print(\"\\n=== Target í¬ê¸° í™•ì¸ ===\")\n",
    "if 'instance_masks' in batch:\n",
    "    print(f\"instance_masks: {batch['instance_masks'][0].shape}\")\n",
    "    h, w = batch['instance_masks'][0].shape[-2:]\n",
    "    print(f\"  -> {h}x{w} = {h*w} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf7db11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° Shape: {'image': torch.Size([2, 3, 640, 640]), 'blade_mask': torch.Size([2, 640, 640]), 'multilabel': torch.Size([2, 3]), 'instance_masks': 2, 'instance_labels': 2}\n",
      "mask_embed shape: torch.Size([2, 100, 256])\n",
      "mask_pred shape: torch.Size([2, 100, 160, 160])\n",
      "mask_pred spatial: H=160, W=160\n",
      "Total elements per mask: 25600\n",
      "âš ï¸ Unexpected resolution: 25600 elements\n",
      "\n",
      "=== Mask2Former ì¶œë ¥ ===\n",
      "pred_logits: torch.Size([2, 100, 4])\n",
      "pred_masks: torch.Size([2, 100, 160, 160])\n",
      "  -> 160x160 = 25600 elements\n",
      "multilabel: torch.Size([2, 3])\n",
      "\n",
      "=== Hungarian Loss í…ŒìŠ¤íŠ¸ ===\n",
      "âœ… ì„±ê³µ!\n",
      "Total loss: 8.9148\n",
      "Loss components: {'ce': 1.6377153396606445, 'mask': 0.734769880771637, 'dice': 0.9827669858932495}\n",
      "\n",
      "=== í¬ê¸° ë§¤ì¹­ í™•ì¸ ===\n",
      "Prediction: 160x160\n",
      "Target: 640x640\n",
      "âš ï¸ í¬ê¸° ë¶ˆì¼ì¹˜ - 4.0ë°° ì—…ìƒ˜í”Œë§ í•„ìš”\n"
     ]
    }
   ],
   "source": [
    "# ===== ì…€ 1: Import ë° ì„¤ì • =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from utils.hungarian_loss import HungarianLoss\n",
    "from utils.hungarian_matcher import HungarianMatcherFixed\n",
    "from utils.dataset import create_dataloaders\n",
    "\n",
    "# ===== ì…€ 2: ë°ì´í„° ë¡œë“œ =====\n",
    "blade_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data')\n",
    "damage_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\multilabeled_data_augmented')\n",
    "\n",
    "train_loader, valid_loader, test_loader = create_dataloaders(\n",
    "    blade_data_root=blade_data_root,\n",
    "    damage_data_root=damage_data_root,\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    model_type='mask2former'\n",
    ")\n",
    "\n",
    "# batch ë³€ìˆ˜ ì •ì˜ (ì¤‘ìš”!)\n",
    "batch = next(iter(train_loader))\n",
    "print(\"ë°ì´í„° Shape:\", {k: v.shape if torch.is_tensor(v) else len(v) for k, v in batch.items()})\n",
    "\n",
    "# ===== ì…€ 3: SimplePixelDecoder ì •ì˜ =====\n",
    "class SimplePixelDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(256, 256, 1)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        # ì¼ë‹¨ 160x160 ê·¸ëŒ€ë¡œ (ë‚˜ì¤‘ì— ì—…ìƒ˜í”Œë§ ì¶”ê°€)\n",
    "        mask_features = self.conv(features[0])\n",
    "        return mask_features, features[:3]\n",
    "\n",
    "# ===== ì…€ 4: Mask2Former í…ŒìŠ¤íŠ¸ =====\n",
    "from models.heads.mask2former_damage_head import Mask2FormerDamageHead\n",
    "\n",
    "# Mask2Former ìƒì„±\n",
    "mask2former = Mask2FormerDamageHead(\n",
    "    in_channels=256,\n",
    "    num_classes=3,\n",
    "    num_queries=100\n",
    ")\n",
    "\n",
    "# MSDeformAttnPixelDecoder ëŒ€ì²´\n",
    "mask2former.pixel_decoder = SimplePixelDecoder()\n",
    "\n",
    "# ë”ë¯¸ features\n",
    "dummy_features = [\n",
    "    torch.randn(2, 256, 160, 160),\n",
    "    torch.randn(2, 256, 80, 80),\n",
    "    torch.randn(2, 256, 40, 40),\n",
    "    torch.randn(2, 256, 20, 20)\n",
    "]\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = mask2former(dummy_features)\n",
    "    \n",
    "print(\"\\n=== Mask2Former ì¶œë ¥ ===\")\n",
    "for k, v in outputs.items():\n",
    "    if torch.is_tensor(v):\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "        if k == 'pred_masks':\n",
    "            h, w = v.shape[-2:]\n",
    "            print(f\"  -> {h}x{w} = {h*w} elements\")\n",
    "\n",
    "# ===== ì…€ 5: Hungarian Loss í…ŒìŠ¤íŠ¸ =====\n",
    "print(\"\\n=== Hungarian Loss í…ŒìŠ¤íŠ¸ ===\")\n",
    "\n",
    "criterion = HungarianLoss(num_classes=3)\n",
    "\n",
    "try:\n",
    "    loss, loss_dict = criterion(outputs, batch)\n",
    "    print(f\"âœ… ì„±ê³µ!\")\n",
    "    print(f\"Total loss: {loss.item():.4f}\")\n",
    "    print(\"Loss components:\", {k: v.item() if torch.is_tensor(v) else v for k, v in loss_dict.items()})\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì—ëŸ¬: {e}\")\n",
    "    \n",
    "    # ë””ë²„ê¹… ì •ë³´\n",
    "    print(\"\\në””ë²„ê¹… ì •ë³´:\")\n",
    "    print(f\"outputs keys: {outputs.keys()}\")\n",
    "    print(f\"batch keys: {batch.keys()}\")\n",
    "    \n",
    "    if 'instance_masks' in batch:\n",
    "        print(f\"instance_masks[0]: {batch['instance_masks'][0].shape}\")\n",
    "        print(f\"pred_masks: {outputs['pred_masks'].shape}\")\n",
    "\n",
    "# ===== ì…€ 6: í¬ê¸° ë¬¸ì œ í•´ê²° í™•ì¸ =====\n",
    "print(\"\\n=== í¬ê¸° ë§¤ì¹­ í™•ì¸ ===\")\n",
    "pred_h, pred_w = outputs['pred_masks'].shape[-2:]\n",
    "tgt_h, tgt_w = batch['instance_masks'][0].shape[-2:]\n",
    "\n",
    "print(f\"Prediction: {pred_h}x{pred_w}\")\n",
    "print(f\"Target: {tgt_h}x{tgt_w}\")\n",
    "\n",
    "if pred_h != tgt_h:\n",
    "    print(f\"âš ï¸ í¬ê¸° ë¶ˆì¼ì¹˜ - {tgt_h/pred_h}ë°° ì—…ìƒ˜í”Œë§ í•„ìš”\")\n",
    "else:\n",
    "    print(\"âœ… í¬ê¸° ì¼ì¹˜!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b7caf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: 24.690439 M\n",
      "\n",
      "=== ê°œì„ ëœ Mask2Former ì¶œë ¥ ===\n",
      "pred_logits: torch.Size([2, 100, 4])\n",
      "pred_masks: torch.Size([2, 100, 640, 640])\n",
      "  -> Resolution: 640x640 = 409600 pixels\n",
      "  âœ… 640x640 ë‹¬ì„±!\n",
      "multilabel: torch.Size([2, 3])\n",
      "\n",
      "=== Hungarian Loss ê²°ê³¼ ===\n",
      "Total loss: 4.8094\n",
      "  ce: 0.7768\n",
      "  mask: 0.2529\n",
      "  dice: 0.9958\n",
      "âœ… Hungarian matching ì„±ê³µ!\n",
      "\n",
      "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 2.39 GB\n"
     ]
    }
   ],
   "source": [
    "# ===== Jupyter Notebook í…ŒìŠ¤íŠ¸: ê°œì„ ëœ Mask2Former =====\n",
    "\n",
    "# ì…€ 1: íŒŒì¼ ì¬ë¡œë“œ\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# ê¸°ì¡´ ëª¨ë“ˆ ì œê±°\n",
    "if 'models.heads.mask2former_damage_head' in sys.modules:\n",
    "    del sys.modules['models.heads.mask2former_damage_head']\n",
    "\n",
    "# ë‹¤ì‹œ import\n",
    "from models.heads.mask2former_damage_head import Mask2FormerDamageHead\n",
    "\n",
    "# ì…€ 2: ëª¨ë¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Mask2Former ìƒì„± (ê°œì„ ëœ ë²„ì „)\n",
    "mask2former = Mask2FormerDamageHead(\n",
    "    in_channels=256,\n",
    "    num_classes=3,\n",
    "    num_queries=100,  # ì¤„ì„\n",
    "    hidden_dim=256,\n",
    "    num_heads=8,\n",
    "    dec_layers=3,  # ì¤„ì„\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(\"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜:\", sum(p.numel() for p in mask2former.parameters()) / 1e6, \"M\")\n",
    "\n",
    "# ì…€ 3: ë”ë¯¸ ë°ì´í„°ë¡œ Forward Pass í…ŒìŠ¤íŠ¸\n",
    "dummy_features = [\n",
    "    torch.randn(2, 256, 160, 160),\n",
    "    torch.randn(2, 256, 80, 80),\n",
    "    torch.randn(2, 256, 40, 40),\n",
    "    torch.randn(2, 256, 20, 20)\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = mask2former(dummy_features)\n",
    "\n",
    "print(\"\\n=== ê°œì„ ëœ Mask2Former ì¶œë ¥ ===\")\n",
    "for k, v in outputs.items():\n",
    "    if torch.is_tensor(v):\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "        if k == 'pred_masks':\n",
    "            h, w = v.shape[-2:]\n",
    "            print(f\"  -> Resolution: {h}x{w} = {h*w} pixels\")\n",
    "            if h*w == 409600:\n",
    "                print(\"  âœ… 640x640 ë‹¬ì„±!\")\n",
    "\n",
    "# ì…€ 4: ì‹¤ì œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\n",
    "from utils.dataset import create_dataloaders\n",
    "from pathlib import Path\n",
    "\n",
    "blade_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data')\n",
    "damage_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\multilabeled_data_augmented')\n",
    "\n",
    "train_loader, _, _ = create_dataloaders(\n",
    "    blade_data_root=blade_data_root,\n",
    "    damage_data_root=damage_data_root,\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    model_type='mask2former'\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# ì…€ 5: Hungarian Loss í…ŒìŠ¤íŠ¸\n",
    "from utils.hungarian_loss import HungarianLoss\n",
    "\n",
    "criterion = HungarianLoss(num_classes=3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = mask2former(dummy_features)\n",
    "    \n",
    "try:\n",
    "    loss, loss_dict = criterion(outputs, batch)\n",
    "    print(\"\\n=== Hungarian Loss ê²°ê³¼ ===\")\n",
    "    print(f\"Total loss: {loss.item():.4f}\")\n",
    "    for k, v in loss_dict.items():\n",
    "        print(f\"  {k}: {v.item():.4f}\")\n",
    "    print(\"âœ… Hungarian matching ì„±ê³µ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì—ëŸ¬: {e}\")\n",
    "\n",
    "# ì…€ 6: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n",
    "if torch.cuda.is_available():\n",
    "    mask2former = mask2former.cuda()\n",
    "    dummy_features_cuda = [f.cuda() for f in dummy_features]\n",
    "    \n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    with torch.no_grad():\n",
    "        outputs = mask2former(dummy_features_cuda)\n",
    "    \n",
    "    memory_used = torch.cuda.max_memory_allocated() / 1e9\n",
    "    print(f\"\\në©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_used:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecab4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
