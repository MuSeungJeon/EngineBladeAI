{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557f2ff5",
   "metadata": {},
   "source": [
    "Hybrid_model : ConvNext-FPN Mask2Former 만 사용, Gaussian Distance 사용, mAP 0 뜸. F1, precision, recall 은 올라감. 근데 전혀 못 맞춰서 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2e49ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Master Dataset ---\n",
      "✅ DataLoaders created!\n",
      "--- Initializing Hybrid Unified Model ---\n",
      "✅ Initialization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_13772\\2379612393.py:134: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "import os\n",
    "\n",
    "# --- 프로젝트 경로 추가 및 모듈 임포트 ---\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from models.hybrid_model import HybridUnifiedModel\n",
    "from utils.criterion import SetCriterion\n",
    "from utils.hungarian_matcher import HungarianMatcher\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "from torchmetrics.classification import MulticlassJaccardIndex, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# --- 최종 설정 ---\n",
    "class FinalConfig:\n",
    "    DATA_ROOT = Path('./data/master_dataset')\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    EPOCHS = 50\n",
    "    LR = 3e-5\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_WORKERS = 0\n",
    "    GRADIENT_CLIP_VAL = 1.0\n",
    "    WARMUP_EPOCHS = 5\n",
    "\n",
    "    MODEL = SimpleNamespace(\n",
    "        BACKBONE=SimpleNamespace(NAME='ConvNeXt-Tiny'),\n",
    "        FPN=SimpleNamespace(OUT_CHANNELS=256),\n",
    "        HEAD_B=SimpleNamespace(\n",
    "            FEAT_CHANNELS=256,\n",
    "            OUT_CHANNELS=256,\n",
    "            NUM_CLASSES=4,\n",
    "            QUERIES_PER_CLASS=75,\n",
    "            DEC_LAYERS=6\n",
    "        )\n",
    "    )\n",
    "    LOSS = SimpleNamespace(\n",
    "        CLASS_WEIGHTS=[0.5, 1.5, 1.0, 1.3],\n",
    "        EOS_COEF=0.1\n",
    "    )\n",
    "config = FinalConfig()\n",
    "\n",
    "# --- 데이터셋 클래스 및 로더 ---\n",
    "class UnifiedDataset(Dataset):\n",
    "    def __init__(self, image_infos, annotations_map, images_dir, transform=None):\n",
    "        self.image_infos = image_infos\n",
    "        self.annotations_map = annotations_map\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.cat_map = {1: 0, 2: 1, 3: 2, 4: 3}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_infos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.image_infos[idx]\n",
    "        img_id = img_info['id']\n",
    "        image = Image.open(self.images_dir / img_info['file_name']).convert('RGB')\n",
    "        original_w, original_h = image.size\n",
    "        \n",
    "        target = {}\n",
    "        masks, labels = [], []\n",
    "        annotations = self.annotations_map.get(img_id, [])\n",
    "        for ann in annotations:\n",
    "            if not ann.get('segmentation') or not ann['segmentation'][0] or len(ann['segmentation'][0]) < 6: continue\n",
    "            rle = mask_utils.frPyObjects([ann['segmentation'][0]], original_h, original_h)\n",
    "            mask = mask_utils.decode(rle)\n",
    "            if mask.ndim == 3: mask = np.max(mask, axis=2)\n",
    "            masks.append(mask)\n",
    "            labels.append(self.cat_map[ann['category_id']])\n",
    "\n",
    "        if self.transform: image = self.transform(image)\n",
    "        \n",
    "        target['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        # --- [핵심 수정] 마스크 타입을 다시 float32로 변경 ---\n",
    "        if masks:\n",
    "            target['masks'] = torch.from_numpy(np.stack(masks)).to(torch.float32)\n",
    "        else:\n",
    "            target['masks'] = torch.zeros((0, original_h, original_w), dtype=torch.float32)\n",
    "            \n",
    "        return image, target\n",
    "\n",
    "def collate_fn(batch): return tuple(zip(*batch))\n",
    "\n",
    "# --- 데이터 로딩 실행 ---\n",
    "print(\"--- Loading Master Dataset ---\")\n",
    "with open(config.DATA_ROOT / 'master_annotations.json', 'r') as f: master_data = json.load(f)\n",
    "images_info = master_data['images']\n",
    "annotations_map = {}\n",
    "for ann in master_data['annotations']:\n",
    "    img_id = ann['image_id']\n",
    "    if img_id not in annotations_map: annotations_map[img_id] = []\n",
    "    annotations_map[img_id].append(ann)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)), transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "full_dataset = UnifiedDataset(images_info, annotations_map, config.DATA_ROOT / 'images', transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=config.NUM_WORKERS, collate_fn=collate_fn)\n",
    "print(\"✅ DataLoaders created!\")\n",
    "\n",
    "# --- 모델, 손실함수, 옵티마이저 초기화 ---\n",
    "print(\"--- Initializing Hybrid Unified Model ---\")\n",
    "model = HybridUnifiedModel(config).to(config.DEVICE)\n",
    "matcher = HungarianMatcher(num_classes=config.MODEL.HEAD_B.NUM_CLASSES)\n",
    "weight_dict = {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0}\n",
    "criterion = SetCriterion(\n",
    "    num_classes=config.MODEL.HEAD_B.NUM_CLASSES, matcher=matcher, weight_dict=weight_dict,\n",
    "    eos_coef=config.LOSS.EOS_COEF, losses=['labels', 'masks'], class_weights=config.LOSS.CLASS_WEIGHTS\n",
    ").to(config.DEVICE)\n",
    "optimizer = AdamW(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n",
    "scaler = GradScaler()\n",
    "warmup_scheduler = LinearLR(optimizer, start_factor=0.1, total_iters=config.WARMUP_EPOCHS)\n",
    "main_scheduler = CosineAnnealingLR(optimizer, T_max=config.EPOCHS - config.WARMUP_EPOCHS, eta_min=1e-7)\n",
    "lr_scheduler = SequentialLR(optimizer, schedulers=[warmup_scheduler, main_scheduler], milestones=[config.WARMUP_EPOCHS])\n",
    "print(\"✅ Initialization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45f71b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, criterion, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Train]\")\n",
    "    for images, targets in pbar:\n",
    "        images = torch.stack(images).to(device)\n",
    "        targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss_dict = criterion(outputs, targets_gpu)\n",
    "            weighted_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(weighted_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.GRADIENT_CLIP_VAL)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        pbar.set_postfix({'loss': f'{weighted_loss.item():.4f}'})\n",
    "\n",
    "def validate(model, criterion, dataloader, device):\n",
    "    \"\"\"\n",
    "    모델 검증 함수\n",
    "    Args:\n",
    "        model: 평가할 모델\n",
    "        criterion: 손실 함수 (matcher 접근용)\n",
    "        dataloader: 검증 데이터 로더\n",
    "        device: 디바이스 (cuda/cpu)\n",
    "    Returns:\n",
    "        metrics: 평가 지표 딕셔너리\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # --- 평가 지표 객체 초기화 ---\n",
    "    num_classes = config.MODEL.HEAD_B.NUM_CLASSES\n",
    "    \n",
    "    # 1. mAP (Detection/Segmentation 표준)\n",
    "    map_metric = MeanAveragePrecision(iou_type=\"segm\")\n",
    "    \n",
    "    # 2. IoU (Jaccard Index) - 클래스별 평균\n",
    "    iou_metric = MulticlassJaccardIndex(num_classes=num_classes, average='macro').to(device)\n",
    "    \n",
    "    # 3. Precision, Recall, F1-score - 클래스별 평균\n",
    "    precision_metric = MulticlassPrecision(num_classes=num_classes, average='macro').to(device)\n",
    "    recall_metric = MulticlassRecall(num_classes=num_classes, average='macro').to(device)\n",
    "    f1_metric = MulticlassF1Score(num_classes=num_classes, average='macro').to(device)\n",
    "    \n",
    "    # 메트릭 업데이트 여부 추적\n",
    "    metrics_updated = False\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"[Valid]\")\n",
    "        for images, targets in pbar:\n",
    "            images = torch.stack(images).to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "            \n",
    "            # --- mAP 계산용 데이터 준비 ---\n",
    "            preds_cpu = {k: v.cpu() for k, v in outputs.items() if torch.is_tensor(v)}\n",
    "            \n",
    "            preds_for_map = []\n",
    "            for i in range(len(targets)):\n",
    "                scores, labels = F.softmax(preds_cpu['pred_logits'][i], dim=-1).max(-1)\n",
    "                # boolean 마스크를 uint8로 변환\n",
    "                masks_uint8 = (torch.sigmoid(preds_cpu['pred_masks'][i]) > 0.5).to(torch.uint8)\n",
    "                preds_for_map.append(dict(masks=masks_uint8, scores=scores, labels=labels))\n",
    "\n",
    "            targets_for_map = []\n",
    "            for t in targets:\n",
    "                target_dict = {\n",
    "                    'labels': t['labels'].cpu(),\n",
    "                    # 정답 마스크도 uint8 타입으로 변환\n",
    "                    'masks': t['masks'].cpu().to(torch.uint8)\n",
    "                }\n",
    "                targets_for_map.append(target_dict)\n",
    "\n",
    "            map_metric.update(preds_for_map, targets_for_map)\n",
    "            \n",
    "            # --- IoU, P, R, F1 계산용 데이터 준비 ---\n",
    "            indices = criterion.matcher(outputs, [{k: v.to(device) for k, v in t.items()} for t in targets])\n",
    "            \n",
    "            if any(len(i[0]) > 0 for i in indices):\n",
    "                idx = criterion._get_src_permutation_idx(indices)\n",
    "                pred_logits = outputs['pred_logits'][idx]\n",
    "                target_labels = torch.cat([t[\"labels\"][J] for t, (_, J) in zip(targets, indices)]).to(device)\n",
    "\n",
    "                # 매칭된 결과로 지표 업데이트\n",
    "                iou_metric.update(pred_logits, target_labels)\n",
    "                precision_metric.update(pred_logits, target_labels)\n",
    "                recall_metric.update(pred_logits, target_labels)\n",
    "                f1_metric.update(pred_logits, target_labels)\n",
    "                metrics_updated = True\n",
    "\n",
    "    # 최종 결과 집계\n",
    "    try:\n",
    "        map_results = map_metric.compute()\n",
    "        map_val = map_results.get('map', torch.tensor(0.0))\n",
    "        map_50_val = map_results.get('map_50', torch.tensor(0.0))\n",
    "        \n",
    "        # tensor인지 확인하고 item() 호출\n",
    "        if torch.is_tensor(map_val):\n",
    "            map_val = map_val.item()\n",
    "        if torch.is_tensor(map_50_val):\n",
    "            map_50_val = map_50_val.item()\n",
    "    except:\n",
    "        print(\"⚠️ Warning: mAP computation failed\")\n",
    "        map_val = 0.0\n",
    "        map_50_val = 0.0\n",
    "    \n",
    "    # 다른 메트릭들 계산\n",
    "    if metrics_updated:\n",
    "        try:\n",
    "            iou_val = iou_metric.compute().item()\n",
    "        except:\n",
    "            iou_val = 0.0\n",
    "        \n",
    "        try:\n",
    "            precision_val = precision_metric.compute().item()\n",
    "        except:\n",
    "            precision_val = 0.0\n",
    "            \n",
    "        try:\n",
    "            recall_val = recall_metric.compute().item()\n",
    "        except:\n",
    "            recall_val = 0.0\n",
    "            \n",
    "        try:\n",
    "            f1_val = f1_metric.compute().item()\n",
    "        except:\n",
    "            f1_val = 0.0\n",
    "    else:\n",
    "        # 메트릭이 한 번도 업데이트되지 않은 경우\n",
    "        print(\"⚠️ Warning: No valid predictions matched with targets\")\n",
    "        iou_val = precision_val = recall_val = f1_val = 0.0\n",
    "    \n",
    "    metrics = {\n",
    "        'mAP': map_val,\n",
    "        'mAP_50': map_50_val,\n",
    "        'iou': iou_val,\n",
    "        'precision': precision_val,\n",
    "        'recall': recall_val,\n",
    "        'f1_score': f1_val\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "736974b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 🚀 Starting Hybrid Unified Model Training 🚀 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   0%|          | 0/655 [00:00<?, ?it/s]C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_13772\\1293238820.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=6.2026] \n",
      "[Valid]:   0%|          | 0/164 [00:00<?, ?it/s]C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_13772\\1293238820.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2091 | F1: 0.3120\n",
      "  Precision: 0.5245 | Recall: 0.3580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|██████████| 655/655 [06:44<00:00,  1.62it/s, loss=4.4183]\n",
      "[Valid]: 100%|██████████| 164/164 [00:27<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.1826 | F1: 0.2692\n",
      "  Precision: 0.5048 | Recall: 0.4049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|██████████| 655/655 [06:50<00:00,  1.59it/s, loss=5.5379] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.1881 | F1: 0.2836\n",
      "  Precision: 0.4199 | Recall: 0.3226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.63it/s, loss=7.5676] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2325 | F1: 0.3702\n",
      "  Precision: 0.3975 | Recall: 0.4046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=7.3938] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n",
      "c:\\Users\\user\\anaconda3\\envs\\yoloEnv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2449 | F1: 0.3594\n",
      "  Precision: 0.3797 | Recall: 0.3659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=5.6607] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2083 | F1: 0.3375\n",
      "  Precision: 0.4139 | Recall: 0.3514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=7.6219] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.1485 | F1: 0.2508\n",
      "  Precision: 0.2549 | Recall: 0.2555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.64it/s, loss=1.6495] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.5350 | F1: 0.6613\n",
      "  Precision: 0.7152 | Recall: 0.6734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=8.3342] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2372 | F1: 0.3705\n",
      "  Precision: 0.3753 | Recall: 0.3774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.63it/s, loss=8.4895] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.1817 | F1: 0.2878\n",
      "  Precision: 0.3134 | Recall: 0.3108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=6.6898] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2125 | F1: 0.3346\n",
      "  Precision: 0.3524 | Recall: 0.3694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.64it/s, loss=6.8351]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2624 | F1: 0.4101\n",
      "  Precision: 0.4102 | Recall: 0.4305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=3.0545] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.4192 | F1: 0.5474\n",
      "  Precision: 0.5901 | Recall: 0.5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=5.5454] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.3298 | F1: 0.4791\n",
      "  Precision: 0.5163 | Recall: 0.4669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.64it/s, loss=4.6245] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2632 | F1: 0.3969\n",
      "  Precision: 0.4319 | Recall: 0.4411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.63it/s, loss=3.5817] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2821 | F1: 0.4246\n",
      "  Precision: 0.4830 | Recall: 0.4619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.64it/s, loss=5.5957] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.3289 | F1: 0.4791\n",
      "  Precision: 0.5083 | Recall: 0.4745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.63it/s, loss=6.3058] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2441 | F1: 0.3887\n",
      "  Precision: 0.3833 | Recall: 0.4037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.63it/s, loss=6.4287]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2672 | F1: 0.4094\n",
      "  Precision: 0.4222 | Recall: 0.4047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=1.8159]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.3709 | F1: 0.5085\n",
      "  Precision: 0.5606 | Recall: 0.4992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.63it/s, loss=3.1577] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2017 | F1: 0.3039\n",
      "  Precision: 0.4411 | Recall: 0.3209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=6.1988] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2004 | F1: 0.3184\n",
      "  Precision: 0.3700 | Recall: 0.3254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.63it/s, loss=5.7442] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2610 | F1: 0.4028\n",
      "  Precision: 0.4508 | Recall: 0.3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.64it/s, loss=7.8434] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.4425 | F1: 0.6028\n",
      "  Precision: 0.6265 | Recall: 0.5929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.64it/s, loss=4.1192] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.4028 | F1: 0.5536\n",
      "  Precision: 0.5901 | Recall: 0.5553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [Train]: 100%|██████████| 655/655 [06:40<00:00,  1.63it/s, loss=7.1493]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.2344 | F1: 0.3619\n",
      "  Precision: 0.4128 | Recall: 0.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=2.1421] \n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.5240 | F1: 0.6627\n",
      "  Precision: 0.6980 | Recall: 0.6544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=1.2596]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.6021 | F1: 0.7278\n",
      "  Precision: 0.7288 | Recall: 0.7386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=3.8005]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.5740 | F1: 0.6938\n",
      "  Precision: 0.6882 | Recall: 0.7015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [Train]: 100%|██████████| 655/655 [06:42<00:00,  1.63it/s, loss=2.6286]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7203 | F1: 0.8270\n",
      "  Precision: 0.8210 | Recall: 0.8349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=2.0859]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7126 | F1: 0.8214\n",
      "  Precision: 0.8566 | Recall: 0.8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=0.7915]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7115 | F1: 0.8187\n",
      "  Precision: 0.8352 | Recall: 0.8067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=2.3643]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.6853 | F1: 0.7962\n",
      "  Precision: 0.8456 | Recall: 0.7789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 [Train]: 100%|██████████| 655/655 [06:42<00:00,  1.63it/s, loss=1.2871]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7036 | F1: 0.8082\n",
      "  Precision: 0.8777 | Recall: 0.7844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=0.6665]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7083 | F1: 0.8156\n",
      "  Precision: 0.8578 | Recall: 0.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=0.7545]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7415 | F1: 0.8422\n",
      "  Precision: 0.8593 | Recall: 0.8314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=1.2581]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.6948 | F1: 0.8039\n",
      "  Precision: 0.8300 | Recall: 0.7882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=4.5561]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7011 | F1: 0.8083\n",
      "  Precision: 0.8569 | Recall: 0.7863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=2.3546]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7302 | F1: 0.8338\n",
      "  Precision: 0.8909 | Recall: 0.8082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=1.2932]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7032 | F1: 0.8124\n",
      "  Precision: 0.8338 | Recall: 0.7976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=2.6223]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7305 | F1: 0.8330\n",
      "  Precision: 0.8736 | Recall: 0.8115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=1.3673]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7534 | F1: 0.8522\n",
      "  Precision: 0.8617 | Recall: 0.8456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=2.4409]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7506 | F1: 0.8502\n",
      "  Precision: 0.8616 | Recall: 0.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=2.1028]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7722 | F1: 0.8658\n",
      "  Precision: 0.8782 | Recall: 0.8561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 [Train]: 100%|██████████| 655/655 [06:44<00:00,  1.62it/s, loss=3.0336]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7540 | F1: 0.8509\n",
      "  Precision: 0.8600 | Recall: 0.8441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 [Train]: 100%|██████████| 655/655 [06:42<00:00,  1.63it/s, loss=1.1953]\n",
      "[Valid]: 100%|██████████| 164/164 [00:27<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7244 | F1: 0.8313\n",
      "  Precision: 0.8324 | Recall: 0.8304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=1.1622]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7392 | F1: 0.8415\n",
      "  Precision: 0.8538 | Recall: 0.8342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=3.0448]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7470 | F1: 0.8474\n",
      "  Precision: 0.8647 | Recall: 0.8369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=1.6188]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7545 | F1: 0.8522\n",
      "  Precision: 0.8670 | Recall: 0.8433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 [Train]: 100%|██████████| 655/655 [06:41<00:00,  1.63it/s, loss=0.5522]\n",
      "[Valid]: 100%|██████████| 164/164 [00:26<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/50:\n",
      "  Val mAP: 0.0000 | mAP@.50: 0.0000\n",
      "  IoU: 0.7533 | F1: 0.8514\n",
      "  Precision: 0.8700 | Recall: 0.8407\n",
      "\n",
      "--- 🎉 Training Complete ---\n",
      "Best mAP achieved: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# --- 메인 학습 루프 (완전한 버전) ---\n",
    "print(\"\\n--- 🚀 Starting Hybrid Unified Model Training 🚀 ---\")\n",
    "best_map = 0.0\n",
    "for epoch in range(config.EPOCHS):\n",
    "    # 학습\n",
    "    train_epoch(model, criterion, train_loader, optimizer, config.DEVICE, epoch)\n",
    "    \n",
    "    # 검증 - criterion도 전달\n",
    "    val_metrics = validate(model, criterion, val_loader, config.DEVICE)\n",
    "    \n",
    "    # 메트릭 출력\n",
    "    val_map = val_metrics['mAP']\n",
    "    val_map_50 = val_metrics['mAP_50']\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{config.EPOCHS}:\")\n",
    "    print(f\"  Val mAP: {val_map:.4f} | mAP@.50: {val_map_50:.4f}\")\n",
    "    print(f\"  IoU: {val_metrics['iou']:.4f} | F1: {val_metrics['f1_score']:.4f}\")\n",
    "    print(f\"  Precision: {val_metrics['precision']:.4f} | Recall: {val_metrics['recall']:.4f}\")\n",
    "    \n",
    "    # 스케줄러 업데이트\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # 베스트 모델 저장\n",
    "    if val_map > best_map:\n",
    "        best_map = val_map\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_map': best_map,\n",
    "            'metrics': val_metrics\n",
    "        }, 'hybrid_unified_best_model.pth')\n",
    "        print(f\"✨ New best model saved with mAP: {best_map:.4f}\")\n",
    "        \n",
    "print(f\"\\n--- 🎉 Training Complete ---\")\n",
    "print(f\"Best mAP achieved: {best_map:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e499dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 🚀 Starting Single Batch Overfit Test ---\n",
      "✅ Single batch loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_13772\\547243036.py:19: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_test = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting to overfit on the single batch for 200 iterations ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_13772\\547243036.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "  5%|▌         | 10/200 [00:05<01:48,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10/200 -> Loss: 10.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [00:11<01:42,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20/200 -> Loss: 9.3961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [00:17<01:36,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30/200 -> Loss: 8.4513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [00:22<01:30,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40/200 -> Loss: 9.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [00:28<01:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50/200 -> Loss: 9.2957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [00:34<01:19,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 60/200 -> Loss: 7.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [00:39<01:13,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70/200 -> Loss: 7.8645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [00:45<01:08,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 80/200 -> Loss: 8.9995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [00:51<01:03,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 90/200 -> Loss: 8.0684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [00:57<00:58,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100/200 -> Loss: 7.2103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [01:02<00:51,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 110/200 -> Loss: 7.3659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [01:08<00:45,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 120/200 -> Loss: 8.4996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 130/200 [01:14<00:39,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 130/200 -> Loss: 7.8203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140/200 [01:19<00:34,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 140/200 -> Loss: 6.9739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 150/200 [01:25<00:28,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 150/200 -> Loss: 7.4296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [01:31<00:22,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 160/200 -> Loss: 8.8397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 170/200 [01:36<00:17,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 170/200 -> Loss: 7.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180/200 [01:42<00:11,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 180/200 -> Loss: 7.2570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190/200 [01:48<00:05,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 190/200 -> Loss: 8.6877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:53<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200/200 -> Loss: 8.6085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 🚀 Starting Single Batch Overfit Test ---\")\n",
    "\n",
    "# 1. 학습 데이터 로더에서 딱 한 개의 배치만 가져오기\n",
    "try:\n",
    "    single_batch = next(iter(train_loader))\n",
    "    print(\"✅ Single batch loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load a batch: {e}\")\n",
    "\n",
    "if 'single_batch' in locals():\n",
    "    images, targets = single_batch\n",
    "    images = torch.stack(images).to(config.DEVICE)\n",
    "    targets_gpu = [{k: v.to(config.DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    # 2. 모델과 옵티마이저를 새로 초기화 (깨끗한 상태에서 시작)\n",
    "    model_test = HybridUnifiedModel(config).to(config.DEVICE)\n",
    "    optimizer_test = AdamW(model_test.parameters(), lr=config.LR)\n",
    "    criterion_test = criterion.to(config.DEVICE)\n",
    "    scaler_test = GradScaler()\n",
    "    model_test.train()\n",
    "    \n",
    "    print(\"\\n--- Starting to overfit on the single batch for 200 iterations ---\")\n",
    "    # 3. 동일한 배치로 200번 학습 시도\n",
    "    for i in tqdm(range(200)):\n",
    "        with autocast():\n",
    "            outputs = model_test(images)\n",
    "            loss_dict = criterion_test(outputs, targets_gpu)\n",
    "            weighted_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "        optimizer_test.zero_grad()\n",
    "        scaler_test.scale(weighted_loss).backward()\n",
    "        scaler_test.step(optimizer_test)\n",
    "        scaler_test.update()\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Iteration {i+1}/200 -> Loss: {weighted_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca36438",
   "metadata": {},
   "source": [
    "Unified_model : ConvNext-FPN Mask2Former 만 사용, Gaussian Distance 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b074679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading the best model and visualizing predictions ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_13772\\2759810527.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('hybrid_unified_best_model.pth'))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hybrid_unified_best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Loading the best model and visualizing predictions ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1. 최종 모델 가중치 불러오기\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhybrid_unified_best_model.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 2. 시각화 함수 실행\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# val_loader를 사용하여 검증 데이터에 대한 예측을 확인합니다.\u001b[39;00m\n\u001b[32m     10\u001b[39m visualize_predictions(model, val_loader, config.DEVICE, num_samples=\u001b[32m5\u001b[39m) \u001b[38;5;66;03m# 5개 샘플 확인\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\yoloEnv\\Lib\\site-packages\\torch\\serialization.py:1319\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1317\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1321\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1322\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1323\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1324\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\yoloEnv\\Lib\\site-packages\\torch\\serialization.py:659\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    661\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\yoloEnv\\Lib\\site-packages\\torch\\serialization.py:640\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'hybrid_unified_best_model.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "import os\n",
    "\n",
    "# --- 프로젝트 경로 추가 및 모듈 임포트 ---\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from models.unified_model import UnifiedModel\n",
    "from utils.criterion import SetCriterion\n",
    "from utils.hungarian_matcher import HungarianMatcher\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "from torchmetrics.classification import MulticlassJaccardIndex, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "print(\"--- 🚀 Starting Single Batch Overfit Test (Simple Model) ---\")\n",
    "\n",
    "# 1. 학습 데이터 로더에서 딱 한 개의 배치만 가져오기\n",
    "try:\n",
    "    single_batch = next(iter(train_loader))\n",
    "    print(\"✅ Single batch loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load a batch: {e}\")\n",
    "\n",
    "if 'single_batch' in locals():\n",
    "    images, targets = single_batch\n",
    "    images = torch.stack(images).to(config.DEVICE)\n",
    "    targets_gpu = [{k: v.to(config.DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    # 2. 모델과 옵티마이저를 새로 초기화 (깨끗한 상태에서 시작)\n",
    "    model_test = UnifiedModel(config).to(config.DEVICE)\n",
    "    optimizer_test = AdamW(model_test.parameters(), lr=config.LR)\n",
    "    criterion_test = criterion.to(config.DEVICE)\n",
    "    scaler_test = GradScaler()\n",
    "    model_test.train()\n",
    "    \n",
    "    print(\"\\n--- Starting to overfit on the single batch for 200 iterations ---\")\n",
    "    # 3. 동일한 배치로 200번 학습 시도\n",
    "    for i in tqdm(range(200)):\n",
    "        with autocast():\n",
    "            outputs = model_test(images)\n",
    "            loss_dict = criterion_test(outputs, targets_gpu)\n",
    "            weighted_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "        optimizer_test.zero_grad()\n",
    "        scaler_test.scale(weighted_loss).backward()\n",
    "        scaler_test.step(optimizer_test)\n",
    "        scaler_test.update()\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Iteration {i+1}/200 -> Loss: {weighted_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90739a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
