{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680d2cbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (convnext_fpn.py, line 113)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92mc:\\Users\\user\\anaconda3\\envs\\yoloEnv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[2]\u001b[39m\u001b[92m, line 25\u001b[39m\n    from models.heads.mask2former_damage_head import Mask2FormerDamageHead\n",
      "  File \u001b[92mc:\\EngineBladeAI\\EngineInspectionAI_MS\\models\\__init__.py:2\u001b[39m\n    from models.backbones.convnext_fpn import ConvNeXtFPN\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32mc:\\EngineBladeAI\\EngineInspectionAI_MS\\models\\backbones\\__init__.py:2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfrom .convnext_fpn import ConvNeXtFPN\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32mc:\\EngineBladeAI\\EngineInspectionAI_MS\\models\\backbones\\convnext_fpn.py:113\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcclass ConvNeXtFPN(nn.Module):\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ÌîÑÎ°úÏ†ùÌä∏ Í≤ΩÎ°ú Ï∂îÍ∞Ä\n",
    "project_path = Path('C:/EngineBladeAI/EngineInspectionAI_MS')\n",
    "sys.path.append(str(project_path))\n",
    "\n",
    "# Custom imports\n",
    "from models.heads.mask2former_damage_head import Mask2FormerDamageHead\n",
    "from models.backbones.convnext_fpn import ConvNeXtFPN\n",
    "from utils.evaluate import ModelEvaluator\n",
    "\n",
    "# Device ÏÑ§Ï†ï\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    free_memory = (torch.cuda.get_device_properties(0).total_memory - \n",
    "                   torch.cuda.memory_allocated(0)) / 1024**3\n",
    "    print(f\"   GPU: {gpu_name}\")\n",
    "    print(f\"   Total Memory: {gpu_memory:.1f} GB\")\n",
    "    print(f\"   Free Memory: {free_memory:.1f} GB\")\n",
    "\n",
    "print(\"\\n‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"ÌîÑÎ°úÏ†ùÌä∏ Ï†ÑÏ≤¥ ÏÑ§Ï†ï\"\"\"\n",
    "    \n",
    "    # ÏÜêÏÉÅ ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "    NUM_CLASSES = 3\n",
    "    CLASS_NAMES = ['crack', 'nick', 'tear']\n",
    "    CLASS_COLORS = {\n",
    "        'crack': (255, 0, 0),    # Red\n",
    "        'nick': (0, 255, 0),      # Green\n",
    "        'tear': (0, 0, 255),      # Blue\n",
    "    }\n",
    "    \n",
    "    # Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú\n",
    "    DATA_ROOT = project_path / 'data'\n",
    "    TRAIN_DATA = DATA_ROOT / 'multilabeled_data_augmented' / 'train'\n",
    "    VALID_DATA = DATA_ROOT / 'multilabeled_data_augmented' / 'valid'\n",
    "    TEST_DATA = DATA_ROOT / 'multilabeled_data_augmented' / 'test'\n",
    "    \n",
    "    # Î™®Îç∏ ÏÑ§Ï†ï (RTX 4090 ÏµúÏ†ÅÌôî)\n",
    "    QUERIES_PER_CLASS = 100  # Í∞Å ÌÅ¥ÎûòÏä§Îãπ 100Í∞ú\n",
    "    TOTAL_QUERIES = NUM_CLASSES * QUERIES_PER_CLASS  # 300\n",
    "    \n",
    "    # Î∞±Î≥∏ ÏÑ§Ï†ï\n",
    "    BACKBONE_MODEL = 'convnext_tiny'\n",
    "    BACKBONE_PRETRAINED = True\n",
    "    FPN_CHANNELS = 256\n",
    "    \n",
    "    # Mask2Former ÏÑ§Ï†ï\n",
    "    HIDDEN_DIM = 256\n",
    "    NUM_HEADS = 8\n",
    "    DIM_FEEDFORWARD = 1024\n",
    "    DEC_LAYERS = 3\n",
    "    DROPOUT = 0.1\n",
    "    \n",
    "    # ÌïôÏäµ ÏÑ§Ï†ï\n",
    "    BATCH_SIZE = 2\n",
    "    GRAD_ACCUM_STEPS = 2  # Effective batch size = 4\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 5e-5\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    \n",
    "    # Loss Í∞ÄÏ§ëÏπò\n",
    "    LOSS_CE_WEIGHT = 2.0\n",
    "    LOSS_MASK_WEIGHT = 5.0\n",
    "    LOSS_DICE_WEIGHT = 2.0\n",
    "    \n",
    "    # Í∏∞ÌÉÄ\n",
    "    NUM_WORKERS = 4\n",
    "    CHECKPOINT_DIR = project_path / 'checkpoints' / f'run_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "    USE_WANDB = False\n",
    "    WANDB_PROJECT = 'EngineBladeAI'\n",
    "    \n",
    "config = Config()\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Classes: {config.CLASS_NAMES}\")\n",
    "print(f\"  Total Queries: {config.TOTAL_QUERIES}\")\n",
    "print(f\"  Batch Size: {config.BATCH_SIZE} (√ó{config.GRAD_ACCUM_STEPS} = {config.BATCH_SIZE * config.GRAD_ACCUM_STEPS})\")\n",
    "print(f\"  Epochs: {config.NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask2former_model(config):\n",
    "    \"\"\"Mask2Former Î™®Îç∏ ÏÉùÏÑ± (300 queries, 3 classes)\"\"\"\n",
    "    \n",
    "    model = Mask2FormerDamageHead(\n",
    "        in_channels=config.FPN_CHANNELS,\n",
    "        num_classes=config.NUM_CLASSES,  # 3\n",
    "        num_queries=config.TOTAL_QUERIES,  # 300\n",
    "        hidden_dim=config.HIDDEN_DIM,\n",
    "        num_heads=config.NUM_HEADS,\n",
    "        dim_feedforward=config.DIM_FEEDFORWARD,\n",
    "        dec_layers=config.DEC_LAYERS,\n",
    "        dropout=config.DROPOUT,\n",
    "        use_blade_mask=True\n",
    "    )\n",
    "    \n",
    "    # Background ÌÅ¥ÎûòÏä§ Ï†úÍ±∞ (num_classes + 1 ‚Üí num_classes)\n",
    "    if hasattr(model, 'class_head'):\n",
    "        if model.class_head.out_features != config.NUM_CLASSES:\n",
    "            print(f\"‚ö†Ô∏è Fixing class_head: {model.class_head.out_features} ‚Üí {config.NUM_CLASSES}\")\n",
    "            in_features = model.class_head.in_features\n",
    "            model.class_head = nn.Linear(in_features, config.NUM_CLASSES)\n",
    "    \n",
    "    # Query-to-class Îß§Ìïë Ï∂îÍ∞Ä\n",
    "    model.query_to_class = {}\n",
    "    for q in range(config.TOTAL_QUERIES):\n",
    "        model.query_to_class[q] = q // config.QUERIES_PER_CLASS\n",
    "    \n",
    "    # Class specialization Ìï®Ïàò\n",
    "    def apply_class_specialization(outputs):\n",
    "        \"\"\"Í∞Å queryÍ∞Ä ÏûêÏã†Ïùò Ï†ÑÎ¨∏ ÌÅ¥ÎûòÏä§Îßå ÎÜíÍ≤å ÏòàÏ∏°\"\"\"\n",
    "        pred_logits = outputs['pred_logits']\n",
    "        batch_size, num_queries, num_classes = pred_logits.shape\n",
    "        \n",
    "        for q in range(num_queries):\n",
    "            assigned_class = model.query_to_class.get(q, 0)\n",
    "            if assigned_class < num_classes:\n",
    "                # Ìï¥Îãπ ÌÅ¥ÎûòÏä§Îäî Ï¶ùÌè≠, Îã§Î•∏ ÌÅ¥ÎûòÏä§Îäî ÏñµÏ†ú\n",
    "                mask = torch.ones_like(pred_logits[:, q])\n",
    "                mask[:, assigned_class] *= 5.0\n",
    "                for c in range(num_classes):\n",
    "                    if c != assigned_class:\n",
    "                        mask[:, c] *= 0.1\n",
    "                outputs['pred_logits'][:, q] = outputs['pred_logits'][:, q] * mask\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    model.apply_class_specialization = apply_class_specialization\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Î™®Îç∏ ÏÉùÏÑ±\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating Mask2Former model...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "mask2former = create_mask2former_model(config).to(device)\n",
    "\n",
    "# ÌååÎùºÎØ∏ÌÑ∞ Ïàò ÌôïÏù∏\n",
    "num_params = sum(p.numel() for p in mask2former.parameters()) / 1e6\n",
    "trainable_params = sum(p.numel() for p in mask2former.parameters() if p.requires_grad) / 1e6\n",
    "\n",
    "print(f\"‚úÖ Model created!\")\n",
    "print(f\"   Total parameters: {num_params:.2f}M\")\n",
    "print(f\"   Trainable parameters: {trainable_params:.2f}M\")\n",
    "print(f\"   Queries: {config.TOTAL_QUERIES} (Crack:0-99, Nick:100-199, Tear:200-299)\")\n",
    "print(f\"   Output classes: {config.NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating ConvNeXt-FPN backbone...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "backbone = ConvNeXtFPN(\n",
    "    model_name=config.BACKBONE_MODEL,\n",
    "    pretrained=config.BACKBONE_PRETRAINED,\n",
    "    feature_channels=[96, 192, 384, 768],  # ConvNeXt-Tiny\n",
    "    fpn_channels=config.FPN_CHANNELS\n",
    ").to(device)\n",
    "\n",
    "print(f\"‚úÖ Backbone created: {config.BACKBONE_MODEL}\")\n",
    "print(f\"   FPN channels: {config.FPN_CHANNELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a4a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
