{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2640b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu121\n",
      "CUDA Available: True\n",
      "\n",
      "--- Configuration Initialized ---\n",
      "Data Path: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\final_dataset_augmented\n",
      "Device: cuda\n",
      "Initial Learning Rate: 2e-05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# pycocotools가 필요합니다. pip install pycocotools\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# --- 프로젝트 경로 추가 및 모듈 임포트 ---\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from models.blade_model_v2 import BladeModelV2\n",
    "from utils.criterion import SetCriterion\n",
    "from utils.hungarian_matcher import HungarianMatcher\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# --- 최종 설정 (Configuration) ---\n",
    "class Config:\n",
    "    DATA_ROOT = Path('C:/EngineBladeAI/EngineInspectionAI_MS/data/final_dataset_augmented')\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # --- 학습 하이퍼파라미터 (수정) ---\n",
    "    BATCH_SIZE = 4\n",
    "    EPOCHS = 15 # <-- 1단계 학습을 위해 에포크 수 조정\n",
    "    LR = 2e-5 \n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    NUM_WORKERS = 0\n",
    "    LR_DROP_STEP = 20\n",
    "    GRADIENT_CLIP_VAL = 1.0 # <-- [추가] Gradient Clipping 값 설정\n",
    "\n",
    "    MODEL = SimpleNamespace(\n",
    "        # --- [수정] 딕셔너리를 SimpleNamespace로 변경 ---\n",
    "        BACKBONE=SimpleNamespace(NAME='ConvNeXt-Tiny'),\n",
    "        FPN=SimpleNamespace(OUT_CHANNELS=256),\n",
    "        HEAD_B=SimpleNamespace(\n",
    "            FEAT_CHANNELS=256,\n",
    "            OUT_CHANNELS=256,\n",
    "            NUM_CLASSES=3,\n",
    "            QUERIES_PER_CLASS=100,\n",
    "            DEC_LAYERS=6\n",
    "        )\n",
    "    )\n",
    "    LOSS = SimpleNamespace(\n",
    "        CLASS_WEIGHTS=[1.5, 1.0, 1.3], # Crack, Nick, Tear\n",
    "        EOS_COEF=0.1\n",
    "    )\n",
    "\n",
    "config = Config()\n",
    "print(f\"\\n--- Configuration Initialized ---\")\n",
    "print(f\"Data Path: {config.DATA_ROOT}\")\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"Initial Learning Rate: {config.LR}\") # <-- 확인용 print 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d111756a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset class and collate_fn are defined.\n"
     ]
    }
   ],
   "source": [
    "class FinalBladeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    최종 통합된 데이터셋(final_dataset)을 위한 Dataset 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, split='train', transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.split = split\n",
    "        self.images_dir = self.root / self.split / 'images'\n",
    "        \n",
    "        json_path = self.root / self.split / 'annotations.json'\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "            \n",
    "        self.images_info = self.data['images']\n",
    "        self.annotations_map = {}\n",
    "        for ann in self.data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.annotations_map:\n",
    "                self.annotations_map[img_id] = []\n",
    "            self.annotations_map[img_id].append(ann)\n",
    "            \n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((640, 640)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images_info[idx]\n",
    "        img_id = img_info['id']\n",
    "        img_path = self.images_dir / img_info['file_name']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        original_w, original_h = image.size\n",
    "        \n",
    "        target = {}\n",
    "        blade_mask = np.zeros((original_h, original_w), dtype=np.uint8)\n",
    "        damage_masks_np = []\n",
    "        damage_labels = []\n",
    "        multilabel_vector = torch.zeros(3, dtype=torch.float32)\n",
    "\n",
    "        annotations = self.annotations_map.get(img_id, [])\n",
    "        for ann in annotations:\n",
    "            # --- [핵심 수정] ---\n",
    "            # segmentation 데이터가 유효한지 확인하는 방어 코드 추가\n",
    "            seg = ann.get('segmentation')\n",
    "            if not seg or not isinstance(seg, list) or not seg[0] or len(seg[0]) < 6:\n",
    "                # 유효하지 않은 polygon (최소 3개의 점 필요)이면 건너뛰기\n",
    "                continue\n",
    "                \n",
    "            cat_id = ann['category_id']\n",
    "            \n",
    "            try:\n",
    "                rle = mask_utils.frPyObjects([seg[0]], original_h, original_w)\n",
    "                mask = mask_utils.decode(rle)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to decode segmentation for ann_id {ann.get('id')}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            if mask.ndim == 3:\n",
    "                mask = np.max(mask, axis=2)\n",
    "\n",
    "            if cat_id == 1:\n",
    "                blade_mask = np.maximum(blade_mask, mask)\n",
    "            else:\n",
    "                damage_masks_np.append(mask)\n",
    "                damage_labels.append(cat_id - 2)\n",
    "                multilabel_vector[cat_id - 2] = 1.0\n",
    "\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        target['blade_mask'] = torch.from_numpy(blade_mask).long()\n",
    "        target['labels'] = torch.tensor(damage_labels, dtype=torch.int64)\n",
    "        target['multilabel'] = multilabel_vector\n",
    "        \n",
    "        if damage_masks_np:\n",
    "            damage_masks_tensor = torch.from_numpy(np.stack(damage_masks_np)).float()\n",
    "            target['masks'] = damage_masks_tensor\n",
    "        else:\n",
    "            target['masks'] = torch.zeros((0, original_h, original_w), dtype=torch.float32)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    images = torch.stack(images, dim=0)\n",
    "    return images, targets\n",
    "\n",
    "print(\"✅ Dataset class and collate_fn are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f32742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating DataLoaders ---\n",
      "✅ DataLoaders created!\n",
      "   Train samples: 7365, Val samples: 491\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Creating DataLoaders ---\")\n",
    "train_dataset = FinalBladeDataset(root=config.DATA_ROOT, split='train')\n",
    "val_dataset = FinalBladeDataset(root=config.DATA_ROOT, split='valid')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.BATCH_SIZE, shuffle=True,\n",
    "    num_workers=config.NUM_WORKERS, collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=config.BATCH_SIZE, shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS, collate_fn=collate_fn\n",
    ")\n",
    "print(f\"✅ DataLoaders created!\")\n",
    "print(f\"   Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3731d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Model, Criterion, Optimizer ---\n",
      "✅ Initialization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_42148\\911795868.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# ===== 셀 4: 모델, 손실함수, 옵티마이저 초기화 (수정) =====\n",
    "\n",
    "print(\"--- Initializing Model, Criterion, Optimizer ---\")\n",
    "model = BladeModelV2(config).to(config.DEVICE)\n",
    "\n",
    "matcher = HungarianMatcher(cost_class=2.0, cost_mask=5.0, cost_dice=5.0)\n",
    "# 수정된 weight_dict (손상 탐지의 중요도를 크게 높임)\n",
    "weight_dict = {'loss_ce': 5.0, 'loss_mask': 10.0, 'loss_dice': 10.0}\n",
    "\n",
    "criterion = SetCriterion(\n",
    "    num_classes=config.MODEL.HEAD_B.NUM_CLASSES, matcher=matcher, weight_dict=weight_dict,\n",
    "    eos_coef=config.LOSS.EOS_COEF, losses=['labels', 'masks'],\n",
    "    class_weights=config.LOSS.CLASS_WEIGHTS\n",
    ").to(config.DEVICE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- [수정] 학습률 스케줄러 설정 ---\n",
    "lr_scheduler = StepLR(optimizer, step_size=config.LR_DROP_STEP)\n",
    "\n",
    "print(\"✅ Initialization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae72ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# torchmetrics 라이브러리 임포트\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "\n",
    "# ==============================================================================\n",
    "# 학습 함수 (train_epoch)\n",
    "# ==============================================================================\n",
    "def train_epoch(model, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Stage 1: Train Blade]\")\n",
    "    \n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device)\n",
    "        targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # --- [1단계 수정] 블레이드 손실만 계산 ---\n",
    "            blade_logits = outputs['blade_logits']\n",
    "            gt_blade_masks = torch.stack([t['blade_mask'] for t in targets_gpu]).unsqueeze(1).float()\n",
    "            blade_logits_resized = F.interpolate(blade_logits, size=gt_blade_masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            \n",
    "            loss_blade = F.binary_cross_entropy_with_logits(blade_logits_resized, gt_blade_masks)\n",
    "            weighted_loss = loss_blade # 최종 손실은 이제 블레이드 손실만 해당\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(weighted_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.GRADIENT_CLIP_VAL)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += weighted_loss.item()\n",
    "        pbar.set_postfix({'loss': f'{weighted_loss.item():.4f}'})\n",
    "        \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    blade_iou_metric = MulticlassJaccardIndex(num_classes=2).to(device)\n",
    "    val_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"[Valid]\")\n",
    "        for images, targets in pbar:\n",
    "            images = images.to(device)\n",
    "            targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # --- [1단계 수정] 블레이드 손실만 계산 ---\n",
    "                blade_logits = outputs['blade_logits']\n",
    "                gt_blade_masks = torch.stack([t['blade_mask'] for t in targets_gpu]).unsqueeze(1).float()\n",
    "                blade_logits_resized = F.interpolate(blade_logits, size=gt_blade_masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "                loss_blade = F.binary_cross_entropy_with_logits(blade_logits_resized, gt_blade_masks)\n",
    "            \n",
    "            val_losses.append(loss_blade.item())\n",
    "            \n",
    "            # Blade IoU 계산\n",
    "            pred_blade_masks = (torch.sigmoid(blade_logits_resized) > 0.5).int().squeeze(1)\n",
    "            blade_iou_metric.update(pred_blade_masks, gt_blade_masks.squeeze(1).int())\n",
    "\n",
    "    metrics = {\n",
    "        'loss': np.mean(val_losses),\n",
    "        'blade_iou': blade_iou_metric.compute().item(),\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbab2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 🚀 Starting Stage 1 Training: Blade Expert 🚀 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Stage 1: Train Blade]:   0%|          | 0/1842 [00:00<?, ?it/s]C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_42148\\3467118361.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/15 [Stage 1: Train Blade]: 100%|██████████| 1842/1842 [04:12<00:00,  7.30it/s, loss=0.2358]\n",
      "[Valid]:   0%|          | 0/123 [00:00<?, ?it/s]C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_42148\\3467118361.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "[Valid]: 100%|██████████| 123/123 [00:09<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15 -> Train Loss: 0.2651, Val Loss: 0.0800\n",
      "  [Metrics] Blade IoU: 0.9418\n",
      "✨ New best blade expert model saved with validation loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Stage 1: Train Blade]: 100%|██████████| 1842/1842 [04:13<00:00,  7.27it/s, loss=0.0257]\n",
      "[Valid]: 100%|██████████| 123/123 [00:09<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/15 -> Train Loss: 0.1812, Val Loss: 0.0729\n",
      "  [Metrics] Blade IoU: 0.9498\n",
      "✨ New best blade expert model saved with validation loss: 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Stage 1: Train Blade]: 100%|██████████| 1842/1842 [04:13<00:00,  7.27it/s, loss=0.0138]\n",
      "[Valid]: 100%|██████████| 123/123 [00:09<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/15 -> Train Loss: 0.1533, Val Loss: 0.0726\n",
      "  [Metrics] Blade IoU: 0.9502\n",
      "✨ New best blade expert model saved with validation loss: 0.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Stage 1: Train Blade]:  39%|███▉      | 722/1842 [01:39<02:35,  7.18it/s, loss=0.8343]"
     ]
    }
   ],
   "source": [
    "# ===== 셀 6의 메인 학습 루프를 아래 코드로 교체 =====\n",
    "\n",
    "print(\"\\n--- 🚀 Starting Stage 1 Training: Blade Expert 🚀 ---\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "    # --- [수정] criterion 인자 제거 ---\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, config.DEVICE, epoch)\n",
    "    val_metrics = validate(model, val_loader, config.DEVICE)\n",
    "    \n",
    "    val_loss = val_metrics['loss']\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{config.EPOCHS} -> Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  [Metrics] Blade IoU: {val_metrics['blade_iou']:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'blade_expert_model.pth')\n",
    "        print(f\"✨ New best blade expert model saved with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\n--- 🎉 Stage 1 Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 🚀 Initializing Stage 2: Damage Expert Training 🚀 ---\")\n",
    "\n",
    "# 1. 새로운 모델 객체 생성\n",
    "# (이전 학습의 영향을 받지 않는 깨끗한 모델로 시작)\n",
    "model = BladeModelV2(config).to(config.DEVICE)\n",
    "\n",
    "# 2. 1단계에서 학습한 '블레이드 전문가' 가중치 불러오기\n",
    "# strict=False는 Head-B의 가중치가 없어도 오류를 내지 않도록 함\n",
    "model.load_state_dict(torch.load('blade_expert_model.pth'), strict=False)\n",
    "print(\"✅ Blade expert weights loaded successfully.\")\n",
    "\n",
    "# 3. Backbone과 Head-A의 가중치 동결 (Freeze)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'head_b' not in name:\n",
    "        param.requires_grad = False\n",
    "        \n",
    "print(\"✅ Backbone and Head-A have been frozen.\")\n",
    "\n",
    "# 4. 학습 가능한 파라미터만 필터링하여 새로운 옵티마이저 생성\n",
    "# (오직 Head-B의 가중치만 업데이트됨)\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = AdamW(trainable_params, lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n",
    "lr_scheduler = StepLR(optimizer, step_size=config.LR_DROP_STEP)\n",
    "\n",
    "print(\"✅ Optimizer re-initialized for Head-B only.\")\n",
    "\n",
    "# 5. 손상 탐지용 Criterion 재정의 (셀 4와 동일)\n",
    "matcher = HungarianMatcher(cost_class=2.0, cost_mask=5.0, cost_dice=5.0)\n",
    "weight_dict = {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0}\n",
    "criterion = SetCriterion(\n",
    "    num_classes=config.MODEL.HEAD_B.NUM_CLASSES, matcher=matcher, weight_dict=weight_dict,\n",
    "    eos_coef=config.LOSS.EOS_COEF, losses=['labels', 'masks'],\n",
    "    class_weights=config.LOSS.CLASS_WEIGHTS\n",
    ").to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_stage2(model, criterion, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    # Head-B만 학습 모드로 설정 (BatchNorm 등 레이어에 영향)\n",
    "    model.head_b.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Stage 2: Train Damage]\")\n",
    "    \n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device)\n",
    "        targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # --- [2단계] 손상 탐지(Head-B) 손실만 계산 ---\n",
    "            loss_dict = criterion(outputs, targets_gpu)\n",
    "            weighted_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(weighted_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.GRADIENT_CLIP_VAL)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += weighted_loss.item()\n",
    "        pbar.set_postfix({'loss': f'{weighted_loss.item():.4f}'})\n",
    "        \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# ==============================================================================\n",
    "# 검증 함수 (validate)\n",
    "# ==============================================================================\n",
    "def validate(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    \n",
    "    # 평가 지표 객체 초기화\n",
    "    blade_iou_metric = MulticlassJaccardIndex(num_classes=2).to(device)\n",
    "    map_metric = MeanAveragePrecision(iou_type=\"segm\") # 경고 메시지 제거\n",
    "\n",
    "    val_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"[Valid]\")\n",
    "        for images, targets in pbar:\n",
    "            images = images.to(device)\n",
    "            targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                # --- 손실 계산 ---\n",
    "                loss_dict = criterion(outputs, targets_gpu)\n",
    "                damage_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "                blade_logits = outputs['blade_logits']\n",
    "                gt_blade_masks = torch.stack([t['blade_mask'] for t in targets_gpu]).unsqueeze(1).float()\n",
    "                blade_logits_resized = F.interpolate(blade_logits, size=gt_blade_masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "                loss_blade = F.binary_cross_entropy_with_logits(blade_logits_resized, gt_blade_masks)\n",
    "                weighted_loss = damage_loss + (loss_blade * 1.0)\n",
    "            val_losses.append(weighted_loss.item())\n",
    "\n",
    "            # --- 평가 지표 업데이트 ---\n",
    "            # 1. Blade IoU\n",
    "            pred_blade_masks = (torch.sigmoid(blade_logits_resized) > 0.5).int().squeeze(1)\n",
    "            blade_iou_metric.update(pred_blade_masks, gt_blade_masks.squeeze(1).int())\n",
    "\n",
    "            # 2. mAP 계산을 위한 데이터 형식 변환\n",
    "            # (이전의 가장 안정적인 버전으로 복구)\n",
    "            pred_logits_cpu = outputs['pred_logits'].cpu()\n",
    "            pred_masks_cpu = outputs['pred_masks'].cpu()\n",
    "            \n",
    "            preds_for_map = []\n",
    "            for i in range(len(targets)):\n",
    "                scores, labels = F.softmax(pred_logits_cpu[i], dim=-1).max(-1)\n",
    "                masks_bool = (torch.sigmoid(pred_masks_cpu[i]) > 0.5)\n",
    "                preds_for_map.append(dict(masks=masks_bool, scores=scores, labels=labels))\n",
    "\n",
    "            targets_for_map = []\n",
    "            for t in targets:\n",
    "                targets_for_map.append(dict(masks=(t['masks'] > 0.5), labels=t['labels']))\n",
    "            \n",
    "            map_metric.update(preds_for_map, targets_for_map)\n",
    "\n",
    "    # 최종 결과 집계\n",
    "    blade_iou = blade_iou_metric.compute().item()\n",
    "    map_results = map_metric.compute()\n",
    "    \n",
    "    # mAP 결과에서 Precision, Recall, F1-score 근사치 계산\n",
    "    precision = map_results['map_50'].item()\n",
    "    recall = map_results['mar_100'].item()\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "\n",
    "    metrics = {\n",
    "        'loss': np.mean(val_losses),\n",
    "        'blade_iou': blade_iou,\n",
    "        'mAP': map_results['map'].item(),\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# validate 함수는 이전의 최종 버전을 그대로 사용해도 됩니다.\n",
    "# (모든 지표를 계산하는 최종 validate 함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7bea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 🚀 Starting Stage 2 Training: Damage Expert 🚀 ---\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# 2단계 학습을 위해 EPOCHS를 다시 설정할 수 있습니다.\n",
    "# 예: config.EPOCHS = 30\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train_loss = train_epoch_stage2(model, criterion, train_loader, optimizer, config.DEVICE, epoch)\n",
    "    val_metrics = validate(model, criterion, val_loader, config.DEVICE)\n",
    "    \n",
    "    val_loss = val_metrics['loss']\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{config.EPOCHS} -> Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  [Damage] mAP: {val_metrics['mAP']:.4f} | Precision: {val_metrics['precision']:.4f} | \"\n",
    "          f\"Recall: {val_metrics['recall']:.4f} | F1: {val_metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'final_best_model.pth') # <-- 최종 모델 저장\n",
    "        print(f\"✨ New best FINAL model saved with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\n--- 🎉 Stage 2 Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# ===== visualize_predictions 함수 교체 =====\n",
    "\n",
    "def visualize_predictions(model, dataloader, device, num_samples=3, conf_threshold=0.5):\n",
    "    \"\"\"모델의 예측 결과를 시각화합니다.\"\"\"\n",
    "    model.eval()\n",
    "    samples_shown = 0\n",
    "    \n",
    "    # Config에 클래스 이름 리스트가 있다고 가정\n",
    "    # 예: config.MODEL.HEAD_B.CLASSES = ['crack', 'nick', 'tear']\n",
    "    class_names = getattr(config.MODEL.HEAD_B, 'CLASSES', ['crack', 'nick', 'tear'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            if samples_shown >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            images_cpu = images.cpu()\n",
    "            outputs_cpu = {k: v.cpu() for k, v in outputs.items() if torch.is_tensor(v)}\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                if samples_shown >= num_samples:\n",
    "                    break\n",
    "                \n",
    "                image_tensor = images_cpu[i]\n",
    "                target = targets[i]\n",
    "                output = {k: v[i] for k, v in outputs_cpu.items()}\n",
    "                \n",
    "                # 이미지를 Numpy 배열로 변환\n",
    "                img_to_draw = image_tensor.permute(1, 2, 0).numpy()\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                img_to_draw = (img_to_draw * std + mean) * 255\n",
    "                img_to_draw = np.clip(img_to_draw, 0, 255).astype(np.uint8)\n",
    "                \n",
    "                # --- [핵심 수정] 메모리 레이아웃을 OpenCV 호환 형태로 변경 ---\n",
    "                img_to_draw = np.ascontiguousarray(img_to_draw)\n",
    "                \n",
    "                plt.figure(figsize=(12, 12))\n",
    "                \n",
    "                # 1. 정답 마스크 그리기 (초록색, 점선)\n",
    "                for mask in target['masks']:\n",
    "                    contours, _ = cv2.findContours(mask.numpy().astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    cv2.drawContours(img_to_draw, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "                # 2. 예측 마스크 그리기 (빨간색, 실선)\n",
    "                scores, labels = F.softmax(output['pred_logits'], dim=-1).max(-1)\n",
    "                \n",
    "                for j, (score, label) in enumerate(zip(scores, labels)):\n",
    "                    if score > conf_threshold:\n",
    "                        mask = (torch.sigmoid(output['pred_masks'][j]) > 0.5).numpy().astype(np.uint8)\n",
    "                        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        cv2.drawContours(img_to_draw, contours, -1, (255, 0, 0), 2)\n",
    "                        \n",
    "                        cat_name = class_names[label.item()]\n",
    "                        text = f'{cat_name}: {score:.2f}'\n",
    "                        if contours:\n",
    "                            x, y, w, h = cv2.boundingRect(contours[0])\n",
    "                            cv2.putText(img_to_draw, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                plt.imshow(img_to_draw)\n",
    "                plt.title(f\"Sample {samples_shown+1} (Green: Ground Truth, Red: Prediction)\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "                samples_shown += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model.load_state_dict(torch.load('blade_damage_best_model.pth'))\n",
    "# 시각화 함수 실행\n",
    "visualize_predictions(model, val_loader, config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc24d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
