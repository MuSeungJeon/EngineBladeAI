{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2640b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# pycocotools가 필요합니다. pip install pycocotools\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# --- 프로젝트 경로 추가 및 모듈 임포트 ---\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from models.blade_model_v2 import BladeModelV2\n",
    "from utils.criterion import SetCriterion\n",
    "from utils.hungarian_matcher import HungarianMatcher\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# --- 최종 설정 (Configuration) ---\n",
    "class Config:\n",
    "    DATA_ROOT = Path('C:/EngineBladeAI/EngineInspectionAI_MS/data/final_dataset_augmented')\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # --- 학습 하이퍼파라미터 (수정) ---\n",
    "    BATCH_SIZE = 4\n",
    "    EPOCHS = 50\n",
    "    LR = 2e-5  # <-- [수정] 1e-4는 너무 높았으므로, 2e-5 (0.00002)로 낮춥니다.\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    NUM_WORKERS = 0\n",
    "    LR_DROP_STEP = 20\n",
    "    GRADIENT_CLIP_VAL = 1.0 # <-- [추가] Gradient Clipping 값 설정\n",
    "\n",
    "    MODEL = SimpleNamespace(\n",
    "        # --- [수정] 딕셔너리를 SimpleNamespace로 변경 ---\n",
    "        BACKBONE=SimpleNamespace(NAME='ConvNeXt-Tiny'),\n",
    "        FPN=SimpleNamespace(OUT_CHANNELS=256),\n",
    "        HEAD_B=SimpleNamespace(\n",
    "            FEAT_CHANNELS=256,\n",
    "            OUT_CHANNELS=256,\n",
    "            NUM_CLASSES=3,\n",
    "            QUERIES_PER_CLASS=100,\n",
    "            DEC_LAYERS=6\n",
    "        )\n",
    "    )\n",
    "    LOSS = SimpleNamespace(\n",
    "        CLASS_WEIGHTS=[1.5, 1.0, 1.3], # Crack, Nick, Tear\n",
    "        EOS_COEF=0.1\n",
    "    )\n",
    "\n",
    "config = Config()\n",
    "print(f\"\\n--- Configuration Initialized ---\")\n",
    "print(f\"Data Path: {config.DATA_ROOT}\")\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"Initial Learning Rate: {config.LR}\") # <-- 확인용 print 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalBladeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    최종 통합된 데이터셋(final_dataset)을 위한 Dataset 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, split='train', transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.split = split\n",
    "        self.images_dir = self.root / self.split / 'images'\n",
    "        \n",
    "        json_path = self.root / self.split / 'annotations.json'\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "            \n",
    "        self.images_info = self.data['images']\n",
    "        self.annotations_map = {}\n",
    "        for ann in self.data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.annotations_map:\n",
    "                self.annotations_map[img_id] = []\n",
    "            self.annotations_map[img_id].append(ann)\n",
    "            \n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((640, 640)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images_info[idx]\n",
    "        img_id = img_info['id']\n",
    "        img_path = self.images_dir / img_info['file_name']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        original_w, original_h = image.size\n",
    "        \n",
    "        target = {}\n",
    "        blade_mask = np.zeros((original_h, original_w), dtype=np.uint8)\n",
    "        damage_masks_np = []\n",
    "        damage_labels = []\n",
    "        multilabel_vector = torch.zeros(3, dtype=torch.float32)\n",
    "\n",
    "        annotations = self.annotations_map.get(img_id, [])\n",
    "        for ann in annotations:\n",
    "            # --- [핵심 수정] ---\n",
    "            # segmentation 데이터가 유효한지 확인하는 방어 코드 추가\n",
    "            seg = ann.get('segmentation')\n",
    "            if not seg or not isinstance(seg, list) or not seg[0] or len(seg[0]) < 6:\n",
    "                # 유효하지 않은 polygon (최소 3개의 점 필요)이면 건너뛰기\n",
    "                continue\n",
    "                \n",
    "            cat_id = ann['category_id']\n",
    "            \n",
    "            try:\n",
    "                rle = mask_utils.frPyObjects([seg[0]], original_h, original_w)\n",
    "                mask = mask_utils.decode(rle)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to decode segmentation for ann_id {ann.get('id')}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            if mask.ndim == 3:\n",
    "                mask = np.max(mask, axis=2)\n",
    "\n",
    "            if cat_id == 1:\n",
    "                blade_mask = np.maximum(blade_mask, mask)\n",
    "            else:\n",
    "                damage_masks_np.append(mask)\n",
    "                damage_labels.append(cat_id - 2)\n",
    "                multilabel_vector[cat_id - 2] = 1.0\n",
    "\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        target['blade_mask'] = torch.from_numpy(blade_mask).long()\n",
    "        target['labels'] = torch.tensor(damage_labels, dtype=torch.int64)\n",
    "        target['multilabel'] = multilabel_vector\n",
    "        \n",
    "        if damage_masks_np:\n",
    "            damage_masks_tensor = torch.from_numpy(np.stack(damage_masks_np)).float()\n",
    "            target['masks'] = damage_masks_tensor\n",
    "        else:\n",
    "            target['masks'] = torch.zeros((0, original_h, original_w), dtype=torch.float32)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    images = torch.stack(images, dim=0)\n",
    "    return images, targets\n",
    "\n",
    "print(\"✅ Dataset class and collate_fn are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f32742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Creating DataLoaders ---\")\n",
    "train_dataset = FinalBladeDataset(root=config.DATA_ROOT, split='train')\n",
    "val_dataset = FinalBladeDataset(root=config.DATA_ROOT, split='valid')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.BATCH_SIZE, shuffle=True,\n",
    "    num_workers=config.NUM_WORKERS, collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=config.BATCH_SIZE, shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS, collate_fn=collate_fn\n",
    ")\n",
    "print(f\"✅ DataLoaders created!\")\n",
    "print(f\"   Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3731d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 4: 모델, 손실함수, 옵티마이저 초기화 (수정) =====\n",
    "\n",
    "print(\"--- Initializing Model, Criterion, Optimizer ---\")\n",
    "model = BladeModelV2(config).to(config.DEVICE)\n",
    "\n",
    "matcher = HungarianMatcher(cost_class=2.0, cost_mask=5.0, cost_dice=5.0)\n",
    "# 수정된 weight_dict (손상 탐지의 중요도를 크게 높임)\n",
    "weight_dict = {'loss_ce': 5.0, 'loss_mask': 10.0, 'loss_dice': 10.0}\n",
    "\n",
    "criterion = SetCriterion(\n",
    "    num_classes=config.MODEL.HEAD_B.NUM_CLASSES, matcher=matcher, weight_dict=weight_dict,\n",
    "    eos_coef=config.LOSS.EOS_COEF, losses=['labels', 'masks'],\n",
    "    class_weights=config.LOSS.CLASS_WEIGHTS\n",
    ").to(config.DEVICE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- [수정] 학습률 스케줄러 설정 ---\n",
    "lr_scheduler = StepLR(optimizer, step_size=config.LR_DROP_STEP)\n",
    "\n",
    "print(\"✅ Initialization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae72ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchmetrics에서 필요한 모든 평가 지표 클래스를 임포트합니다.\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "from torchmetrics.classification import MulticlassJaccardIndex # Blade IoU용\n",
    "\n",
    "\n",
    "# train_epoch 함수는 그대로 둡니다.\n",
    "def train_epoch(model, criterion, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    total_loss = 0\n",
    "    blade_loss_weight = 1.0\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Train]\")\n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device)\n",
    "        targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss_dict = criterion(outputs, targets_gpu)\n",
    "            damage_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "            blade_logits = outputs['blade_logits']\n",
    "            gt_blade_masks = torch.stack([t['blade_mask'] for t in targets_gpu]).unsqueeze(1).float()\n",
    "            blade_logits_resized = F.interpolate(blade_logits, size=gt_blade_masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            loss_blade = F.binary_cross_entropy_with_logits(blade_logits_resized, gt_blade_masks)\n",
    "            weighted_loss = damage_loss + (loss_blade * blade_loss_weight)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(weighted_loss).backward()\n",
    "        \n",
    "        # --- [추가] Gradient Clipping ---\n",
    "        # scaler가 unscale을 한 후에 clipping을 적용해야 함\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.GRADIENT_CLIP_VAL)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += weighted_loss.item()\n",
    "        pbar.set_postfix({'loss': f'{weighted_loss.item():.4f}', 'L_dmg': f'{damage_loss.item():.2f}', 'L_bld': f'{loss_blade.item():.2f}'})\n",
    "        \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def validate(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    \n",
    "    # --- [최종 수정] Detection 전용 평가 지표 객체 초기화 ---\n",
    "    num_damage_classes = config.MODEL.HEAD_B.NUM_CLASSES\n",
    "    # 1. Blade IoU (이전과 동일)\n",
    "    blade_iou_metric = MulticlassJaccardIndex(num_classes=2).to(device)\n",
    "    # 2. Damage mAP (탐지 문제의 표준 평가 지표)\n",
    "    map_metric = MeanAveragePrecision(iou_type=\"segm\")\n",
    "\n",
    "    val_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"[Valid]\")\n",
    "        for images, targets in pbar:\n",
    "            images = images.to(device)\n",
    "            targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                # --- 손실 계산 (기존과 동일) ---\n",
    "                loss_dict = criterion(outputs, targets_gpu)\n",
    "                damage_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "                blade_logits = outputs['blade_logits']\n",
    "                gt_blade_masks = torch.stack([t['blade_mask'] for t in targets_gpu]).unsqueeze(1).float()\n",
    "                blade_logits_resized = F.interpolate(blade_logits, size=gt_blade_masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "                loss_blade = F.binary_cross_entropy_with_logits(blade_logits_resized, gt_blade_masks)\n",
    "                weighted_loss = damage_loss + (loss_blade * 1.0)\n",
    "            val_losses.append(weighted_loss.item())\n",
    "            \n",
    "            # --- [최종 수정] 평가 지표 업데이트 ---\n",
    "            # 1. Blade IoU\n",
    "            pred_blade_masks = (torch.sigmoid(blade_logits_resized) > 0.5).int().squeeze(1)\n",
    "            blade_iou_metric.update(pred_blade_masks, gt_blade_masks.squeeze(1).int())\n",
    "\n",
    "            # 2. mAP 계산을 위한 데이터 형식 변환\n",
    "            pred_logits = outputs['pred_logits'].cpu()\n",
    "            pred_masks = outputs['pred_masks'].cpu()\n",
    "            \n",
    "            preds_for_map = []\n",
    "            for i in range(len(targets)):\n",
    "                scores, labels = F.softmax(pred_logits[i], dim=-1).max(-1)\n",
    "                masks_bool = (torch.sigmoid(pred_masks[i]) > 0.5)\n",
    "                \n",
    "                preds_for_map.append(dict(\n",
    "                    masks=masks_bool, scores=scores, labels=labels,\n",
    "                ))\n",
    "\n",
    "            targets_for_map = []\n",
    "            for t in targets:\n",
    "                targets_for_map.append(dict(\n",
    "                    masks=(t['masks'] > 0.5), labels=t['labels'],\n",
    "                ))\n",
    "            \n",
    "            map_metric.update(preds_for_map, targets_for_map)\n",
    "\n",
    "    # --- [최종 수정] 모든 지표 계산 및 집계 ---\n",
    "    blade_iou = blade_iou_metric.compute().item()\n",
    "    map_results = map_metric.compute()\n",
    "    \n",
    "    # mAP 결과에서 Precision, Recall 추출\n",
    "    precision = map_results['map_50'].item() # mAP@50은 Precision-Recall 곡선의 면적\n",
    "    recall = map_results['mar_100'].item() # 100개 예측 시 평균 재현율\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "\n",
    "    metrics = {\n",
    "        'loss': np.mean(val_losses),\n",
    "        'blade_iou': blade_iou,\n",
    "        'mAP': map_results['map'].item(),\n",
    "        'precision': precision, # 근사치\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbab2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 셀 6의 메인 학습 루프를 아래 코드로 교체 =====\n",
    "\n",
    "print(\"\\n--- 🚀 Starting Final Training 🚀 ---\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train_loss = train_epoch(model, criterion, train_loader, optimizer, config.DEVICE, epoch)\n",
    "    val_metrics = validate(model, criterion, val_loader, config.DEVICE)\n",
    "    \n",
    "    val_loss = val_metrics['loss']\n",
    "    \n",
    "    # --- [최종 수정] 새로운 지표들 출력 ---\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.EPOCHS} -> Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  [Blade] IoU: {val_metrics['blade_iou']:.4f}\")\n",
    "    print(f\"  [Damage] mAP: {val_metrics['mAP']:.4f} | Precision: {val_metrics['precision']:.4f} | \"\n",
    "          f\"Recall: {val_metrics['recall']:.4f} | F1: {val_metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'blade_damage_best_model.pth')\n",
    "        print(f\"✨ New best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\n--- 🎉 Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06d87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
