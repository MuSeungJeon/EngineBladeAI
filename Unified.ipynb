{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2640b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu121\n",
      "CUDA Available: True\n",
      "\n",
      "--- Configuration Initialized ---\n",
      "Data Path: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\final_dataset_augmented\n",
      "Device: cuda\n",
      "Initial Learning Rate: 2e-05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# pycocotoolsÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§. pip install pycocotools\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "# --- ÌîÑÎ°úÏ†ùÌä∏ Í≤ΩÎ°ú Ï∂îÍ∞Ä Î∞è Î™®Îìà ÏûÑÌè¨Ìä∏ ---\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from models.blade_model_v2 import BladeModelV2\n",
    "from utils.criterion import SetCriterion\n",
    "from utils.hungarian_matcher import HungarianMatcher\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# --- ÏµúÏ¢Ö ÏÑ§Ï†ï (Configuration) ---\n",
    "class Config:\n",
    "    DATA_ROOT = Path('C:/EngineBladeAI/EngineInspectionAI_MS/data/final_dataset_augmented')\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # --- ÌïôÏäµ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ (ÏàòÏ†ï) ---\n",
    "    BATCH_SIZE = 4\n",
    "    EPOCHS = 15 # <-- 1Îã®Í≥Ñ ÌïôÏäµÏùÑ ÏúÑÌï¥ ÏóêÌè¨ÌÅ¨ Ïàò Ï°∞Ï†ï\n",
    "    LR = 2e-5 \n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    NUM_WORKERS = 0\n",
    "    LR_DROP_STEP = 20\n",
    "    GRADIENT_CLIP_VAL = 1.0 # <-- [Ï∂îÍ∞Ä] Gradient Clipping Í∞í ÏÑ§Ï†ï\n",
    "\n",
    "    MODEL = SimpleNamespace(\n",
    "        # --- [ÏàòÏ†ï] ÎîïÏÖîÎÑàÎ¶¨Î•º SimpleNamespaceÎ°ú Î≥ÄÍ≤Ω ---\n",
    "        BACKBONE=SimpleNamespace(NAME='ConvNeXt-Tiny'),\n",
    "        FPN=SimpleNamespace(OUT_CHANNELS=256),\n",
    "        HEAD_B=SimpleNamespace(\n",
    "            FEAT_CHANNELS=256,\n",
    "            OUT_CHANNELS=256,\n",
    "            NUM_CLASSES=3,\n",
    "            QUERIES_PER_CLASS=100,\n",
    "            DEC_LAYERS=6\n",
    "        )\n",
    "    )\n",
    "    LOSS = SimpleNamespace(\n",
    "        CLASS_WEIGHTS=[1.5, 1.0, 1.3], # Crack, Nick, Tear\n",
    "        EOS_COEF=0.1\n",
    "    )\n",
    "\n",
    "config = Config()\n",
    "print(f\"\\n--- Configuration Initialized ---\")\n",
    "print(f\"Data Path: {config.DATA_ROOT}\")\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"Initial Learning Rate: {config.LR}\") # <-- ÌôïÏù∏Ïö© print Ï∂îÍ∞Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d111756a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset class and collate_fn are defined.\n"
     ]
    }
   ],
   "source": [
    "class FinalBladeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ÏµúÏ¢Ö ÌÜµÌï©Îêú Îç∞Ïù¥ÌÑ∞ÏÖã(final_dataset)ÏùÑ ÏúÑÌïú Dataset ÌÅ¥ÎûòÏä§.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, split='train', transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.split = split\n",
    "        self.images_dir = self.root / self.split / 'images'\n",
    "        \n",
    "        json_path = self.root / self.split / 'annotations.json'\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "            \n",
    "        self.images_info = self.data['images']\n",
    "        self.annotations_map = {}\n",
    "        for ann in self.data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.annotations_map:\n",
    "                self.annotations_map[img_id] = []\n",
    "            self.annotations_map[img_id].append(ann)\n",
    "            \n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((640, 640)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images_info[idx]\n",
    "        img_id = img_info['id']\n",
    "        img_path = self.images_dir / img_info['file_name']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        original_w, original_h = image.size\n",
    "        \n",
    "        target = {}\n",
    "        blade_mask = np.zeros((original_h, original_w), dtype=np.uint8)\n",
    "        damage_masks_np = []\n",
    "        damage_labels = []\n",
    "        multilabel_vector = torch.zeros(3, dtype=torch.float32)\n",
    "\n",
    "        annotations = self.annotations_map.get(img_id, [])\n",
    "        for ann in annotations:\n",
    "            # --- [ÌïµÏã¨ ÏàòÏ†ï] ---\n",
    "            # segmentation Îç∞Ïù¥ÌÑ∞Í∞Ä Ïú†Ìö®ÌïúÏßÄ ÌôïÏù∏ÌïòÎäî Î∞©Ïñ¥ ÏΩîÎìú Ï∂îÍ∞Ä\n",
    "            seg = ann.get('segmentation')\n",
    "            if not seg or not isinstance(seg, list) or not seg[0] or len(seg[0]) < 6:\n",
    "                # Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ polygon (ÏµúÏÜå 3Í∞úÏùò Ï†ê ÌïÑÏöî)Ïù¥Î©¥ Í±¥ÎÑàÎõ∞Í∏∞\n",
    "                continue\n",
    "                \n",
    "            cat_id = ann['category_id']\n",
    "            \n",
    "            try:\n",
    "                rle = mask_utils.frPyObjects([seg[0]], original_h, original_w)\n",
    "                mask = mask_utils.decode(rle)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to decode segmentation for ann_id {ann.get('id')}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            if mask.ndim == 3:\n",
    "                mask = np.max(mask, axis=2)\n",
    "\n",
    "            if cat_id == 1:\n",
    "                blade_mask = np.maximum(blade_mask, mask)\n",
    "            else:\n",
    "                damage_masks_np.append(mask)\n",
    "                damage_labels.append(cat_id - 2)\n",
    "                multilabel_vector[cat_id - 2] = 1.0\n",
    "\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        target['blade_mask'] = torch.from_numpy(blade_mask).long()\n",
    "        target['labels'] = torch.tensor(damage_labels, dtype=torch.int64)\n",
    "        target['multilabel'] = multilabel_vector\n",
    "        \n",
    "        if damage_masks_np:\n",
    "            damage_masks_tensor = torch.from_numpy(np.stack(damage_masks_np)).float()\n",
    "            target['masks'] = damage_masks_tensor\n",
    "        else:\n",
    "            target['masks'] = torch.zeros((0, original_h, original_w), dtype=torch.float32)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    images = torch.stack(images, dim=0)\n",
    "    return images, targets\n",
    "\n",
    "print(\"‚úÖ Dataset class and collate_fn are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f32742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating DataLoaders ---\n",
      "‚úÖ DataLoaders created!\n",
      "   Train samples: 7365, Val samples: 491\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Creating DataLoaders ---\")\n",
    "train_dataset = FinalBladeDataset(root=config.DATA_ROOT, split='train')\n",
    "val_dataset = FinalBladeDataset(root=config.DATA_ROOT, split='valid')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.BATCH_SIZE, shuffle=True,\n",
    "    num_workers=config.NUM_WORKERS, collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=config.BATCH_SIZE, shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS, collate_fn=collate_fn\n",
    ")\n",
    "print(f\"‚úÖ DataLoaders created!\")\n",
    "print(f\"   Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3731d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Model, Criterion, Optimizer ---\n",
      "‚úÖ Initialization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_42148\\911795868.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# ===== ÏÖÄ 4: Î™®Îç∏, ÏÜêÏã§Ìï®Ïàò, ÏòµÌã∞ÎßàÏù¥Ï†Ä Ï¥àÍ∏∞Ìôî (ÏàòÏ†ï) =====\n",
    "\n",
    "print(\"--- Initializing Model, Criterion, Optimizer ---\")\n",
    "model = BladeModelV2(config).to(config.DEVICE)\n",
    "\n",
    "matcher = HungarianMatcher(cost_class=2.0, cost_mask=5.0, cost_dice=5.0)\n",
    "# ÏàòÏ†ïÎêú weight_dict (ÏÜêÏÉÅ ÌÉêÏßÄÏùò Ï§ëÏöîÎèÑÎ•º ÌÅ¨Í≤å ÎÜíÏûÑ)\n",
    "weight_dict = {'loss_ce': 5.0, 'loss_mask': 10.0, 'loss_dice': 10.0}\n",
    "\n",
    "criterion = SetCriterion(\n",
    "    num_classes=config.MODEL.HEAD_B.NUM_CLASSES, matcher=matcher, weight_dict=weight_dict,\n",
    "    eos_coef=config.LOSS.EOS_COEF, losses=['labels', 'masks'],\n",
    "    class_weights=config.LOSS.CLASS_WEIGHTS\n",
    ").to(config.DEVICE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- [ÏàòÏ†ï] ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï ---\n",
    "lr_scheduler = StepLR(optimizer, step_size=config.LR_DROP_STEP)\n",
    "\n",
    "print(\"‚úÖ Initialization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae72ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# torchmetrics ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "\n",
    "# ==============================================================================\n",
    "# ÌïôÏäµ Ìï®Ïàò (train_epoch)\n",
    "# ==============================================================================\n",
    "def train_epoch(model, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Stage 1: Train Blade]\")\n",
    "    \n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device)\n",
    "        targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # --- [1Îã®Í≥Ñ ÏàòÏ†ï] Î∏îÎ†àÏù¥Îìú ÏÜêÏã§Îßå Í≥ÑÏÇ∞ ---\n",
    "            blade_logits = outputs['blade_logits']\n",
    "            gt_blade_masks = torch.stack([t['blade_mask'] for t in targets_gpu]).unsqueeze(1).float()\n",
    "            blade_logits_resized = F.interpolate(blade_logits, size=gt_blade_masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            \n",
    "            loss_blade = F.binary_cross_entropy_with_logits(blade_logits_resized, gt_blade_masks)\n",
    "            weighted_loss = loss_blade # ÏµúÏ¢Ö ÏÜêÏã§ÏùÄ Ïù¥Ï†ú Î∏îÎ†àÏù¥Îìú ÏÜêÏã§Îßå Ìï¥Îãπ\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(weighted_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.GRADIENT_CLIP_VAL)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += weighted_loss.item()\n",
    "        pbar.set_postfix({'loss': f'{weighted_loss.item():.4f}'})\n",
    "        \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    blade_iou_metric = MulticlassJaccardIndex(num_classes=2).to(device)\n",
    "    val_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"[Valid]\")\n",
    "        for images, targets in pbar:\n",
    "            images = images.to(device)\n",
    "            targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # --- [1Îã®Í≥Ñ ÏàòÏ†ï] Î∏îÎ†àÏù¥Îìú ÏÜêÏã§Îßå Í≥ÑÏÇ∞ ---\n",
    "                blade_logits = outputs['blade_logits']\n",
    "                gt_blade_masks = torch.stack([t['blade_mask'] for t in targets_gpu]).unsqueeze(1).float()\n",
    "                blade_logits_resized = F.interpolate(blade_logits, size=gt_blade_masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "                loss_blade = F.binary_cross_entropy_with_logits(blade_logits_resized, gt_blade_masks)\n",
    "            \n",
    "            val_losses.append(loss_blade.item())\n",
    "            \n",
    "            # Blade IoU Í≥ÑÏÇ∞\n",
    "            pred_blade_masks = (torch.sigmoid(blade_logits_resized) > 0.5).int().squeeze(1)\n",
    "            blade_iou_metric.update(pred_blade_masks, gt_blade_masks.squeeze(1).int())\n",
    "\n",
    "    metrics = {\n",
    "        'loss': np.mean(val_losses),\n",
    "        'blade_iou': blade_iou_metric.compute().item(),\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbab2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üöÄ Starting Stage 1 Training: Blade Expert üöÄ ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Stage 1: Train Blade]:   0%|          | 0/1842 [00:00<?, ?it/s]C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_42148\\3467118361.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/15 [Stage 1: Train Blade]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1842/1842 [04:12<00:00,  7.30it/s, loss=0.2358]\n",
      "[Valid]:   0%|          | 0/123 [00:00<?, ?it/s]C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_42148\\3467118361.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "[Valid]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:09<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15 -> Train Loss: 0.2651, Val Loss: 0.0800\n",
      "  [Metrics] Blade IoU: 0.9418\n",
      "‚ú® New best blade expert model saved with validation loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Stage 1: Train Blade]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1842/1842 [04:13<00:00,  7.27it/s, loss=0.0257]\n",
      "[Valid]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:09<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/15 -> Train Loss: 0.1812, Val Loss: 0.0729\n",
      "  [Metrics] Blade IoU: 0.9498\n",
      "‚ú® New best blade expert model saved with validation loss: 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Stage 1: Train Blade]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1842/1842 [04:13<00:00,  7.27it/s, loss=0.0138]\n",
      "[Valid]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 123/123 [00:09<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/15 -> Train Loss: 0.1533, Val Loss: 0.0726\n",
      "  [Metrics] Blade IoU: 0.9502\n",
      "‚ú® New best blade expert model saved with validation loss: 0.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Stage 1: Train Blade]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 722/1842 [01:39<02:35,  7.18it/s, loss=0.8343]"
     ]
    }
   ],
   "source": [
    "# ===== ÏÖÄ 6Ïùò Î©îÏù∏ ÌïôÏäµ Î£®ÌîÑÎ•º ÏïÑÎûò ÏΩîÎìúÎ°ú ÍµêÏ≤¥ =====\n",
    "\n",
    "print(\"\\n--- üöÄ Starting Stage 1 Training: Blade Expert üöÄ ---\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "    # --- [ÏàòÏ†ï] criterion Ïù∏Ïûê Ï†úÍ±∞ ---\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, config.DEVICE, epoch)\n",
    "    val_metrics = validate(model, val_loader, config.DEVICE)\n",
    "    \n",
    "    val_loss = val_metrics['loss']\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{config.EPOCHS} -> Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  [Metrics] Blade IoU: {val_metrics['blade_iou']:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'blade_expert_model.pth')\n",
    "        print(f\"‚ú® New best blade expert model saved with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\n--- üéâ Stage 1 Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- üöÄ Initializing Stage 2: Damage Expert Training üöÄ ---\")\n",
    "\n",
    "# 1. ÏÉàÎ°úÏö¥ Î™®Îç∏ Í∞ùÏ≤¥ ÏÉùÏÑ±\n",
    "# (Ïù¥Ï†Ñ ÌïôÏäµÏùò ÏòÅÌñ•ÏùÑ Î∞õÏßÄ ÏïäÎäî Íπ®ÎÅóÌïú Î™®Îç∏Î°ú ÏãúÏûë)\n",
    "model = BladeModelV2(config).to(config.DEVICE)\n",
    "\n",
    "# 2. 1Îã®Í≥ÑÏóêÏÑú ÌïôÏäµÌïú 'Î∏îÎ†àÏù¥Îìú Ï†ÑÎ¨∏Í∞Ä' Í∞ÄÏ§ëÏπò Î∂àÎü¨Ïò§Í∏∞\n",
    "# strict=FalseÎäî Head-BÏùò Í∞ÄÏ§ëÏπòÍ∞Ä ÏóÜÏñ¥ÎèÑ Ïò§Î•òÎ•º ÎÇ¥ÏßÄ ÏïäÎèÑÎ°ù Ìï®\n",
    "model.load_state_dict(torch.load('blade_expert_model.pth'), strict=False)\n",
    "print(\"‚úÖ Blade expert weights loaded successfully.\")\n",
    "\n",
    "# 3. BackboneÍ≥º Head-AÏùò Í∞ÄÏ§ëÏπò ÎèôÍ≤∞ (Freeze)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'head_b' not in name:\n",
    "        param.requires_grad = False\n",
    "        \n",
    "print(\"‚úÖ Backbone and Head-A have been frozen.\")\n",
    "\n",
    "# 4. ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞Îßå ÌïÑÌÑ∞ÎßÅÌïòÏó¨ ÏÉàÎ°úÏö¥ ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÉùÏÑ±\n",
    "# (Ïò§ÏßÅ Head-BÏùò Í∞ÄÏ§ëÏπòÎßå ÏóÖÎç∞Ïù¥Ìä∏Îê®)\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = AdamW(trainable_params, lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n",
    "lr_scheduler = StepLR(optimizer, step_size=config.LR_DROP_STEP)\n",
    "\n",
    "print(\"‚úÖ Optimizer re-initialized for Head-B only.\")\n",
    "\n",
    "# 5. ÏÜêÏÉÅ ÌÉêÏßÄÏö© Criterion Ïû¨Ï†ïÏùò (ÏÖÄ 4ÏôÄ ÎèôÏùº)\n",
    "matcher = HungarianMatcher(cost_class=2.0, cost_mask=5.0, cost_dice=5.0)\n",
    "weight_dict = {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0}\n",
    "criterion = SetCriterion(\n",
    "    num_classes=config.MODEL.HEAD_B.NUM_CLASSES, matcher=matcher, weight_dict=weight_dict,\n",
    "    eos_coef=config.LOSS.EOS_COEF, losses=['labels', 'masks'],\n",
    "    class_weights=config.LOSS.CLASS_WEIGHTS\n",
    ").to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_stage2(model, criterion, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    # Head-BÎßå ÌïôÏäµ Î™®ÎìúÎ°ú ÏÑ§Ï†ï (BatchNorm Îì± Î†àÏù¥Ïñ¥Ïóê ÏòÅÌñ•)\n",
    "    model.head_b.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Stage 2: Train Damage]\")\n",
    "    \n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device)\n",
    "        targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # --- [2Îã®Í≥Ñ] ÏÜêÏÉÅ ÌÉêÏßÄ(Head-B) ÏÜêÏã§Îßå Í≥ÑÏÇ∞ ---\n",
    "            loss_dict = criterion(outputs, targets_gpu)\n",
    "            weighted_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(weighted_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.GRADIENT_CLIP_VAL)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += weighted_loss.item()\n",
    "        pbar.set_postfix({'loss': f'{weighted_loss.item():.4f}'})\n",
    "        \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# ==============================================================================\n",
    "# Í≤ÄÏ¶ù Ìï®Ïàò (validate)\n",
    "# ==============================================================================\n",
    "def validate(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    \n",
    "    # ÌèâÍ∞Ä ÏßÄÌëú Í∞ùÏ≤¥ Ï¥àÍ∏∞Ìôî\n",
    "    blade_iou_metric = MulticlassJaccardIndex(num_classes=2).to(device)\n",
    "    map_metric = MeanAveragePrecision(iou_type=\"segm\") # Í≤ΩÍ≥† Î©îÏãúÏßÄ Ï†úÍ±∞\n",
    "\n",
    "    val_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"[Valid]\")\n",
    "        for images, targets in pbar:\n",
    "            images = images.to(device)\n",
    "            targets_gpu = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                # --- ÏÜêÏã§ Í≥ÑÏÇ∞ ---\n",
    "                loss_dict = criterion(outputs, targets_gpu)\n",
    "                damage_loss = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "                blade_logits = outputs['blade_logits']\n",
    "                gt_blade_masks = torch.stack([t['blade_mask'] for t in targets_gpu]).unsqueeze(1).float()\n",
    "                blade_logits_resized = F.interpolate(blade_logits, size=gt_blade_masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "                loss_blade = F.binary_cross_entropy_with_logits(blade_logits_resized, gt_blade_masks)\n",
    "                weighted_loss = damage_loss + (loss_blade * 1.0)\n",
    "            val_losses.append(weighted_loss.item())\n",
    "\n",
    "            # --- ÌèâÍ∞Ä ÏßÄÌëú ÏóÖÎç∞Ïù¥Ìä∏ ---\n",
    "            # 1. Blade IoU\n",
    "            pred_blade_masks = (torch.sigmoid(blade_logits_resized) > 0.5).int().squeeze(1)\n",
    "            blade_iou_metric.update(pred_blade_masks, gt_blade_masks.squeeze(1).int())\n",
    "\n",
    "            # 2. mAP Í≥ÑÏÇ∞ÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ ÌòïÏãù Î≥ÄÌôò\n",
    "            # (Ïù¥Ï†ÑÏùò Í∞ÄÏû• ÏïàÏ†ïÏ†ÅÏù∏ Î≤ÑÏ†ÑÏúºÎ°ú Î≥µÍµ¨)\n",
    "            pred_logits_cpu = outputs['pred_logits'].cpu()\n",
    "            pred_masks_cpu = outputs['pred_masks'].cpu()\n",
    "            \n",
    "            preds_for_map = []\n",
    "            for i in range(len(targets)):\n",
    "                scores, labels = F.softmax(pred_logits_cpu[i], dim=-1).max(-1)\n",
    "                masks_bool = (torch.sigmoid(pred_masks_cpu[i]) > 0.5)\n",
    "                preds_for_map.append(dict(masks=masks_bool, scores=scores, labels=labels))\n",
    "\n",
    "            targets_for_map = []\n",
    "            for t in targets:\n",
    "                targets_for_map.append(dict(masks=(t['masks'] > 0.5), labels=t['labels']))\n",
    "            \n",
    "            map_metric.update(preds_for_map, targets_for_map)\n",
    "\n",
    "    # ÏµúÏ¢Ö Í≤∞Í≥º ÏßëÍ≥Ñ\n",
    "    blade_iou = blade_iou_metric.compute().item()\n",
    "    map_results = map_metric.compute()\n",
    "    \n",
    "    # mAP Í≤∞Í≥ºÏóêÏÑú Precision, Recall, F1-score Í∑ºÏÇ¨Ïπò Í≥ÑÏÇ∞\n",
    "    precision = map_results['map_50'].item()\n",
    "    recall = map_results['mar_100'].item()\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "\n",
    "    metrics = {\n",
    "        'loss': np.mean(val_losses),\n",
    "        'blade_iou': blade_iou,\n",
    "        'mAP': map_results['map'].item(),\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# validate Ìï®ÏàòÎäî Ïù¥Ï†ÑÏùò ÏµúÏ¢Ö Î≤ÑÏ†ÑÏùÑ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©Ìï¥ÎèÑ Îê©ÎãàÎã§.\n",
    "# (Î™®Îì† ÏßÄÌëúÎ•º Í≥ÑÏÇ∞ÌïòÎäî ÏµúÏ¢Ö validate Ìï®Ïàò)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7bea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- üöÄ Starting Stage 2 Training: Damage Expert üöÄ ---\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# 2Îã®Í≥Ñ ÌïôÏäµÏùÑ ÏúÑÌï¥ EPOCHSÎ•º Îã§Ïãú ÏÑ§Ï†ïÌï† Ïàò ÏûàÏäµÎãàÎã§.\n",
    "# Ïòà: config.EPOCHS = 30\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train_loss = train_epoch_stage2(model, criterion, train_loader, optimizer, config.DEVICE, epoch)\n",
    "    val_metrics = validate(model, criterion, val_loader, config.DEVICE)\n",
    "    \n",
    "    val_loss = val_metrics['loss']\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{config.EPOCHS} -> Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  [Damage] mAP: {val_metrics['mAP']:.4f} | Precision: {val_metrics['precision']:.4f} | \"\n",
    "          f\"Recall: {val_metrics['recall']:.4f} | F1: {val_metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'final_best_model.pth') # <-- ÏµúÏ¢Ö Î™®Îç∏ Ï†ÄÏû•\n",
    "        print(f\"‚ú® New best FINAL model saved with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\n--- üéâ Stage 2 Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# ===== visualize_predictions Ìï®Ïàò ÍµêÏ≤¥ =====\n",
    "\n",
    "def visualize_predictions(model, dataloader, device, num_samples=3, conf_threshold=0.5):\n",
    "    \"\"\"Î™®Îç∏Ïùò ÏòàÏ∏° Í≤∞Í≥ºÎ•º ÏãúÍ∞ÅÌôîÌï©ÎãàÎã§.\"\"\"\n",
    "    model.eval()\n",
    "    samples_shown = 0\n",
    "    \n",
    "    # ConfigÏóê ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ Î¶¨Ïä§Ìä∏Í∞Ä ÏûàÎã§Í≥† Í∞ÄÏ†ï\n",
    "    # Ïòà: config.MODEL.HEAD_B.CLASSES = ['crack', 'nick', 'tear']\n",
    "    class_names = getattr(config.MODEL.HEAD_B, 'CLASSES', ['crack', 'nick', 'tear'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            if samples_shown >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            images_cpu = images.cpu()\n",
    "            outputs_cpu = {k: v.cpu() for k, v in outputs.items() if torch.is_tensor(v)}\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                if samples_shown >= num_samples:\n",
    "                    break\n",
    "                \n",
    "                image_tensor = images_cpu[i]\n",
    "                target = targets[i]\n",
    "                output = {k: v[i] for k, v in outputs_cpu.items()}\n",
    "                \n",
    "                # Ïù¥ÎØ∏ÏßÄÎ•º Numpy Î∞∞Ïó¥Î°ú Î≥ÄÌôò\n",
    "                img_to_draw = image_tensor.permute(1, 2, 0).numpy()\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                img_to_draw = (img_to_draw * std + mean) * 255\n",
    "                img_to_draw = np.clip(img_to_draw, 0, 255).astype(np.uint8)\n",
    "                \n",
    "                # --- [ÌïµÏã¨ ÏàòÏ†ï] Î©îÎ™®Î¶¨ Î†àÏù¥ÏïÑÏõÉÏùÑ OpenCV Ìò∏Ìôò ÌòïÌÉúÎ°ú Î≥ÄÍ≤Ω ---\n",
    "                img_to_draw = np.ascontiguousarray(img_to_draw)\n",
    "                \n",
    "                plt.figure(figsize=(12, 12))\n",
    "                \n",
    "                # 1. Ï†ïÎãµ ÎßàÏä§ÌÅ¨ Í∑∏Î¶¨Í∏∞ (Ï¥àÎ°ùÏÉâ, Ï†êÏÑ†)\n",
    "                for mask in target['masks']:\n",
    "                    contours, _ = cv2.findContours(mask.numpy().astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    cv2.drawContours(img_to_draw, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "                # 2. ÏòàÏ∏° ÎßàÏä§ÌÅ¨ Í∑∏Î¶¨Í∏∞ (Îπ®Í∞ÑÏÉâ, Ïã§ÏÑ†)\n",
    "                scores, labels = F.softmax(output['pred_logits'], dim=-1).max(-1)\n",
    "                \n",
    "                for j, (score, label) in enumerate(zip(scores, labels)):\n",
    "                    if score > conf_threshold:\n",
    "                        mask = (torch.sigmoid(output['pred_masks'][j]) > 0.5).numpy().astype(np.uint8)\n",
    "                        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        cv2.drawContours(img_to_draw, contours, -1, (255, 0, 0), 2)\n",
    "                        \n",
    "                        cat_name = class_names[label.item()]\n",
    "                        text = f'{cat_name}: {score:.2f}'\n",
    "                        if contours:\n",
    "                            x, y, w, h = cv2.boundingRect(contours[0])\n",
    "                            cv2.putText(img_to_draw, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                plt.imshow(img_to_draw)\n",
    "                plt.title(f\"Sample {samples_shown+1} (Green: Ground Truth, Red: Prediction)\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "                samples_shown += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "model.load_state_dict(torch.load('blade_damage_best_model.pth'))\n",
    "# ÏãúÍ∞ÅÌôî Ìï®Ïàò Ïã§Ìñâ\n",
    "visualize_predictions(model, val_loader, config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc24d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
