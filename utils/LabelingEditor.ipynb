{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7da1199",
   "metadata": {},
   "source": [
    "COCO DATA SETì—ì„œ BLADE ë¼ë²¨ë§ í•„í„°ë§(ë¸”ë ˆì´ë“œ only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b0180a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COCO Segmentation ë°ì´í„° ì²˜ë¦¬\n",
      "============================================================\n",
      "ê²½ë¡œ: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\coco_segmentation_for_multilabel\n",
      "train: 496 images, 1 JSON files\n",
      "  - _annotations.coco.json\n",
      "valid: 150 images, 1 JSON files\n",
      "  - _annotations.coco.json\n",
      "test: 120 images, 1 JSON files\n",
      "  - _annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 1: í™˜ê²½ ì„¤ì •\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "sys.path.append('.')\n",
    "from LabelingEditorFunctions import (\n",
    "    extract_blade_only,\n",
    "    extract_damage_only,\n",
    "    check_categories\n",
    ")\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "coco_seg_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\coco_segmentation_for_multilabel')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COCO Segmentation ë°ì´í„° ì²˜ë¦¬\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ê²½ë¡œ: {coco_seg_root}\")\n",
    "\n",
    "# í´ë” êµ¬ì¡° í™•ì¸\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = coco_seg_root / split\n",
    "    if split_dir.exists():\n",
    "        # JSON íŒŒì¼ í™•ì¸\n",
    "        json_files = list(split_dir.glob('*.json'))\n",
    "        img_files = list(split_dir.glob('*.jpg')) + list(split_dir.glob('*.png'))\n",
    "        print(f\"{split}: {len(img_files)} images, {len(json_files)} JSON files\")\n",
    "        \n",
    "        # JSON íŒŒì¼ ì´ë¦„ ì¶œë ¥\n",
    "        for jf in json_files:\n",
    "            print(f\"  - {jf.name}\")\n",
    "    else:\n",
    "        print(f\"{split}: í´ë” ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7862c5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COCO JSON íŒŒì¼ í™•ì¸\n",
      "============================================================\n",
      "train: _annotations.coco.json ì‚¬ìš©\n",
      "  - Images: 496ê°œ\n",
      "  - Annotations: 2187ê°œ\n",
      "  - Categories: ['objects', 'Blade', 'Crack', 'Nick', 'Tear']\n",
      "valid: _annotations.coco.json ì‚¬ìš©\n",
      "  - Images: 150ê°œ\n",
      "  - Annotations: 484ê°œ\n",
      "  - Categories: ['objects', 'Blade', 'Crack', 'Nick', 'Tear']\n",
      "test: _annotations.coco.json ì‚¬ìš©\n",
      "  - Images: 120ê°œ\n",
      "  - Annotations: 510ê°œ\n",
      "  - Categories: ['objects', 'Blade', 'Crack', 'Nick', 'Tear']\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 2: COCO JSON íŒŒì¼ ì°¾ê¸° ë° í™•ì¸\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COCO JSON íŒŒì¼ í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "coco_json_files = {}\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = coco_seg_root / split\n",
    "    \n",
    "    if not split_dir.exists():\n",
    "        continue\n",
    "    \n",
    "    # ì¼ë°˜ì ì¸ COCO annotation íŒŒì¼ëª…ë“¤\n",
    "    possible_names = [\n",
    "        '_annotations.coco.json',\n",
    "        'annotations.json',\n",
    "        '_annotations.json',\n",
    "        f'{split}.json',\n",
    "        'instances_default.json',\n",
    "        'via_region_data.json'\n",
    "    ]\n",
    "    \n",
    "    json_file = None\n",
    "    for name in possible_names:\n",
    "        candidate = split_dir / name\n",
    "        if candidate.exists():\n",
    "            json_file = candidate\n",
    "            break\n",
    "    \n",
    "    # ëª» ì°¾ìœ¼ë©´ ì²« ë²ˆì§¸ JSON íŒŒì¼ ì‚¬ìš©\n",
    "    if json_file is None:\n",
    "        json_files = list(split_dir.glob('*.json'))\n",
    "        if json_files:\n",
    "            json_file = json_files[0]\n",
    "    \n",
    "    if json_file:\n",
    "        coco_json_files[split] = json_file\n",
    "        print(f\"{split}: {json_file.name} ì‚¬ìš©\")\n",
    "        \n",
    "        # ë‚´ìš© í™•ì¸\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"  - Images: {len(data.get('images', []))}ê°œ\")\n",
    "        print(f\"  - Annotations: {len(data.get('annotations', []))}ê°œ\")\n",
    "        print(f\"  - Categories: {[cat['name'] for cat in data.get('categories', [])]}\")\n",
    "    else:\n",
    "        print(f\"{split}: âŒ JSON íŒŒì¼ ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "052b09db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ì¹´í…Œê³ ë¦¬ ìƒì„¸ ì •ë³´\n",
      "============================================================\n",
      "\n",
      "train (_annotations.coco.json):\n",
      "  ID 0: objects = 0ê°œ\n",
      "  ID 1: Blade = 857ê°œ\n",
      "  ID 2: Crack = 354ê°œ\n",
      "  ID 3: Nick = 815ê°œ\n",
      "  ID 4: Tear = 161ê°œ\n",
      "\n",
      "valid (_annotations.coco.json):\n",
      "  ID 0: objects = 0ê°œ\n",
      "  ID 1: Blade = 249ê°œ\n",
      "  ID 2: Crack = 0ê°œ\n",
      "  ID 3: Nick = 133ê°œ\n",
      "  ID 4: Tear = 102ê°œ\n",
      "\n",
      "test (_annotations.coco.json):\n",
      "  ID 0: objects = 0ê°œ\n",
      "  ID 1: Blade = 206ê°œ\n",
      "  ID 2: Crack = 76ê°œ\n",
      "  ID 3: Nick = 184ê°œ\n",
      "  ID 4: Tear = 44ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 3: ì¹´í…Œê³ ë¦¬ ìƒì„¸ í™•ì¸\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ì¹´í…Œê³ ë¦¬ ìƒì„¸ ì •ë³´\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split, json_file in coco_json_files.items():\n",
    "    print(f\"\\n{split} ({json_file.name}):\")\n",
    "    \n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ë³„ annotation ìˆ˜ ê³„ì‚°\n",
    "    cat_counts = {}\n",
    "    for cat in data['categories']:\n",
    "        cat_counts[cat['id']] = {'name': cat['name'], 'count': 0}\n",
    "    \n",
    "    for ann in data['annotations']:\n",
    "        if ann['category_id'] in cat_counts:\n",
    "            cat_counts[ann['category_id']]['count'] += 1\n",
    "    \n",
    "    # ì¶œë ¥\n",
    "    for cat_id, info in cat_counts.items():\n",
    "        print(f\"  ID {cat_id}: {info['name']} = {info['count']}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f2071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Step 1: Bladeë§Œ ì¶”ì¶œ\n",
      "============================================================\n",
      "\n",
      "train ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: ['objects', 'Blade', 'Crack', 'Nick', 'Tear']\n",
      "ì „ì²´ annotations: 2187\n",
      "âœ… Blade annotations: 857\n",
      "  âœ… blade_only.json ìƒì„± ì™„ë£Œ: 857ê°œ annotations\n",
      "\n",
      "valid ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: ['objects', 'Blade', 'Crack', 'Nick', 'Tear']\n",
      "ì „ì²´ annotations: 484\n",
      "âœ… Blade annotations: 249\n",
      "  âœ… blade_only.json ìƒì„± ì™„ë£Œ: 249ê°œ annotations\n",
      "\n",
      "test ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: ['objects', 'Blade', 'Crack', 'Nick', 'Tear']\n",
      "ì „ì²´ annotations: 510\n",
      "âœ… Blade annotations: 206\n",
      "  âœ… blade_only.json ìƒì„± ì™„ë£Œ: 206ê°œ annotations\n",
      "\n",
      "ì´ Blade annotations: 1312ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 4: Bladeë§Œ ì¶”ì¶œ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 1: Bladeë§Œ ì¶”ì¶œ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "blade_total = 0\n",
    "\n",
    "for split, json_file in coco_json_files.items():\n",
    "    output_file = json_file.parent / 'blade_only.json'\n",
    "    \n",
    "    print(f\"\\n{split} ì²˜ë¦¬ ì¤‘...\")\n",
    "    result = extract_blade_only(str(json_file), str(output_file))\n",
    "    \n",
    "    if result:\n",
    "        with open(output_file, 'r') as f:\n",
    "            blade_data = json.load(f)\n",
    "        count = len(blade_data['annotations'])\n",
    "        blade_total += count\n",
    "        print(f\"  âœ… blade_only.json ìƒì„± ì™„ë£Œ: {count}ê°œ annotations\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ Blade ì¹´í…Œê³ ë¦¬ ì—†ìŒ\")\n",
    "\n",
    "print(f\"\\nì´ Blade annotations: {blade_total}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6371f4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Step 2: ì†ìƒë§Œ ì¶”ì¶œ (Blade ì œì™¸)\n",
      "============================================================\n",
      "\n",
      "train ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: [(0, 'objects'), (1, 'Blade'), (2, 'Crack'), (3, 'Nick'), (4, 'Tear')]\n",
      "ì†ìƒ ì¹´í…Œê³ ë¦¬: ['Crack', 'Nick', 'Tear']\n",
      "âœ… ì†ìƒ annotations: 1330\n",
      "  âœ… damage_only.json ìƒì„± ì™„ë£Œ: 1330ê°œ annotations\n",
      "    - Crack: 354ê°œ\n",
      "    - Nick: 815ê°œ\n",
      "    - Tear: 161ê°œ\n",
      "\n",
      "valid ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: [(0, 'objects'), (1, 'Blade'), (2, 'Crack'), (3, 'Nick'), (4, 'Tear')]\n",
      "ì†ìƒ ì¹´í…Œê³ ë¦¬: ['Crack', 'Nick', 'Tear']\n",
      "âœ… ì†ìƒ annotations: 235\n",
      "  âœ… damage_only.json ìƒì„± ì™„ë£Œ: 235ê°œ annotations\n",
      "    - Crack: 0ê°œ\n",
      "    - Nick: 133ê°œ\n",
      "    - Tear: 102ê°œ\n",
      "\n",
      "test ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: [(0, 'objects'), (1, 'Blade'), (2, 'Crack'), (3, 'Nick'), (4, 'Tear')]\n",
      "ì†ìƒ ì¹´í…Œê³ ë¦¬: ['Crack', 'Nick', 'Tear']\n",
      "âœ… ì†ìƒ annotations: 304\n",
      "  âœ… damage_only.json ìƒì„± ì™„ë£Œ: 304ê°œ annotations\n",
      "    - Crack: 76ê°œ\n",
      "    - Nick: 184ê°œ\n",
      "    - Tear: 44ê°œ\n",
      "\n",
      "ì´ ì†ìƒ annotations: 1869ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 5: ì†ìƒë§Œ ì¶”ì¶œ (Blade ì œì™¸)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 2: ì†ìƒë§Œ ì¶”ì¶œ (Blade ì œì™¸)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "damage_total = 0\n",
    "\n",
    "for split, json_file in coco_json_files.items():\n",
    "    output_file = json_file.parent / 'damage_only.json'\n",
    "    \n",
    "    print(f\"\\n{split} ì²˜ë¦¬ ì¤‘...\")\n",
    "    result = extract_damage_only(str(json_file), str(output_file))\n",
    "    \n",
    "    if result:\n",
    "        with open(output_file, 'r') as f:\n",
    "            damage_data = json.load(f)\n",
    "        count = len(damage_data['annotations'])\n",
    "        damage_total += count\n",
    "        print(f\"  âœ… damage_only.json ìƒì„± ì™„ë£Œ: {count}ê°œ annotations\")\n",
    "        \n",
    "        # ì†ìƒ ì¢…ë¥˜ë³„ í†µê³„\n",
    "        damage_cats = {cat['name']: cat['id'] for cat in damage_data['categories']}\n",
    "        damage_dist = {name: 0 for name in damage_cats}\n",
    "        \n",
    "        for ann in damage_data['annotations']:\n",
    "            for name, cat_id in damage_cats.items():\n",
    "                if ann['category_id'] == cat_id:\n",
    "                    damage_dist[name] += 1\n",
    "        \n",
    "        for name, cnt in damage_dist.items():\n",
    "            print(f\"    - {name}: {cnt}ê°œ\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ ì†ìƒ ì¹´í…Œê³ ë¦¬ ì—†ìŒ\")\n",
    "\n",
    "print(f\"\\nì´ ì†ìƒ annotations: {damage_total}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6d245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\n",
      "============================================================\n",
      "Split      Original   Blade      Damage    \n",
      "----------------------------------------\n",
      "train      2187       857        1330      \n",
      "valid      484        249        235       \n",
      "test       510        206        304       \n",
      "----------------------------------------\n",
      "Total      3181       1312       1869      \n"
     ]
    }
   ],
   "source": [
    "# ì…€ 6: ê²°ê³¼ ìš”ì•½\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = {\n",
    "    'split': [],\n",
    "    'original': [],\n",
    "    'blade': [],\n",
    "    'damage': []\n",
    "}\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = coco_seg_root / split\n",
    "    \n",
    "    if not split_dir.exists():\n",
    "        continue\n",
    "    \n",
    "    summary['split'].append(split)\n",
    "    \n",
    "    # ì›ë³¸\n",
    "    if split in coco_json_files:\n",
    "        with open(coco_json_files[split], 'r') as f:\n",
    "            data = json.load(f)\n",
    "        summary['original'].append(len(data['annotations']))\n",
    "    else:\n",
    "        summary['original'].append(0)\n",
    "    \n",
    "    # Blade\n",
    "    blade_file = split_dir / 'blade_only.json'\n",
    "    if blade_file.exists():\n",
    "        with open(blade_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        summary['blade'].append(len(data['annotations']))\n",
    "    else:\n",
    "        summary['blade'].append(0)\n",
    "    \n",
    "    # Damage\n",
    "    damage_file = split_dir / 'damage_only.json'\n",
    "    if damage_file.exists():\n",
    "        with open(damage_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        summary['damage'].append(len(data['annotations']))\n",
    "    else:\n",
    "        summary['damage'].append(0)\n",
    "\n",
    "# í…Œì´ë¸” ì¶œë ¥\n",
    "print(f\"{'Split':<10} {'Original':<10} {'Blade':<10} {'Damage':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for i in range(len(summary['split'])):\n",
    "    print(f\"{summary['split'][i]:<10} {summary['original'][i]:<10} {summary['blade'][i]:<10} {summary['damage'][i]:<10}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Total':<10} {sum(summary['original']):<10} {sum(summary['blade']):<10} {sum(summary['damage']):<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aed7c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ìƒì„±ëœ íŒŒì¼ ëª©ë¡\n",
      "============================================================\n",
      "\n",
      "train:\n",
      "  âœ… blade_only.json\n",
      "     í¬ê¸°: 786.3 KB\n",
      "     ì´ë¯¸ì§€: 496ê°œ\n",
      "     Annotations: 857ê°œ\n",
      "     ì¹´í…Œê³ ë¦¬: ['Blade']\n",
      "  âœ… damage_only.json\n",
      "     í¬ê¸°: 1063.7 KB\n",
      "     ì´ë¯¸ì§€: 496ê°œ\n",
      "     Annotations: 1330ê°œ\n",
      "     ì¹´í…Œê³ ë¦¬: ['Crack', 'Nick', 'Tear']\n",
      "\n",
      "valid:\n",
      "  âœ… blade_only.json\n",
      "     í¬ê¸°: 254.9 KB\n",
      "     ì´ë¯¸ì§€: 150ê°œ\n",
      "     Annotations: 249ê°œ\n",
      "     ì¹´í…Œê³ ë¦¬: ['Blade']\n",
      "  âœ… damage_only.json\n",
      "     í¬ê¸°: 207.5 KB\n",
      "     ì´ë¯¸ì§€: 150ê°œ\n",
      "     Annotations: 235ê°œ\n",
      "     ì¹´í…Œê³ ë¦¬: ['Crack', 'Nick', 'Tear']\n",
      "\n",
      "test:\n",
      "  âœ… blade_only.json\n",
      "     í¬ê¸°: 193.2 KB\n",
      "     ì´ë¯¸ì§€: 120ê°œ\n",
      "     Annotations: 206ê°œ\n",
      "     ì¹´í…Œê³ ë¦¬: ['Blade']\n",
      "  âœ… damage_only.json\n",
      "     í¬ê¸°: 249.6 KB\n",
      "     ì´ë¯¸ì§€: 120ê°œ\n",
      "     Annotations: 304ê°œ\n",
      "     ì¹´í…Œê³ ë¦¬: ['Crack', 'Nick', 'Tear']\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 7: ìƒì„±ëœ íŒŒì¼ í™•ì¸\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ìƒì„±ëœ íŒŒì¼ ëª©ë¡\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = coco_seg_root / split\n",
    "    \n",
    "    if not split_dir.exists():\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{split}:\")\n",
    "    \n",
    "    # í™•ì¸í•  íŒŒì¼ë“¤\n",
    "    files_to_check = [\n",
    "        'blade_only.json',\n",
    "        'damage_only.json'\n",
    "    ]\n",
    "    \n",
    "    for file_name in files_to_check:\n",
    "        file_path = split_dir / file_name\n",
    "        if file_path.exists():\n",
    "            size_kb = file_path.stat().st_size / 1024\n",
    "            \n",
    "            # ë‚´ìš© ê°„ë‹¨ í™•ì¸\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            print(f\"  âœ… {file_name}\")\n",
    "            print(f\"     í¬ê¸°: {size_kb:.1f} KB\")\n",
    "            print(f\"     ì´ë¯¸ì§€: {len(data['images'])}ê°œ\")\n",
    "            print(f\"     Annotations: {len(data['annotations'])}ê°œ\")\n",
    "            print(f\"     ì¹´í…Œê³ ë¦¬: {[cat['name'] for cat in data['categories']]}\")\n",
    "        else:\n",
    "            print(f\"  âŒ {file_name} (ì—†ìŒ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b6359ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…€ 8: ìƒ˜í”Œ ë°ì´í„° í™•ì¸ (ì„ íƒì‚¬í•­)\n",
    "def check_sample_annotation(json_file, sample_idx=0):\n",
    "    \"\"\"ìƒ˜í”Œ annotation í™•ì¸\"\"\"\n",
    "    \n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    if sample_idx >= len(data['annotations']):\n",
    "        print(f\"ì¸ë±ìŠ¤ ì´ˆê³¼ (ìµœëŒ€: {len(data['annotations'])-1})\")\n",
    "        return\n",
    "    \n",
    "    ann = data['annotations'][sample_idx]\n",
    "    img_id = ann['image_id']\n",
    "    \n",
    "    # í•´ë‹¹ ì´ë¯¸ì§€ ì •ë³´ ì°¾ê¸°\n",
    "    img_info = None\n",
    "    for img in data['images']:\n",
    "        if img['id'] == img_id:\n",
    "            img_info = img\n",
    "            break\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ ì •ë³´\n",
    "    cat_info = None\n",
    "    for cat in data['categories']:\n",
    "        if cat['id'] == ann['category_id']:\n",
    "            cat_info = cat\n",
    "            break\n",
    "    \n",
    "    print(f\"Annotation #{sample_idx}:\")\n",
    "    print(f\"  ì´ë¯¸ì§€: {img_info['file_name'] if img_info else 'Unknown'}\")\n",
    "    print(f\"  ì¹´í…Œê³ ë¦¬: {cat_info['name'] if cat_info else 'Unknown'}\")\n",
    "    print(f\"  BBox: {ann.get('bbox', 'None')}\")\n",
    "    print(f\"  Area: {ann.get('area', 'None')}\")\n",
    "    \n",
    "    if 'segmentation' in ann:\n",
    "        if isinstance(ann['segmentation'], list) and ann['segmentation']:\n",
    "            print(f\"  Segmentation: {len(ann['segmentation'][0])/2:.0f} points\")\n",
    "\n",
    "# ìƒ˜í”Œ í™•ì¸\n",
    "if coco_seg_root / 'train' / 'blade_only.json' in coco_json_files.values():\n",
    "    print(\"\\nBlade ìƒ˜í”Œ:\")\n",
    "    check_sample_annotation(coco_seg_root / 'train' / 'blade_only.json', 0)\n",
    "\n",
    "if coco_seg_root / 'train' / 'damage_only.json' in coco_json_files.values():\n",
    "    print(\"\\nì†ìƒ ìƒ˜í”Œ:\")\n",
    "    check_sample_annotation(coco_seg_root / 'train' / 'damage_only.json', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca575ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°±ì—…: train__annotations.coco.json\n",
      "âœ… ë°±ì—…: valid__annotations.coco.json\n",
      "âœ… ë°±ì—…: test__annotations.coco.json\n",
      "\n",
      "ë°±ì—… ì™„ë£Œ: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\coco_segmentation_for_multilabel\\backup\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 9: ë°±ì—… ìƒì„± (ì„ íƒì‚¬í•­)\n",
    "create_backup = input(\"ì›ë³¸ JSON íŒŒì¼ ë°±ì—… ìƒì„±? (y/n): \")\n",
    "\n",
    "if create_backup.lower() == 'y':\n",
    "    backup_dir = coco_seg_root / 'backup'\n",
    "    backup_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for split, json_file in coco_json_files.items():\n",
    "        backup_file = backup_dir / f\"{split}_{json_file.name}\"\n",
    "        shutil.copy2(json_file, backup_file)\n",
    "        print(f\"âœ… ë°±ì—…: {backup_file.name}\")\n",
    "    \n",
    "    print(f\"\\në°±ì—… ì™„ë£Œ: {backup_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a8156",
   "metadata": {},
   "source": [
    "YOLOv8 ìš© ë°ì´í„°ë„ í•™ìŠµì— í™œìš© (ë¸”ë ˆì´ë“œ only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8885556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 2177 images, 3085 annotations\n",
      "valid: 300 images, 437 annotations\n",
      "âš ï¸ test í´ë” ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "from LabelingEditorFunctions import process_yolo_splits\n",
    "\n",
    "yolo_root = r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\final_ver_data_rev2.v3i.yolov8'\n",
    "process_yolo_splits(yolo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb9b970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train:\n",
      "  Images: 2177\n",
      "  Blade annotations: 3085\n",
      "\n",
      "valid:\n",
      "  Images: 300\n",
      "  Blade annotations: 437\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 2: ë³€í™˜ ê²°ê³¼ í™•ì¸\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "yolo_path = Path(yolo_root)\n",
    "\n",
    "for split in ['train', 'valid']:\n",
    "    json_file = yolo_path / split / 'blade_only.json'\n",
    "    if json_file.exists():\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"\\n{split}:\")\n",
    "        print(f\"  Images: {len(data['images'])}\")\n",
    "        print(f\"  Blade annotations: {len(data['annotations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a648357",
   "metadata": {},
   "source": [
    "YOLO ë°ì´í„° ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce0cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "YOLO ë°ì´í„° ì²˜ë¦¬\n",
      "============================================================\n",
      "ê²½ë¡œ: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\final_ver_data_rev2.v3i.yolov8\n",
      "train: 2177 images, 2177 labels\n",
      "valid: 300 images, 387 labels\n",
      "test: 268 images, 268 labels\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 1: í™˜ê²½ ì„¤ì •\n",
    "import sys\n",
    "import json\n",
    "import cv2\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('.')\n",
    "from LabelingEditorFunctions import (\n",
    "    extract_blade_only,\n",
    "    extract_damage_only,\n",
    "    convert_yolo_to_coco,\n",
    "    check_categories\n",
    ")\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "yolo_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\final_ver_data_rev2.v3i.yolov8')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"YOLO ë°ì´í„° ì²˜ë¦¬\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ê²½ë¡œ: {yolo_root}\")\n",
    "\n",
    "# í´ë” í™•ì¸\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = yolo_root / split\n",
    "    if split_dir.exists():\n",
    "        images_count = len(list((split_dir / 'images').glob('*.jpg')))\n",
    "        labels_count = len(list((split_dir / 'labels').glob('*.txt')))\n",
    "        print(f\"{split}: {images_count} images, {labels_count} labels\")\n",
    "    else:\n",
    "        print(f\"{split}: í´ë” ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671a9bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO í´ë˜ìŠ¤ ì •ë³´:\n",
      "í´ë˜ìŠ¤ ìˆ˜: 4\n",
      "í´ë˜ìŠ¤ ì´ë¦„: ['Blade', 'Crack', 'Nick', 'Tear']\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 2: data.yaml í™•ì¸ (í´ë˜ìŠ¤ ì •ë³´)\n",
    "yaml_file = yolo_root / 'data.yaml'\n",
    "\n",
    "if yaml_file.exists():\n",
    "    with open(yaml_file, 'r') as f:\n",
    "        yaml_data = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"YOLO í´ë˜ìŠ¤ ì •ë³´:\")\n",
    "    print(f\"í´ë˜ìŠ¤ ìˆ˜: {yaml_data.get('nc', 'N/A')}\")\n",
    "    print(f\"í´ë˜ìŠ¤ ì´ë¦„: {yaml_data.get('names', 'N/A')}\")\n",
    "else:\n",
    "    print(\"âš ï¸ data.yaml íŒŒì¼ ì—†ìŒ\")\n",
    "    print(\"ê¸°ë³¸ê°’ ì‚¬ìš©: ['Blade', 'Crack', 'Nick', 'Tear']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69099359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Step 1: YOLO â†’ COCO JSON ë³€í™˜\n",
      "============================================================\n",
      "\n",
      "train ë³€í™˜ ì¤‘...\n",
      "í´ë˜ìŠ¤ ì •ë³´: ['Blade', 'Crack', 'Nick', 'Tear']\n",
      "âœ… ë³€í™˜ ì™„ë£Œ: 2177 images, 5924 annotations\n",
      "  âœ… _annotations.coco.json ìƒì„± ì™„ë£Œ\n",
      "\n",
      "valid ë³€í™˜ ì¤‘...\n",
      "í´ë˜ìŠ¤ ì •ë³´: ['Blade', 'Crack', 'Nick', 'Tear']\n",
      "âœ… ë³€í™˜ ì™„ë£Œ: 300 images, 788 annotations\n",
      "  âœ… _annotations.coco.json ìƒì„± ì™„ë£Œ\n",
      "\n",
      "test ë³€í™˜ ì¤‘...\n",
      "í´ë˜ìŠ¤ ì •ë³´: ['Blade', 'Crack', 'Nick', 'Tear']\n",
      "âœ… ë³€í™˜ ì™„ë£Œ: 268 images, 868 annotations\n",
      "  âœ… _annotations.coco.json ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 3: YOLO â†’ COCO JSON ë³€í™˜\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 1: YOLO â†’ COCO JSON ë³€í™˜\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = yolo_root / split\n",
    "    \n",
    "    if not split_dir.exists():\n",
    "        print(f\"âš ï¸ {split} í´ë” ì—†ìŒ\")\n",
    "        continue\n",
    "    \n",
    "    output_json = split_dir / '_annotations.coco.json'\n",
    "    \n",
    "    # ì´ë¯¸ ë³€í™˜ëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "    if output_json.exists():\n",
    "        overwrite = input(f\"{split}ì— ì´ë¯¸ JSON íŒŒì¼ ì¡´ì¬. ë®ì–´ì“°ê¸°? (y/n): \")\n",
    "        if overwrite.lower() != 'y':\n",
    "            print(f\"{split} ê±´ë„ˆë›°ê¸°\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{split} ë³€í™˜ ì¤‘...\")\n",
    "    result = convert_yolo_to_coco(\n",
    "        split_dir,\n",
    "        output_json,\n",
    "        yaml_file if yaml_file.exists() else None\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        print(f\"  âœ… {output_json.name} ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7a433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ë³€í™˜ëœ JSON íŒŒì¼ í™•ì¸\n",
      "============================================================\n",
      "\n",
      "train:\n",
      "  ì´ë¯¸ì§€: 2177ê°œ\n",
      "  Annotations: 5924ê°œ\n",
      "  ì¹´í…Œê³ ë¦¬: ['Blade', 'Crack', 'Nick', 'Tear']\n",
      "    - Blade: 3085ê°œ\n",
      "    - Crack: 746ê°œ\n",
      "    - Nick: 1222ê°œ\n",
      "    - Tear: 871ê°œ\n",
      "\n",
      "valid:\n",
      "  ì´ë¯¸ì§€: 300ê°œ\n",
      "  Annotations: 788ê°œ\n",
      "  ì¹´í…Œê³ ë¦¬: ['Blade', 'Crack', 'Nick', 'Tear']\n",
      "    - Blade: 437ê°œ\n",
      "    - Crack: 207ê°œ\n",
      "    - Nick: 110ê°œ\n",
      "    - Tear: 34ê°œ\n",
      "\n",
      "test:\n",
      "  ì´ë¯¸ì§€: 268ê°œ\n",
      "  Annotations: 868ê°œ\n",
      "  ì¹´í…Œê³ ë¦¬: ['Blade', 'Crack', 'Nick', 'Tear']\n",
      "    - Blade: 452ê°œ\n",
      "    - Crack: 227ê°œ\n",
      "    - Nick: 89ê°œ\n",
      "    - Tear: 100ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 4: ë³€í™˜ëœ JSON ì¹´í…Œê³ ë¦¬ í™•ì¸\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ë³€í™˜ëœ JSON íŒŒì¼ í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    json_file = yolo_root / split / '_annotations.coco.json'\n",
    "    \n",
    "    if json_file.exists():\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"\\n{split}:\")\n",
    "        print(f\"  ì´ë¯¸ì§€: {len(data['images'])}ê°œ\")\n",
    "        print(f\"  Annotations: {len(data['annotations'])}ê°œ\")\n",
    "        print(f\"  ì¹´í…Œê³ ë¦¬: {[cat['name'] for cat in data['categories']]}\")\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ë³„ annotation ìˆ˜\n",
    "        cat_counts = {cat['id']: 0 for cat in data['categories']}\n",
    "        for ann in data['annotations']:\n",
    "            cat_counts[ann['category_id']] += 1\n",
    "        \n",
    "        for cat in data['categories']:\n",
    "            print(f\"    - {cat['name']}: {cat_counts[cat['id']]}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d197b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Step 2: Bladeë§Œ ì¶”ì¶œ\n",
      "============================================================\n",
      "\n",
      "train ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: ['Blade', 'Crack', 'Nick', 'Tear']\n",
      "ì „ì²´ annotations: 5924\n",
      "âœ… Blade annotations: 3085\n",
      "  âœ… blade_only.json ìƒì„± ì™„ë£Œ\n",
      "\n",
      "valid ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: ['Blade', 'Crack', 'Nick', 'Tear']\n",
      "ì „ì²´ annotations: 788\n",
      "âœ… Blade annotations: 437\n",
      "  âœ… blade_only.json ìƒì„± ì™„ë£Œ\n",
      "\n",
      "test ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: ['Blade', 'Crack', 'Nick', 'Tear']\n",
      "ì „ì²´ annotations: 868\n",
      "âœ… Blade annotations: 452\n",
      "  âœ… blade_only.json ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 5: Bladeë§Œ ì¶”ì¶œ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 2: Bladeë§Œ ì¶”ì¶œ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    json_file = yolo_root / split / '_annotations.coco.json'\n",
    "    output_file = yolo_root / split / 'blade_only.json'\n",
    "    \n",
    "    if not json_file.exists():\n",
    "        print(f\"âš ï¸ {split}: JSON íŒŒì¼ ì—†ìŒ\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{split} ì²˜ë¦¬ ì¤‘...\")\n",
    "    result = extract_blade_only(str(json_file), str(output_file))\n",
    "    \n",
    "    if result:\n",
    "        print(f\"  âœ… blade_only.json ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c3718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Step 3: ì†ìƒë§Œ ì¶”ì¶œ (Blade ì œì™¸)\n",
      "============================================================\n",
      "\n",
      "train ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: [(0, 'Blade'), (1, 'Crack'), (2, 'Nick'), (3, 'Tear')]\n",
      "ì†ìƒ ì¹´í…Œê³ ë¦¬: ['Crack', 'Nick', 'Tear']\n",
      "âœ… ì†ìƒ annotations: 2839\n",
      "  âœ… damage_only.json ìƒì„± ì™„ë£Œ\n",
      "\n",
      "valid ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: [(0, 'Blade'), (1, 'Crack'), (2, 'Nick'), (3, 'Tear')]\n",
      "ì†ìƒ ì¹´í…Œê³ ë¦¬: ['Crack', 'Nick', 'Tear']\n",
      "âœ… ì†ìƒ annotations: 351\n",
      "  âœ… damage_only.json ìƒì„± ì™„ë£Œ\n",
      "\n",
      "test ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“ íŒŒì¼: _annotations.coco.json\n",
      "ì›ë³¸ ì¹´í…Œê³ ë¦¬: [(0, 'Blade'), (1, 'Crack'), (2, 'Nick'), (3, 'Tear')]\n",
      "ì†ìƒ ì¹´í…Œê³ ë¦¬: ['Crack', 'Nick', 'Tear']\n",
      "âœ… ì†ìƒ annotations: 416\n",
      "  âœ… damage_only.json ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 6: ì†ìƒë§Œ ì¶”ì¶œ (Blade ì œì™¸)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 3: ì†ìƒë§Œ ì¶”ì¶œ (Blade ì œì™¸)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    json_file = yolo_root / split / '_annotations.coco.json'\n",
    "    output_file = yolo_root / split / 'damage_only.json'\n",
    "    \n",
    "    if not json_file.exists():\n",
    "        print(f\"âš ï¸ {split}: JSON íŒŒì¼ ì—†ìŒ\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{split} ì²˜ë¦¬ ì¤‘...\")\n",
    "    result = extract_damage_only(str(json_file), str(output_file))\n",
    "    \n",
    "    if result:\n",
    "        print(f\"  âœ… damage_only.json ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ac845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ìµœì¢… ê²°ê³¼ í™•ì¸\n",
      "============================================================\n",
      "\n",
      "train:\n",
      "  Blade: 3085ê°œ annotations\n",
      "  ì†ìƒ ì´: 2839ê°œ\n",
      "    - Crack: 746ê°œ\n",
      "    - Nick: 1222ê°œ\n",
      "    - Tear: 871ê°œ\n",
      "\n",
      "valid:\n",
      "  Blade: 437ê°œ annotations\n",
      "  ì†ìƒ ì´: 351ê°œ\n",
      "    - Crack: 207ê°œ\n",
      "    - Nick: 110ê°œ\n",
      "    - Tear: 34ê°œ\n",
      "\n",
      "test:\n",
      "  Blade: 452ê°œ annotations\n",
      "  ì†ìƒ ì´: 416ê°œ\n",
      "    - Crack: 227ê°œ\n",
      "    - Nick: 89ê°œ\n",
      "    - Tear: 100ê°œ\n",
      "\n",
      "ì „ì²´ í•©ê³„:\n",
      "  Blade: 3974ê°œ\n",
      "  ì†ìƒ: 3606ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì…€ 7: ìµœì¢… ê²°ê³¼ í™•ì¸\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ìµœì¢… ê²°ê³¼ í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_blade = 0\n",
    "total_damage = 0\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = yolo_root / split\n",
    "    \n",
    "    blade_file = split_dir / 'blade_only.json'\n",
    "    damage_file = split_dir / 'damage_only.json'\n",
    "    \n",
    "    blade_count = 0\n",
    "    damage_count = 0\n",
    "    \n",
    "    print(f\"\\n{split}:\")\n",
    "    \n",
    "    if blade_file.exists():\n",
    "        with open(blade_file, 'r') as f:\n",
    "            blade_data = json.load(f)\n",
    "        blade_count = len(blade_data['annotations'])\n",
    "        print(f\"  Blade: {blade_count}ê°œ annotations\")\n",
    "        \n",
    "    if damage_file.exists():\n",
    "        with open(damage_file, 'r') as f:\n",
    "            damage_data = json.load(f)\n",
    "        damage_count = len(damage_data['annotations'])\n",
    "        \n",
    "        # ì†ìƒ ì¢…ë¥˜ë³„ ê°œìˆ˜\n",
    "        damage_cats = {cat['name']: cat['id'] for cat in damage_data['categories']}\n",
    "        damage_dist = {name: 0 for name in damage_cats}\n",
    "        \n",
    "        for ann in damage_data['annotations']:\n",
    "            for name, cat_id in damage_cats.items():\n",
    "                if ann['category_id'] == cat_id:\n",
    "                    damage_dist[name] += 1\n",
    "        \n",
    "        print(f\"  ì†ìƒ ì´: {damage_count}ê°œ\")\n",
    "        for name, count in damage_dist.items():\n",
    "            print(f\"    - {name}: {count}ê°œ\")\n",
    "    \n",
    "    total_blade += blade_count\n",
    "    total_damage += damage_count\n",
    "\n",
    "print(f\"\\nì „ì²´ í•©ê³„:\")\n",
    "print(f\"  Blade: {total_blade}ê°œ\")\n",
    "print(f\"  ì†ìƒ: {total_damage}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…€ 8: ìƒ˜í”Œ ì‹œê°í™” (ì„ íƒì‚¬í•­)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_sample(split='train', sample_idx=0):\n",
    "    \"\"\"ìƒ˜í”Œ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ì‹œê°í™”\"\"\"\n",
    "    \n",
    "    blade_file = yolo_root / split / 'blade_only.json'\n",
    "    damage_file = yolo_root / split / 'damage_only.json'\n",
    "    \n",
    "    if not blade_file.exists() and not damage_file.exists():\n",
    "        print(\"JSON íŒŒì¼ ì—†ìŒ\")\n",
    "        return\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    if blade_file.exists():\n",
    "        with open(blade_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    else:\n",
    "        with open(damage_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    \n",
    "    if sample_idx >= len(data['images']):\n",
    "        print(f\"ìƒ˜í”Œ ì¸ë±ìŠ¤ ì´ˆê³¼ (ìµœëŒ€: {len(data['images'])-1})\")\n",
    "        return\n",
    "    \n",
    "    img_info = data['images'][sample_idx]\n",
    "    img_path = yolo_root / split / 'images' / img_info['file_name']\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    img = Image.open(img_path)\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # ì›ë³¸ ì´ë¯¸ì§€\n",
    "    axes[0].imshow(img_array)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Blade ë§ˆìŠ¤í¬\n",
    "    if blade_file.exists():\n",
    "        with open(blade_file, 'r') as f:\n",
    "            blade_data = json.load(f)\n",
    "        \n",
    "        blade_mask = np.zeros((img_info['height'], img_info['width']))\n",
    "        for ann in blade_data['annotations']:\n",
    "            if ann['image_id'] == img_info['id']:\n",
    "                # í´ë¦¬ê³¤ì„ ë§ˆìŠ¤í¬ë¡œ ë³€í™˜ (ê°„ë‹¨í•œ ì‹œê°í™”ìš©)\n",
    "                axes[1].add_patch(plt.Polygon(\n",
    "                    np.array(ann['segmentation'][0]).reshape(-1, 2),\n",
    "                    fill=True, alpha=0.5, color='blue'\n",
    "                ))\n",
    "        \n",
    "        axes[1].imshow(img_array)\n",
    "        axes[1].set_title('Blade')\n",
    "        axes[1].axis('off')\n",
    "    \n",
    "    # ì†ìƒ ë§ˆìŠ¤í¬\n",
    "    if damage_file.exists():\n",
    "        with open(damage_file, 'r') as f:\n",
    "            damage_data = json.load(f)\n",
    "        \n",
    "        colors = ['red', 'green', 'yellow']\n",
    "        for ann in damage_data['annotations']:\n",
    "            if ann['image_id'] == img_info['id']:\n",
    "                color = colors[ann['category_id'] % len(colors)]\n",
    "                axes[2].add_patch(plt.Polygon(\n",
    "                    np.array(ann['segmentation'][0]).reshape(-1, 2),\n",
    "                    fill=True, alpha=0.5, color=color\n",
    "                ))\n",
    "        \n",
    "        axes[2].imshow(img_array)\n",
    "        axes[2].set_title('Damage')\n",
    "        axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ìƒ˜í”Œ ì‹œê°í™”\n",
    "visualize_sample('train', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…€ 9: ìƒì„±ëœ íŒŒì¼ ëª©ë¡\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ìƒì„±ëœ íŒŒì¼ ëª©ë¡\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = yolo_root / split\n",
    "    print(f\"\\n{split}:\")\n",
    "    \n",
    "    files = [\n",
    "        '_annotations.coco.json',\n",
    "        'blade_only.json',\n",
    "        'damage_only.json'\n",
    "    ]\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = split_dir / file\n",
    "        if file_path.exists():\n",
    "            size = file_path.stat().st_size / 1024  # KB\n",
    "            print(f\"  âœ… {file} ({size:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"  âŒ {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234649bb",
   "metadata": {},
   "source": [
    "ë¸”ë ˆì´ë“œ ë°ì´í„° í†µí•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e02193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blade data: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data\n",
      "YOLO data: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\final_ver_data_rev2.v3i.yolov8\n",
      "Blade data exists: True\n",
      "YOLO exists: True\n"
     ]
    }
   ],
   "source": [
    "# ===== ì…€ 1: í™˜ê²½ ì„¤ì • =====\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "blade_data_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data')\n",
    "yolo_root = Path(r'C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\final_ver_data_rev2.v3i.yolov8')\n",
    "\n",
    "print(f\"Blade data: {blade_data_root}\")\n",
    "print(f\"YOLO data: {yolo_root}\")\n",
    "print(f\"Blade data exists: {blade_data_root.exists()}\")\n",
    "print(f\"YOLO exists: {yolo_root.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2a7915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë°±ì—… ìƒì„±: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data_backup_20250911_151507\n",
      "âœ… ë°±ì—… ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ===== ì…€ 2: ë°±ì—… ìƒì„± =====\n",
    "def backup_existing_data(blade_data_root):\n",
    "    \"\"\"ê¸°ì¡´ ë°ì´í„° ë°±ì—…\"\"\"\n",
    "    backup_dir = blade_data_root.parent / f\"blade_data_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    \n",
    "    if blade_data_root.exists():\n",
    "        print(f\"ğŸ“ ë°±ì—… ìƒì„±: {backup_dir}\")\n",
    "        shutil.copytree(blade_data_root, backup_dir)\n",
    "        print(\"âœ… ë°±ì—… ì™„ë£Œ\")\n",
    "        return backup_dir\n",
    "    return None\n",
    "\n",
    "# ë°±ì—… ì‹¤í–‰\n",
    "backup_path = backup_existing_data(blade_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6fc4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ“‚ TRAIN ì²˜ë¦¬\n",
      "==================================================\n",
      "  ê¸°ì¡´ blade_data: 2480 images, 4285 annotations\n",
      "  YOLO ë°ì´í„°: 2177 images, 3085 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [00:08<00:00, 256.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… ì¶”ê°€ë¨: 2177 images, 3085 annotations\n",
      "  âœ… ë³µì‚¬ëœ íŒŒì¼: 2177\n",
      "  âœ… ìµœì¢…: 4657 images, 7370 annotations\n",
      "  âœ… ì €ì¥: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data\\train\\blade_only.json\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ VALID ì²˜ë¦¬\n",
      "==================================================\n",
      "  ê¸°ì¡´ blade_data: 150 images, 249 annotations\n",
      "  YOLO ë°ì´í„°: 300 images, 437 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing valid images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:01<00:00, 251.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… ì¶”ê°€ë¨: 300 images, 437 annotations\n",
      "  âœ… ë³µì‚¬ëœ íŒŒì¼: 300\n",
      "  âœ… ìµœì¢…: 450 images, 686 annotations\n",
      "  âœ… ì €ì¥: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data\\valid\\blade_only.json\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ TEST ì²˜ë¦¬\n",
      "==================================================\n",
      "  ê¸°ì¡´ blade_data: 120 images, 206 annotations\n",
      "  YOLO ë°ì´í„°: 268 images, 452 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268/268 [00:01<00:00, 244.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… ì¶”ê°€ë¨: 268 images, 452 annotations\n",
      "  âœ… ë³µì‚¬ëœ íŒŒì¼: 268\n",
      "  âœ… ìµœì¢…: 388 images, 658 annotations\n",
      "  âœ… ì €ì¥: C:\\EngineBladeAI\\EngineInspectionAI_MS\\data\\blade_data\\test\\blade_only.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== ì…€ 3: YOLO blade_only.json í™•ì¸ ë° ë³µì‚¬ =====\n",
    "def merge_blade_data(blade_data_root, yolo_root):\n",
    "    \"\"\"YOLOì˜ blade_only.jsonì„ blade_dataë¡œ í†µí•©\"\"\"\n",
    "    \n",
    "    stats = {'train': {}, 'valid': {}, 'test': {}}\n",
    "    \n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ğŸ“‚ {split.upper()} ì²˜ë¦¬\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # ê²½ë¡œ ì„¤ì •\n",
    "        blade_json_path = blade_data_root / split / 'blade_only.json'\n",
    "        yolo_json_path = yolo_root / split / 'blade_only.json'\n",
    "        yolo_images_dir = yolo_root / split / 'images'\n",
    "        blade_images_dir = blade_data_root / split\n",
    "        \n",
    "        # ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "        blade_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # ê¸°ì¡´ blade_data JSON ë¡œë“œ\n",
    "        if blade_json_path.exists():\n",
    "            with open(blade_json_path, 'r') as f:\n",
    "                blade_data = json.load(f)\n",
    "            print(f\"  ê¸°ì¡´ blade_data: {len(blade_data['images'])} images, {len(blade_data['annotations'])} annotations\")\n",
    "        else:\n",
    "            # ê¸°ë³¸ êµ¬ì¡° ìƒì„±\n",
    "            blade_data = {\n",
    "                \"info\": {\"description\": f\"Blade Detection - {split}\", \"version\": \"2.0\"},\n",
    "                \"licenses\": [],\n",
    "                \"categories\": [\n",
    "                    {\"id\": 0, \"name\": \"background\", \"supercategory\": \"none\"},\n",
    "                    {\"id\": 1, \"name\": \"blade\", \"supercategory\": \"object\"}\n",
    "                ],\n",
    "                \"images\": [],\n",
    "                \"annotations\": []\n",
    "            }\n",
    "            print(\"  ìƒˆë¡œìš´ blade_data ìƒì„±\")\n",
    "        \n",
    "        # YOLO JSON ë¡œë“œ ë° í†µí•©\n",
    "        if yolo_json_path.exists():\n",
    "            with open(yolo_json_path, 'r') as f:\n",
    "                yolo_data = json.load(f)\n",
    "            print(f\"  YOLO ë°ì´í„°: {len(yolo_data['images'])} images, {len(yolo_data['annotations'])} annotations\")\n",
    "            \n",
    "            # ê¸°ì¡´ íŒŒì¼ëª… ëª©ë¡\n",
    "            existing_files = {img['file_name'] for img in blade_data['images']}\n",
    "            \n",
    "            # ID ë§¤í•‘\n",
    "            max_img_id = max([img['id'] for img in blade_data['images']], default=-1)\n",
    "            max_ann_id = max([ann['id'] for ann in blade_data['annotations']], default=-1)\n",
    "            \n",
    "            image_id_map = {}\n",
    "            added_images = 0\n",
    "            added_annotations = 0\n",
    "            copied_files = 0\n",
    "            \n",
    "            # YOLO ì´ë¯¸ì§€ ì¶”ê°€\n",
    "            for yolo_img in tqdm(yolo_data['images'], desc=f\"Processing {split} images\"):\n",
    "                if yolo_img['file_name'] not in existing_files:\n",
    "                    # ìƒˆ ì´ë¯¸ì§€ ì¶”ê°€\n",
    "                    new_img_id = max_img_id + 1 + added_images\n",
    "                    image_id_map[yolo_img['id']] = new_img_id\n",
    "                    \n",
    "                    new_img = yolo_img.copy()\n",
    "                    new_img['id'] = new_img_id\n",
    "                    blade_data['images'].append(new_img)\n",
    "                    \n",
    "                    # ì´ë¯¸ì§€ íŒŒì¼ ë³µì‚¬\n",
    "                    src_path = yolo_images_dir / yolo_img['file_name']\n",
    "                    dst_path = blade_images_dir / yolo_img['file_name']\n",
    "                    \n",
    "                    if src_path.exists() and not dst_path.exists():\n",
    "                        shutil.copy2(src_path, dst_path)\n",
    "                        copied_files += 1\n",
    "                    \n",
    "                    added_images += 1\n",
    "                else:\n",
    "                    # ê¸°ì¡´ ì´ë¯¸ì§€ì˜ ID ì°¾ê¸°\n",
    "                    for existing_img in blade_data['images']:\n",
    "                        if existing_img['file_name'] == yolo_img['file_name']:\n",
    "                            image_id_map[yolo_img['id']] = existing_img['id']\n",
    "                            break\n",
    "            \n",
    "            # YOLO annotation ì¶”ê°€\n",
    "            for yolo_ann in yolo_data['annotations']:\n",
    "                if yolo_ann['image_id'] in image_id_map:\n",
    "                    new_ann = yolo_ann.copy()\n",
    "                    new_ann['id'] = max_ann_id + 1 + added_annotations\n",
    "                    new_ann['image_id'] = image_id_map[yolo_ann['image_id']]\n",
    "                    blade_data['annotations'].append(new_ann)\n",
    "                    added_annotations += 1\n",
    "            \n",
    "            # í†µê³„\n",
    "            stats[split] = {\n",
    "                'original_images': len(blade_data['images']) - added_images,\n",
    "                'added_images': added_images,\n",
    "                'total_images': len(blade_data['images']),\n",
    "                'original_annotations': len(blade_data['annotations']) - added_annotations,\n",
    "                'added_annotations': added_annotations,\n",
    "                'total_annotations': len(blade_data['annotations']),\n",
    "                'copied_files': copied_files\n",
    "            }\n",
    "            \n",
    "            print(f\"  âœ… ì¶”ê°€ë¨: {added_images} images, {added_annotations} annotations\")\n",
    "            print(f\"  âœ… ë³µì‚¬ëœ íŒŒì¼: {copied_files}\")\n",
    "            print(f\"  âœ… ìµœì¢…: {len(blade_data['images'])} images, {len(blade_data['annotations'])} annotations\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ YOLO {split}/blade_only.json ì—†ìŒ\")\n",
    "            stats[split] = {'status': 'no_yolo_data'}\n",
    "        \n",
    "        # ì €ì¥\n",
    "        with open(blade_json_path, 'w') as f:\n",
    "            json.dump(blade_data, f, indent=2)\n",
    "        print(f\"  âœ… ì €ì¥: {blade_json_path}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# í†µí•© ì‹¤í–‰\n",
    "merge_stats = merge_blade_data(blade_data_root, yolo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93219418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š í†µí•© ê²°ê³¼ ìš”ì•½\n",
      "============================================================\n",
      "\n",
      "TRAIN:\n",
      "  ê¸°ì¡´ ì´ë¯¸ì§€: 2480\n",
      "  ì¶”ê°€ ì´ë¯¸ì§€: 2177\n",
      "  ìµœì¢… ì´ë¯¸ì§€: 4657\n",
      "  ì¶”ê°€ annotation: 3085\n",
      "  ë³µì‚¬ëœ íŒŒì¼: 2177\n",
      "\n",
      "VALID:\n",
      "  ê¸°ì¡´ ì´ë¯¸ì§€: 150\n",
      "  ì¶”ê°€ ì´ë¯¸ì§€: 300\n",
      "  ìµœì¢… ì´ë¯¸ì§€: 450\n",
      "  ì¶”ê°€ annotation: 437\n",
      "  ë³µì‚¬ëœ íŒŒì¼: 300\n",
      "\n",
      "TEST:\n",
      "  ê¸°ì¡´ ì´ë¯¸ì§€: 120\n",
      "  ì¶”ê°€ ì´ë¯¸ì§€: 268\n",
      "  ìµœì¢… ì´ë¯¸ì§€: 388\n",
      "  ì¶”ê°€ annotation: 452\n",
      "  ë³µì‚¬ëœ íŒŒì¼: 268\n",
      "\n",
      "ì „ì²´ í†µê³„:\n",
      "  ì´ ì¶”ê°€ ì´ë¯¸ì§€: 2745\n",
      "  ì´ ì¶”ê°€ annotation: 3974\n",
      "  ì´ ë³µì‚¬ íŒŒì¼: 2745\n"
     ]
    }
   ],
   "source": [
    "# ===== ì…€ 4: í†µí•© ê²°ê³¼ ìš”ì•½ =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š í†µí•© ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_added_images = 0\n",
    "total_added_annotations = 0\n",
    "total_copied_files = 0\n",
    "\n",
    "for split, stat in merge_stats.items():\n",
    "    if 'status' not in stat:\n",
    "        print(f\"\\n{split.upper()}:\")\n",
    "        print(f\"  ê¸°ì¡´ ì´ë¯¸ì§€: {stat['original_images']}\")\n",
    "        print(f\"  ì¶”ê°€ ì´ë¯¸ì§€: {stat['added_images']}\")\n",
    "        print(f\"  ìµœì¢… ì´ë¯¸ì§€: {stat['total_images']}\")\n",
    "        print(f\"  ì¶”ê°€ annotation: {stat['added_annotations']}\")\n",
    "        print(f\"  ë³µì‚¬ëœ íŒŒì¼: {stat['copied_files']}\")\n",
    "        \n",
    "        total_added_images += stat['added_images']\n",
    "        total_added_annotations += stat['added_annotations']\n",
    "        total_copied_files += stat['copied_files']\n",
    "\n",
    "print(f\"\\nì „ì²´ í†µê³„:\")\n",
    "print(f\"  ì´ ì¶”ê°€ ì´ë¯¸ì§€: {total_added_images}\")\n",
    "print(f\"  ì´ ì¶”ê°€ annotation: {total_added_annotations}\")\n",
    "print(f\"  ì´ ë³µì‚¬ íŒŒì¼: {total_copied_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ecd1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ” ë°ì´í„° ê²€ì¦\n",
      "============================================================\n",
      "\n",
      "train:\n",
      "  JSON ì´ë¯¸ì§€: 4657\n",
      "  JSON annotation: 7370\n",
      "  ì‹¤ì œ íŒŒì¼: 4657\n",
      "  âœ… íŒŒì¼ ì¼ì¹˜\n",
      "\n",
      "valid:\n",
      "  JSON ì´ë¯¸ì§€: 450\n",
      "  JSON annotation: 686\n",
      "  ì‹¤ì œ íŒŒì¼: 450\n",
      "  âœ… íŒŒì¼ ì¼ì¹˜\n",
      "\n",
      "test:\n",
      "  JSON ì´ë¯¸ì§€: 388\n",
      "  JSON annotation: 658\n",
      "  ì‹¤ì œ íŒŒì¼: 388\n",
      "  âœ… íŒŒì¼ ì¼ì¹˜\n"
     ]
    }
   ],
   "source": [
    "# ===== ì…€ 5: ê²€ì¦ =====\n",
    "def verify_merged_data(blade_data_root):\n",
    "    \"\"\"í†µí•©ëœ ë°ì´í„° ê²€ì¦\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ” ë°ì´í„° ê²€ì¦\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        json_path = blade_data_root / split / 'blade_only.json'\n",
    "        \n",
    "        if json_path.exists():\n",
    "            with open(json_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸\n",
    "            image_dir = blade_data_root / split\n",
    "            actual_images = list(image_dir.glob('*.jpg')) + list(image_dir.glob('*.png'))\n",
    "            \n",
    "            # JSONì˜ íŒŒì¼ëª…\n",
    "            json_files = {img['file_name'] for img in data['images']}\n",
    "            actual_files = {f.name for f in actual_images}\n",
    "            \n",
    "            print(f\"\\n{split}:\")\n",
    "            print(f\"  JSON ì´ë¯¸ì§€: {len(data['images'])}\")\n",
    "            print(f\"  JSON annotation: {len(data['annotations'])}\")\n",
    "            print(f\"  ì‹¤ì œ íŒŒì¼: {len(actual_images)}\")\n",
    "            \n",
    "            # ë¶ˆì¼ì¹˜ í™•ì¸\n",
    "            missing_files = json_files - actual_files\n",
    "            extra_files = actual_files - json_files\n",
    "            \n",
    "            if missing_files:\n",
    "                print(f\"  âš ï¸ JSONì—ë§Œ ìˆëŠ” íŒŒì¼: {len(missing_files)}ê°œ\")\n",
    "                for f in list(missing_files)[:3]:\n",
    "                    print(f\"    - {f}\")\n",
    "            \n",
    "            if extra_files:\n",
    "                print(f\"  âš ï¸ í´ë”ì—ë§Œ ìˆëŠ” íŒŒì¼: {len(extra_files)}ê°œ\")\n",
    "                for f in list(extra_files)[:3]:\n",
    "                    print(f\"    - {f}\")\n",
    "            \n",
    "            if not missing_files and not extra_files:\n",
    "                print(\"  âœ… íŒŒì¼ ì¼ì¹˜\")\n",
    "\n",
    "verify_merged_data(blade_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8228b093",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'previous'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ===== ì…€ 6: DeepLabTest.pyì™€ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ =====\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# CombinedBladeDatasetì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprevious\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mDeepLabTest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CombinedBladeDataset\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# ì´ì œ YOLO ê²½ë¡œ ëŒ€ì‹  blade_dataë§Œ ì‚¬ìš©í•´ë„ ë¨\u001b[39;00m\n\u001b[32m      7\u001b[39m     test_dataset = CombinedBladeDataset(\n\u001b[32m      8\u001b[39m         coco_dir=blade_data_root,\n\u001b[32m      9\u001b[39m         yolo_dir=blade_data_root,  \u001b[38;5;66;03m# ê°™ì€ ê²½ë¡œ ì‚¬ìš©\u001b[39;00m\n\u001b[32m     10\u001b[39m         split=\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     11\u001b[39m     )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'previous'"
     ]
    }
   ],
   "source": [
    "# ===== ì…€ 6: DeepLabTest.pyì™€ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ =====\n",
    "# CombinedBladeDatasetì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸\n",
    "from previous.models.DeepLabTest import CombinedBladeDataset\n",
    "\n",
    "try:\n",
    "    # ì´ì œ YOLO ê²½ë¡œ ëŒ€ì‹  blade_dataë§Œ ì‚¬ìš©í•´ë„ ë¨\n",
    "    test_dataset = CombinedBladeDataset(\n",
    "        coco_dir=blade_data_root,\n",
    "        yolo_dir=blade_data_root,  # ê°™ì€ ê²½ë¡œ ì‚¬ìš©\n",
    "        split='train'\n",
    "    )\n",
    "    print(f\"âœ… CombinedBladeDataset í˜¸í™˜ì„± í™•ì¸: {len(test_dataset)} samples\")\n",
    "    \n",
    "    # ìƒ˜í”Œ í…ŒìŠ¤íŠ¸\n",
    "    img, mask = test_dataset[0]\n",
    "    print(f\"  ì´ë¯¸ì§€ shape: {img.shape}\")\n",
    "    print(f\"  ë§ˆìŠ¤í¬ shape: {mask.shape}\")\n",
    "    print(f\"  ë§ˆìŠ¤í¬ unique values: {torch.unique(mask)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591c76c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
